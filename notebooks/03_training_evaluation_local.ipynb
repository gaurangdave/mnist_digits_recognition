{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZYKPYNu8eF1"
      },
      "source": [
        "# Model Training & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I5faNMt8hp5"
      },
      "source": [
        "* This note book is similar to `02_training_evaluation_colab` the only difference is we've created this to run locally instead of on `Google Colab`. The main reason for this is that the free version of `Google Colab` only has 2 cores, while our local machine has 12 cores giving us added advantage of almost 2X performance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9gYBPVV9jCK"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s9jYgk_x9k8O"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Binarizer, OneHotEncoder, MinMaxScaler, StandardScaler, FunctionTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict,GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import loguniform\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, f1_score, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import joblib\n",
        "import json\n",
        "import gdown\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz-Sy-KP91Wy"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "## function to download data from google drive\n",
        "def download_from_google_drive(file_id, file_name):\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    gdown.download(url, file_name, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "## check if mnist data is already downloaded\n",
        "mnist_train_set_path = Path(\"..\", \"data\", \"mnist_train_set.csv\")\n",
        "mnist_test_set_path = Path(\"..\", \"data\", \"mnist_test_set.csv\")\n",
        "\n",
        "if not mnist_train_set_path.exists():\n",
        "    ## download train set\n",
        "    file_id = \"1Rho1umzwBQTodR7sXVCdUZsJE7xq9EmM\"\n",
        "    # data_dir = str(Path(\"..\", \"data\", \"mnist_train_set.csv\"))\n",
        "    download_from_google_drive(file_id, str(mnist_train_set_path))\n",
        "\n",
        "if not mnist_test_set_path.exists():\n",
        "    ## download test set\n",
        "    file_id = \"1qxd-M96DJpYXHfO8xf_XKdDHr3o0xMUE\"\n",
        "    # data_dir = str(Path(\"..\", \"data\", \"mnist_test_set.csv\"))\n",
        "    download_from_google_drive(file_id, str(mnist_test_set_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NZpnRKS-J4s"
      },
      "source": [
        "### Access Train/Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oX0WLcHw-Ljl"
      },
      "outputs": [],
      "source": [
        "## access train data\n",
        "mnist_train_set = pd.read_csv(mnist_train_set_path)\n",
        "\n",
        "## access test data\n",
        "mnist_test_set = pd.read_csv(mnist_test_set_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "wR1vwxLN-dlT",
        "outputId": "45b49664-e313-40a4-bbf9-e48ea2aa5ae0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0       0       0   \n",
              "2       0       0       0       0       0       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       0       0   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  \\\n",
              "0        0  ...         0         0         0         0         0         0   \n",
              "1        0  ...         0         0         0         0         0         0   \n",
              "2        0  ...         0         0         0         0         0         0   \n",
              "3        0  ...         0         0         0         0         0         0   \n",
              "4        0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel782  pixel783  pixel784  class  \n",
              "0         0         0         0      0  \n",
              "1         0         0         0      7  \n",
              "2         0         0         0      0  \n",
              "3         0         0         0      9  \n",
              "4         0         0         0      1  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist_train_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "LhTJRHwG_OEL",
        "outputId": "004feeb7-0f48-4801-9576-64395cae93e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0       0       0   \n",
              "2       0       0       0       0       0       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       0       0   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  \\\n",
              "0        0  ...         0         0         0         0         0         0   \n",
              "1        0  ...         0         0         0         0         0         0   \n",
              "2        0  ...         0         0         0         0         0         0   \n",
              "3        0  ...         0         0         0         0         0         0   \n",
              "4        0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel782  pixel783  pixel784  class  \n",
              "0         0         0         0      7  \n",
              "1         0         0         0      3  \n",
              "2         0         0         0      1  \n",
              "3         0         0         0      1  \n",
              "4         0         0         0      2  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist_test_set.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGW8p6Yu-glV"
      },
      "source": [
        "### Split Features/Target Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EppfbDFo-kFc"
      },
      "outputs": [],
      "source": [
        "## Split training features and target into separate dataset\n",
        "train_X = mnist_train_set.drop(\"class\", axis=1)\n",
        "train_Y = mnist_train_set[\"class\"]\n",
        "\n",
        "## split test features and target into separate dataset\n",
        "test_X = mnist_test_set.drop(\"class\", axis=1)\n",
        "test_Y = mnist_test_set[\"class\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "VWiQPLgA-2kP",
        "outputId": "1054e378-52a7-488a-b1ff-f087702abe74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0       0       0   \n",
              "2       0       0       0       0       0       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       0       0   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0        0  ...         0         0         0         0         0         0   \n",
              "1        0  ...         0         0         0         0         0         0   \n",
              "2        0  ...         0         0         0         0         0         0   \n",
              "3        0  ...         0         0         0         0         0         0   \n",
              "4        0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrI5yRUF_fPN",
        "outputId": "12a8a312-8aa5-4f9c-fe47-8a26bb716858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56000 entries, 0 to 55999\n",
            "Columns: 784 entries, pixel1 to pixel784\n",
            "dtypes: int64(784)\n",
            "memory usage: 335.0 MB\n"
          ]
        }
      ],
      "source": [
        "train_X.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "8c2h0SZn-6ZM",
        "outputId": "07f35d1f-caae-4f8a-8333-b7c42dc94553"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0\n",
              "1    7\n",
              "2    0\n",
              "3    9\n",
              "4    1\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AyGzY0V_kXC",
        "outputId": "9ec6bc20-e422-40b0-edd1-8041be3d8532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 56000 entries, 0 to 55999\n",
            "Series name: class\n",
            "Non-Null Count  Dtype\n",
            "--------------  -----\n",
            "56000 non-null  int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 437.6 KB\n"
          ]
        }
      ],
      "source": [
        "train_Y.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "7YJJ-Zp4_oBG",
        "outputId": "09dbbadf-7236-40e2-8533-a5c819d3f4c2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0       0       0   \n",
              "2       0       0       0       0       0       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       0       0   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0        0  ...         0         0         0         0         0         0   \n",
              "1        0  ...         0         0         0         0         0         0   \n",
              "2        0  ...         0         0         0         0         0         0   \n",
              "3        0  ...         0         0         0         0         0         0   \n",
              "4        0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkIBCZ5H_qzw",
        "outputId": "488c6f7e-f0f2-414f-c6cf-79217b4eb0c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14000 entries, 0 to 13999\n",
            "Columns: 784 entries, pixel1 to pixel784\n",
            "dtypes: int64(784)\n",
            "memory usage: 83.7 MB\n"
          ]
        }
      ],
      "source": [
        "test_X.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "upNsfr8k_uTc",
        "outputId": "130b0f5c-b402-4c2a-ef9b-9c0dd1b791dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    7\n",
              "1    3\n",
              "2    1\n",
              "3    1\n",
              "4    2\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yDbB4Jt_v9m",
        "outputId": "f6e0e34d-75e9-4f45-f459-cbf379578720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 14000 entries, 0 to 13999\n",
            "Series name: class\n",
            "Non-Null Count  Dtype\n",
            "--------------  -----\n",
            "14000 non-null  int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 109.5 KB\n"
          ]
        }
      ],
      "source": [
        "test_Y.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8SbCvVE8vAK"
      },
      "source": [
        "## Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YniWK6x8wqZ"
      },
      "source": [
        "* Based on `Data Exploration` done in [01_explore_data.ipynb](https://github.com/gaurangdave/mnist_digits_recognition/blob/main/notebooks/01_explore_data.ipynb) below is the outline of the pipeline we are going to create,\n",
        "  * Pipeline Parameters\n",
        "    * `method` - To indicate whether we are going to `normalize`, `binarize` or leave the data as it is `none`.\n",
        "    * `threshold` - only applicable to `binarize` option to help set the threshold for binarization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HNMxsagAi2r"
      },
      "source": [
        "### Preprocessing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bxK8im4e_90L"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data, method=\"none\", threshold = 128):\n",
        "    \"\"\"\n",
        "    Preprocess MNIST data based on the specified method.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Input dataset with only features.\n",
        "        method (str): Preprocessing method - \"normalize\", \"binarize\", or \"none\".\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Preprocessed dataset.\n",
        "    \"\"\"\n",
        "    if method == \"normalize\":\n",
        "        scaler = MinMaxScaler()\n",
        "        transformed_data = scaler.fit_transform(data)\n",
        "        return pd.DataFrame(transformed_data)\n",
        "    elif method == \"binarize\":\n",
        "        binarizer = Binarizer(threshold=threshold)\n",
        "        transformed_data = binarizer.fit_transform(data)\n",
        "        return pd.DataFrame(transformed_data)\n",
        "    # else, keep features unchanged (no transformation)\n",
        "\n",
        "    # Combine processed features and labels\n",
        "    return pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7z3R3SAjlJT"
      },
      "source": [
        "* Lets create a `FunctionalTransformer` and test the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qE1_hInplZos"
      },
      "outputs": [],
      "source": [
        "## helper function to print aggregated descrition of features\n",
        "def print_aggregated_description(data):\n",
        "  # Check the range of normalized pixel values\n",
        "  print(f\"Min of mins in data is {data.iloc[:, :].min().min()} and max of mins in data is {data.iloc[:, :].min().max()}\")\n",
        "  print(f\"Min of max in data is {data.iloc[:, :].max().min()} and max of max in data is {data.iloc[:, :].max().max()}\")\n",
        "\n",
        "  # # Check the mean and standard deviation\n",
        "  print(f\"Aggregated mean of data is {data.iloc[:, :].mean().mean()}\")\n",
        "  print(f\"Aggregated standard deviation of data is {data.iloc[:, :].std().mean()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gWoKBHNBjj3a"
      },
      "outputs": [],
      "source": [
        "preprocess_transformer = FunctionTransformer(preprocess_data, feature_names_out=\"one-to-one\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3oRpt0-k0qa",
        "outputId": "51d0851f-e814-417c-d030-f1d820cfe5f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min of mins in data is 0 and max of mins in data is 0\n",
            "Min of max in data is 0 and max of max in data is 255\n",
            "Aggregated mean of data is 33.40283570973032\n",
            "Aggregated standard deviation of data is 49.25044784975305\n"
          ]
        }
      ],
      "source": [
        "## this should output the dataframe as it is without any changes.\n",
        "preprocessed_data = pd.DataFrame(preprocess_transformer.fit_transform(train_X, y=None), columns=preprocess_transformer.get_feature_names_out())\n",
        "print_aggregated_description(preprocessed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erAGLqzEl3g_"
      },
      "source": [
        "Observation:\n",
        "* Here aggregated min is 0 and max is 255 which matches the raw data as expected and aggreagated mean and standard deviation also matches the raw data as expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zplfk5TmjqE",
        "outputId": "6aae3bc2-07e9-40c3-e075-a93bebd302db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min of mins in data is 0.0 and max of mins in data is 0.0\n",
            "Min of max in data is 0.0 and max of max in data is 1.0\n",
            "Aggregated mean of data is 0.13099372795196987\n",
            "Aggregated standard deviation of data is 0.19343918583584427\n"
          ]
        }
      ],
      "source": [
        "## this should normalized the dataframe.\n",
        "preprocess_transformer = FunctionTransformer(preprocess_data, kw_args={\"method\": \"normalize\"}, feature_names_out=\"one-to-one\")\n",
        "preprocessed_data = pd.DataFrame(preprocess_transformer.fit_transform(train_X), columns=preprocess_transformer.get_feature_names_out())\n",
        "print_aggregated_description(preprocessed_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRPCTjj-puW6",
        "outputId": "de3cb1fa-6a6d-4254-f085-2e4f72a57b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min of mins in data is 0 and max of mins in data is 0\n",
            "Min of max in data is 0 and max of max in data is 1\n",
            "Aggregated mean of data is 0.13101193513119536\n",
            "Aggregated standard deviation of data is 0.21739390727945354\n"
          ]
        }
      ],
      "source": [
        "## this should binarize the dataframe.\n",
        "preprocess_transformer = FunctionTransformer(preprocess_data, kw_args={\"method\": \"binarize\", \"threshold\": 128}, feature_names_out=\"one-to-one\")\n",
        "preprocessed_data = pd.DataFrame(preprocess_transformer.fit_transform(train_X), columns=preprocess_transformer.get_feature_names_out())\n",
        "print_aggregated_description(preprocessed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPCzQjCWC6Is"
      },
      "source": [
        "## Plan\n",
        "\n",
        "* As a learning experience, we've decided to explore the following ML Algorithms to explore for classification,\n",
        "  1. Logistic Regression.\n",
        "  1. Support Vector Classifier (SVC).\n",
        "  1. K-Nearest Neighbour.\n",
        "  1. Random Forest Classifier.\n",
        "* We'll use the following metrics for each model,\n",
        "  * Accuracy\n",
        "  * Weighted F1 Score\n",
        "  * Per-class F1 Score\n",
        "* For `Logistic Regression` and `SVC` we'll focus on `hyperparameter tuning` and `threshold tuning` to get the best results.\n",
        "* For `KNN` and `Random Forest Classifier` we'll just focus on `hyperparameter tuning` to reduce the complexity and focus on getting handson experience with what we've learnt so far.\n",
        "* For all algorithms we'll do the following,\n",
        "  * Find a baseline model using cross validation\n",
        "  * Find hyper params using grid search cv\n",
        "    * Get the metrics for hypertuned model using cross validation for apples to apples comparison between baseline and hypertuned.\n",
        "* We need to do cross validation again for hypertuned model because once the hyper params are discovered, grid search cv trains a model on complete training data. And so when we calculate the performance metrics these numbers are inflated since model has already seen the data.\n",
        "  * To do the right comparison we either need to have a unseen validation set or use the hyper parameters in cross validation to get the right numbers.  For now we've decided to go with cross validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-yAhBe9FbSn"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfaWej-HGh6w"
      },
      "source": [
        "* Lets create models using `DummyClassifier` with stratified and most frequest strategies to create a baseline for comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj7r39b3GwZT"
      },
      "source": [
        "### Stratified Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB4Nr3smFgEW",
        "outputId": "ad50b7b6-2416-4342-d6a5-10ee6bf3128c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratified Prediction - Accuracy: 0.0988\n",
            "Weighted F1: 0.0988\n"
          ]
        }
      ],
      "source": [
        "# Create a dummy classifier that predicts randomly based on class distribution\n",
        "dummy_stratified = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
        "dummy_stratified.fit(train_X, train_Y)\n",
        "\n",
        "# Predict and evaluate\n",
        "stratified_predictions = dummy_stratified.predict(test_X)\n",
        "stratified_accuracy = accuracy_score(test_Y, stratified_predictions)\n",
        "stratified_f1 = f1_score(test_Y, stratified_predictions, average=\"weighted\")\n",
        "print(f\"Stratified Prediction - Accuracy: {stratified_accuracy:.4f}\")\n",
        "print(f\"Weighted F1: {stratified_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjsuDeV2HYRS"
      },
      "source": [
        "### Most Frequest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ga2H6OHHczq",
        "outputId": "3706cb82-2e07-4130-c0f5-0c65ff4cba00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most Frequent Class - Accuracy: 0.1125\n",
            "Weighted F1: 0.0228\n"
          ]
        }
      ],
      "source": [
        "# Create a dummy classifier that predicts the most frequent class\n",
        "dummy_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_most_frequent.fit(train_X, train_Y)\n",
        "\n",
        "# Predict and evaluate\n",
        "most_frequent_predictions = dummy_most_frequent.predict(test_X)\n",
        "most_frequent_accuracy = accuracy_score(test_Y, most_frequent_predictions)\n",
        "most_frequent_f1 = f1_score(test_Y, most_frequent_predictions, average=\"weighted\")\n",
        "print(f\"Most Frequent Class - Accuracy: {most_frequent_accuracy:.4f}\")\n",
        "print(f\"Weighted F1: {most_frequent_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y472_QuZHzmU"
      },
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "ByQVdH6kH1QU",
        "outputId": "49e1aa56-b91f-433f-d2b1-64d79aa00a1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Most Frequent</td>\n",
              "      <td>0.112500</td>\n",
              "      <td>0.022753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stratified</td>\n",
              "      <td>0.098786</td>\n",
              "      <td>0.098806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Model  Accuracy  Weighted F1\n",
              "0  Most Frequent  0.112500     0.022753\n",
              "1     Stratified  0.098786     0.098806"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline_results = pd.DataFrame({\n",
        "    \"Model\": [\"Most Frequent\", \"Stratified\"],\n",
        "    \"Accuracy\": [most_frequent_accuracy, stratified_accuracy],\n",
        "    \"Weighted F1\": [most_frequent_f1, stratified_f1]\n",
        "})\n",
        "\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju4Jf7fZIHaJ"
      },
      "source": [
        "### Observations\n",
        "* Both baseline models have very low `F1 Score` and `Accuracy` as expected.\n",
        "* Since the train and test set were stratified, the frequency of classes in both the sets are more or less similar which explains why the accuracy of `Frequent Dummy Classifier` is more than `Stratified`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPvHuOq4RUSR"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9fciyb7LRkAQ"
      },
      "outputs": [],
      "source": [
        "## helper function to calculate per class f1 scores\n",
        "def per_class_f1_score(actual_classes, prediction_classes):\n",
        "    # Compute F1 scores for each class directly\n",
        "    f1_scores = f1_score(actual_classes, prediction_classes, average=None)\n",
        "    # Create a list of dictionaries for output\n",
        "    per_class_f1_scores = [{\"class\": i, \"f1_score\": score} for i, score in enumerate(f1_scores)]\n",
        "\n",
        "    return per_class_f1_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Dey7q6cLRTRV"
      },
      "outputs": [],
      "source": [
        "def update_model_comparison(probabilities, true_labels, algorithm, method, filename, comparison_df=None):\n",
        "    \"\"\"\n",
        "    Updates the model comparison DataFrame with metrics for a given model.\n",
        "\n",
        "    Args:\n",
        "        probabilities (ndarray): Probabilities or predicted values for the dataset.\n",
        "        true_labels (Series or ndarray): True labels for the dataset.\n",
        "        algorithm (str): Name of the algorithm (e.g., 'Logistic Regression').\n",
        "        method (str): Method used (e.g., 'Default Params', 'Grid Search').\n",
        "        filename (str): Name of the file to save the model.\n",
        "        comparison_df (DataFrame or None): Existing comparison DataFrame. If None, a new one is created.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Updated comparison DataFrame with metrics for the given model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get predicted classes (argmax for probabilities)\n",
        "    predicted_classes = probabilities.argmax(axis=1)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(true_labels, predicted_classes)\n",
        "    weighted_f1 = f1_score(true_labels, predicted_classes, average='weighted')\n",
        "    roc_score = roc_auc_score(train_Y, probabilities, multi_class=\"ovr\")\n",
        "    # Compute per-class F1 scores\n",
        "    per_class_f1_scores = f1_score(true_labels, predicted_classes, average=None)\n",
        "    per_class_f1_dict = {f\"Class_{i}\": score for i, score in enumerate(per_class_f1_scores)}\n",
        "\n",
        "    # Create a new row with metrics\n",
        "    new_row = {\n",
        "        \"Algorithm\": algorithm,\n",
        "        \"Method\": method,\n",
        "        \"File Name\": filename,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Weighted F1 Score\": weighted_f1,\n",
        "        \"ROC AUC Score\": roc_score,\n",
        "        **per_class_f1_dict,  # Unpack per-class F1 scores\n",
        "    }\n",
        "\n",
        "    # Initialize or update the DataFrame\n",
        "    if comparison_df is None:\n",
        "      return pd.DataFrame([new_row])\n",
        "\n",
        "\n",
        "    # Append the new row\n",
        "    comparison_df = pd.concat([comparison_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "    return comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "406loEhhSdTq"
      },
      "outputs": [],
      "source": [
        "## helper function to save the model metrics to google drive\n",
        "models_path = Path(\"..\", \"models\")\n",
        "def save_comparison_df(comparison_df):\n",
        "  comparison_df.to_csv(f\"{str(models_path)}/mnist_models_metrics.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CI3pe4YULN82"
      },
      "outputs": [],
      "source": [
        "## helper function to dump and save the model on google drive\n",
        "from joblib import dump\n",
        "def save_model(estimator, file_name):\n",
        "  ## model path\n",
        "  model_path = Path(\"..\", \"models\", file_name)\n",
        "  dump(estimator, str(model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKxYTxfRAkJO"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvZbJe2nxayj"
      },
      "source": [
        "* Lets start with default estimator in logistic regression, we'll analyze the performance, tune the threshold and get the final performance numbers\n",
        "* After that we'll experiment with hyperparameters using `GridSearchCV` and `RandomSearchCV` tune the threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fVOmadOySA8"
      },
      "source": [
        "### Default Estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2zFd01si0fi"
      },
      "source": [
        "#### Initialize Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "L65-bv9pAbri"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "## initialize LogisticRegression\n",
        "logistic_regression = LogisticRegression(max_iter=10000)\n",
        "\n",
        "## create pipeline\n",
        "default_pipeline = Pipeline([\n",
        "    (\"preprocessing\", FunctionTransformer(preprocess_data, kw_args={\"method\": \"normalize\"})),\n",
        "    (\"training\", logistic_regression)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmiAnaHc_9jD"
      },
      "source": [
        "#### Finding Probabilies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gSJZ14Bh8jgf"
      },
      "outputs": [],
      "source": [
        "probabilities = cross_val_predict(default_pipeline, train_X, train_Y, cv=3, method=\"predict_proba\", n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY8MOnPETCH5",
        "outputId": "639c971c-2c3d-4e81-eb0f-a35e1e35b205"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[9.98539849e-01, 1.72487179e-17, 3.04786440e-08, ...,\n",
              "        8.46459391e-11, 1.14099141e-09, 1.56510674e-11],\n",
              "       [2.17677175e-11, 8.05965604e-05, 2.73645806e-06, ...,\n",
              "        9.96868621e-01, 6.65571635e-04, 2.29046998e-03],\n",
              "       [9.99287289e-01, 3.93336806e-12, 2.53542609e-05, ...,\n",
              "        2.36146724e-06, 3.75609944e-05, 2.72536315e-04],\n",
              "       ...,\n",
              "       [1.34196753e-10, 9.94951280e-01, 6.46942453e-05, ...,\n",
              "        4.78412044e-06, 2.28747392e-03, 2.65979418e-04],\n",
              "       [2.62376595e-08, 1.57345691e-08, 4.04014881e-05, ...,\n",
              "        1.51480874e-03, 4.64608394e-03, 9.77021388e-01],\n",
              "       [1.07720256e-07, 2.95387863e-06, 5.60961756e-05, ...,\n",
              "        2.72198097e-01, 1.98544675e-03, 6.64139264e-02]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function preprocess_data at 0x17b9eeb60&gt;,\n",
              "                                     kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                (&#x27;training&#x27;, LogisticRegression(max_iter=10000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function preprocess_data at 0x17b9eeb60&gt;,\n",
              "                                     kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                (&#x27;training&#x27;, LogisticRegression(max_iter=10000))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function preprocess_data at 0x17b9eeb60&gt;,\n",
              "                    kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=10000)</pre></div> </div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('preprocessing',\n",
              "                 FunctionTransformer(func=<function preprocess_data at 0x17b9eeb60>,\n",
              "                                     kw_args={'method': 'normalize'})),\n",
              "                ('training', LogisticRegression(max_iter=10000))])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train on the entire training dataset\n",
        "default_pipeline.fit(train_X, train_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "## save the model\n",
        "save_model(default_pipeline, \"logistic_regression_v0.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "B5tSibO-SOcZ"
      },
      "outputs": [],
      "source": [
        "## create/update comparison_df to compare metrics from all the models.\n",
        "comparison_df = update_model_comparison(probabilities, train_Y, \"Logistic Regression V0\", \"Default Estimator\", \"logistic_regression_v0.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "cVEUbyFoTPgl",
        "outputId": "c0950f41-a26e-4da0-c19a-3d6cbacb2fbe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Method</th>\n",
              "      <th>File Name</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1 Score</th>\n",
              "      <th>ROC AUC Score</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression V0</td>\n",
              "      <td>Default Estimator</td>\n",
              "      <td>logistic_regression_v0.joblib</td>\n",
              "      <td>0.919839</td>\n",
              "      <td>0.919697</td>\n",
              "      <td>0.992891</td>\n",
              "      <td>0.96094</td>\n",
              "      <td>0.964241</td>\n",
              "      <td>0.904483</td>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.926959</td>\n",
              "      <td>0.879824</td>\n",
              "      <td>0.944259</td>\n",
              "      <td>0.929785</td>\n",
              "      <td>0.880834</td>\n",
              "      <td>0.897883</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Algorithm             Method                      File Name  \\\n",
              "0  Logistic Regression V0  Default Estimator  logistic_regression_v0.joblib   \n",
              "\n",
              "   Accuracy  Weighted F1 Score  ROC AUC Score  Class_0   Class_1   Class_2  \\\n",
              "0  0.919839           0.919697       0.992891  0.96094  0.964241  0.904483   \n",
              "\n",
              "    Class_3   Class_4   Class_5   Class_6   Class_7   Class_8   Class_9  \n",
              "0  0.898339  0.926959  0.879824  0.944259  0.929785  0.880834  0.897883  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "RB2djq1cX4dt"
      },
      "outputs": [],
      "source": [
        "save_comparison_df(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU-fGCHzjrew"
      },
      "source": [
        "Observations:\n",
        "* `ROC AUC Score` of ~.99 means our estimator has high `True Positive Rate (TPR)` and a very low `False Positive Rate (FPR)`\n",
        "  * i.e. The model has very accurate discrimination rate between different classes\n",
        "* `F1 Score` of ~0.92 is a descent score, but this also tells us that our model has a low `Recall` i.e it has a higher `False Negative` rate.\n",
        "* Per class f1 score tells us that f1 score of class instance of 3, 5 8 and 9 is significantly lower than rest of classes and these might have an impact of overall f1 score.\n",
        "* Lets take a look at confusion matrix before threshold tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi84nT-QCjB8"
      },
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsN_OWbsBpiU"
      },
      "source": [
        "* Lets look at normalized data in percentage to get more useful insight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3HH3m7o3OnIh"
      },
      "outputs": [],
      "source": [
        "predictions = np.argmax(probabilities, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "nctXheonBcvg",
        "outputId": "72cd9357-3ce9-4a05-afa0-fcce1436f636"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17b30ce30>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(train_Y, predictions, normalize=\"true\", values_format=\".0%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U40FMUIvCI83"
      },
      "source": [
        "Observations:\n",
        "* So the percent of predictions for `3`, `5` and `8` are significantly less than rest of the classes as expected\n",
        "* Which is interesting because when it comes to hand written digits, `3`, `5` and `8` are similar and can be confusing depending on the handwriting.\n",
        "* Lets focus more on errors by putting 0 weight on correct predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "8m0DNiq36cSj",
        "outputId": "2ad14d21-74ee-46d7-a44f-e05e80456c7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17d72bd70>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample_weight = (predictions != train_Y)\n",
        "ConfusionMatrixDisplay.from_predictions(train_Y, predictions, normalize=\"true\", values_format=\".0%\", sample_weight=sample_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCDC3FyB0jFx"
      },
      "source": [
        "Observations:\n",
        "* This is interesting, this confusion matrix highlights some interesting chunks of errors,\n",
        "  * `47%` of errors of 4 (False Negatives) and `48%` of errors of 7 were classified as 9. This kind of makes sense, cause when we write 4 or 7 its kind of similar to 9. The straight line of 7 or angle of 4 can be mis represented as curve of 9.\n",
        "  * Also majoriy of misclassified 3s are classified as 2, 5 and 8.\n",
        "  * Similarly majority of misclassified 5s are classified as 3 and 8 and majority of 8s are misclassified as 3 and 5.\n",
        "  * This makes sense cause hand written 2,3,5 and 8 share similar patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrYkVZKu3XBm"
      },
      "source": [
        "#### Threshold Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss2mdS_y3Zha"
      },
      "source": [
        "* Lets see if we can find a better threshold and improve the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJyhYj-x5fY1"
      },
      "source": [
        "##### Per Class Threshold Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "QWUGXAUgz_GM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "def calculate_per_class_threshold(actual_classes, prediction_probabilities):\n",
        "    thresholds = []\n",
        "    for class_label in range(10):  # Loop through all classes\n",
        "        # Convert actual_classes to binary labels for the current class\n",
        "        binary_labels = (actual_classes == class_label).astype(int)\n",
        "        # Extract probabilities for the current class\n",
        "        class_probabilities = prediction_probabilities[:, class_label]\n",
        "\n",
        "        # Calculate ROC curve\n",
        "        fpr, tpr, threshold = roc_curve(binary_labels, class_probabilities)\n",
        "\n",
        "        # Calculate F1 scores for each threshold\n",
        "        f1_scores = (2 * tpr * (1 - fpr)) / (tpr + (1 - fpr))\n",
        "\n",
        "        # Handle any division by zero or invalid values in F1 scores\n",
        "        f1_scores = np.nan_to_num(f1_scores)\n",
        "\n",
        "        # Find the threshold with the highest F1 score\n",
        "        optimal_idx = f1_scores.argmax()\n",
        "        optimal_threshold = threshold[optimal_idx]\n",
        "\n",
        "        # Store the threshold for this class\n",
        "        thresholds.append({ \"class\": class_label, \"optimal_threshold\" : optimal_threshold})\n",
        "\n",
        "    return thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-DeNMSM25sPJ"
      },
      "outputs": [],
      "source": [
        "# Assuming `train_Y` contains actual class labels and `probabilities` contains class probabilities\n",
        "thresholds = calculate_per_class_threshold(train_Y, probabilities)\n",
        "threshold_df = pd.DataFrame(thresholds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6dxb7WcEO1c"
      },
      "source": [
        "##### Predictions With Thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8MnIXgms9wQo"
      },
      "outputs": [],
      "source": [
        "## helper functions to predict using optimized thresholds\n",
        "def predict_with_thresholds(prediction_probabilities, thresholds):\n",
        "    predictions = []\n",
        "    for i in range(prediction_probabilities.shape[0]):  # Iterate over each sample\n",
        "        # Check if probabilities exceed their respective thresholds\n",
        "        class_probs = [(cls, prob) for cls, prob in enumerate(prediction_probabilities[i]) if prob >= thresholds[thresholds[\"class\"] == cls][\"optimal_threshold\"].values[0]]\n",
        "\n",
        "        if class_probs:\n",
        "            # Choose the class with the highest probability among those exceeding thresholds\n",
        "            predictions.append(max(class_probs, key=lambda x: x[1])[0])\n",
        "        else:\n",
        "            # If no class exceeds threshold, default to the one with the highest probability\n",
        "            predictions.append(prediction_probabilities[i].argmax())\n",
        "\n",
        "    return np.array(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "0JenNxGVE8Tm"
      },
      "outputs": [],
      "source": [
        "optimized_predictions = predict_with_thresholds(probabilities, thresholds=threshold_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybdatWwyFZpI",
        "outputId": "392a8e94-0094-401a-9b1d-97e5beda8cd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9196967787148708"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(train_Y, optimized_predictions, average=\"weighted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgLDMuZZHVVN"
      },
      "source": [
        "* Original `f1 score` was `0.9197076517400227` so no change there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qiMZfDOLTVh"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9Y2t2o8PkBY"
      },
      "source": [
        "* For `Hyperparameter Tuning` we'll use the following strategy\n",
        "  * Iteration 1 : First we'll experiment with different solvers [‘newton-cg’, ‘sag’, ‘saga’, ‘lbfgs’] and different transformation techniqune ['normalization', 'binarization']\n",
        "  * Iteration 2 : Next along with above params we'll add penalty ['l2', 'None'] since `l2` works with all solvers we'll experiment with and without penalty, along with C [0.01, 0.1, 1, 10, 100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayan9m5NSH3E"
      },
      "source": [
        "#### Iteration 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "GkCXLl7oLYvH"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"logisticregression__solver\": [\"newton-cg\", \"sag\", \"saga\", \"lbfgs\"],\n",
        "    \"preprocessing__kw_args\": [{\"method\": \"normalize\"}, {\"method\": \"binarize\"}],\n",
        "}\n",
        "\n",
        "## initialize LogisticRegression\n",
        "logistic_regression = LogisticRegression(max_iter=10000, verbose=1)\n",
        "\n",
        "## create pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessing\", FunctionTransformer(preprocess_data, kw_args={\"method\": \"normalize\"})),\n",
        "    (\"logisticregression\", logistic_regression)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "1DqwUwy0SyWy",
        "outputId": "c8b825a2-1407-4052-db19-d8b64a8677b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06772560469289908 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06745058123962074 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06750060268395257 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596280984522609 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05424221012737024 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.054371692338912696 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0556326571727961 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05446629223870036 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025091128394095222 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05595957070928089 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.023210490038465433 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0245430528305145 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.023023988305067158 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02525569404177914 <= 0.0001 False\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 1, change: 1.00000000\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024388942315533235 <= 0.0001 False\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 1, change: 1.00000000\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.01453673896669188 <= 0.0001 False\n",
            "Epoch 1, change: 1.00000000\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013746480066164886 <= 0.0001 False\n",
            "Epoch 1, change: 1.00000000\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014559964695867489 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013596754560941109 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014599888853006008 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014506205604912571 <= 0.0001 False\n",
            "Epoch 2, change: 0.32323314\n",
            "Epoch 2, change: 0.29036502\n",
            "Epoch 2, change: 0.30098185\n",
            "Epoch 2, change: 0.31820534\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007593654728518624 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007107543699753866 <= 0.0001 False\n",
            "Epoch 2, change: 0.33398091\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00494944865053879 <= 0.0001 False\n",
            "Epoch 2, change: 0.32638062\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005054019827049796 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007506879794766388 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007283441377992933 <= 0.0001 False\n",
            "Epoch 3, change: 0.21531234\n",
            "Epoch 3, change: 0.17994483\n",
            "Epoch 3, change: 0.22584205\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031146963465692153 <= 0.0001 False\n",
            "Epoch 3, change: 0.18277413\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0033611405003100485 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.002563370178058731 <= 0.0001 False\n",
            "Epoch 3, change: 0.16661226\n",
            "Epoch 3, change: 0.20113732\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031707711255545726 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023202958093750045 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032522697034441383 <= 0.0001 False\n",
            "Epoch 4, change: 0.15654661\n",
            "Epoch 4, change: 0.14486653\n",
            "Epoch 4, change: 0.14299606\n",
            "Epoch 4, change: 0.10965830\n",
            "Epoch 4, change: 0.13322077\n",
            "Epoch 4, change: 0.14254743\n",
            "Epoch 5, change: 0.10668797\n",
            "Epoch 5, change: 0.11952292\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007994908562239658 <= 0.0001 False\n",
            "Epoch 5, change: 0.11308955\n",
            "Epoch 5, change: 0.07737391\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000887177890845067 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0012795083476968949 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000913237919852819 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0008578870970225558 <= 0.0001 False\n",
            "Epoch 5, change: 0.10173331\n",
            "Epoch 5, change: 0.09759162\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000836455371295198 <= 0.0001 False\n",
            "Epoch 6, change: 0.06249080\n",
            "Epoch 6, change: 0.07658652\n",
            "Epoch 6, change: 0.09445754\n",
            "Epoch 6, change: 0.08738370\n",
            "Epoch 6, change: 0.06350946\n",
            "Epoch 6, change: 0.08275806\n",
            "Epoch 7, change: 0.05331276\n",
            "Epoch 7, change: 0.04978084\n",
            "Epoch 7, change: 0.06481113\n",
            "Epoch 7, change: 0.08921258\n",
            "Epoch 7, change: 0.05870784\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005685017146812178 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0004552780825930107 <= 0.0001 False\n",
            "Epoch 7, change: 0.05471187\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005088976609375899 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005845979579338345 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005284668717374731 <= 0.0001 False\n",
            "Epoch 8, change: 0.04275294\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005773570836641845 <= 0.0001 False\n",
            "Epoch 8, change: 0.06123857\n",
            "Epoch 8, change: 0.04217731\n",
            "Epoch 8, change: 0.05313429\n",
            "Epoch 8, change: 0.04855502\n",
            "Epoch 8, change: 0.04359475\n",
            "Epoch 9, change: 0.04463867\n",
            "Epoch 9, change: 0.03904502\n",
            "Epoch 9, change: 0.04198769\n",
            "Epoch 9, change: 0.03822259\n",
            "Epoch 9, change: 0.03577546\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002756891144761195 <= 0.0001 False\n",
            "Epoch 9, change: 0.03694301\n",
            "Epoch 10, change: 0.03558144\n",
            "Epoch 10, change: 0.03863019\n",
            "Epoch 10, change: 0.03436002\n",
            "Epoch 10, change: 0.03308465\n",
            "Epoch 10, change: 0.03224707\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00035367276188885525 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002830050563447772 <= 0.0001 False\n",
            "Epoch 10, change: 0.03362543\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00034405090618695744 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00032831161461654914 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003457691373532914 <= 0.0001 False\n",
            "Epoch 11, change: 0.03457384\n",
            "Epoch 11, change: 0.03283970\n",
            "Epoch 11, change: 0.03085168\n",
            "Epoch 11, change: 0.03220039\n",
            "Epoch 11, change: 0.03013434\n",
            "Epoch 11, change: 0.03204359\n",
            "Epoch 12, change: 0.02662742\n",
            "Epoch 12, change: 0.03206516\n",
            "Epoch 12, change: 0.03225323\n",
            "Epoch 12, change: 0.03066437\n",
            "Epoch 12, change: 0.02855583\n",
            "Epoch 12, change: 0.02951894\n",
            "Epoch 13, change: 0.03033880\n",
            "Epoch 13, change: 0.02605690\n",
            "Epoch 13, change: 0.03022765\n",
            "Epoch 13, change: 0.02809276\n",
            "Epoch 13, change: 0.02619933\n",
            "Epoch 13, change: 0.02613793\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000150611754857631 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00013874705645879417 <= 0.0001 False\n",
            "Epoch 14, change: 0.02818434\n",
            "Epoch 14, change: 0.02413587\n",
            "Epoch 14, change: 0.02717806\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00022188555862540438 <= 0.0001 False\n",
            "Epoch 14, change: 0.02821648\n",
            "Epoch 14, change: 0.02432602\n",
            "Epoch 14, change: 0.02521689\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010587022746062941 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010949043378872298 <= 0.0001 False\n",
            "Epoch 15, change: 0.02602274\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00014093211515910775 <= 0.0001 False\n",
            "Epoch 15, change: 0.02512945\n",
            "Epoch 15, change: 0.02263731\n",
            "Epoch 15, change: 0.02656342\n",
            "Epoch 15, change: 0.02285086\n",
            "Epoch 15, change: 0.02234200\n",
            "Epoch 16, change: 0.02504075\n",
            "Epoch 16, change: 0.02266709\n",
            "Epoch 16, change: 0.02229341\n",
            "Epoch 16, change: 0.02488107\n",
            "Epoch 16, change: 0.02110189\n",
            "Epoch 16, change: 0.02163076\n",
            "Epoch 17, change: 0.02357411\n",
            "Epoch 17, change: 0.02188100\n",
            "Epoch 17, change: 0.02102230\n",
            "Epoch 17, change: 0.02349960\n",
            "Epoch 17, change: 0.02000072\n",
            "Epoch 17, change: 0.02015206\n",
            "Epoch 18, change: 0.02227648\n",
            "Epoch 18, change: 0.02059947\n",
            "Epoch 18, change: 0.02010796\n",
            "Epoch 18, change: 0.02257960\n",
            "Epoch 18, change: 0.01918481\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.3043549648403533e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2281260307051291.\n",
            "Epoch 18, change: 0.01861706\n",
            "Epoch 19, change: 0.02102693\n",
            "Epoch 19, change: 0.01941852\n",
            "Epoch 19, change: 0.01978620\n",
            "Epoch 19, change: 0.02189925\n",
            "Epoch 19, change: 0.01849672\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 9.829169845516656e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2261625773537494.\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 4.115658599819953e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.22256316337129556.\n",
            "Epoch 19, change: 0.01837190\n",
            "Epoch 20, change: 0.01972796\n",
            "Epoch 20, change: 0.01864736\n",
            "Epoch 20, change: 0.01837677\n",
            "Epoch 20, change: 0.02073615\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.9769157620122838e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.21649195609951896.\n",
            "Epoch 20, change: 0.01721209\n",
            "Epoch 1, change: 1.00000000\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 3.4261423127887806e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.22214318537060465.\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.8331698858140754e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2182472068133294.\n",
            "Epoch 20, change: 0.01694914\n",
            "Epoch 21, change: 0.01856343\n",
            "Epoch 21, change: 0.01763475\n",
            "Epoch 21, change: 0.01964261\n",
            "Epoch 21, change: 0.01774556\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 21, change: 0.01640651\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 2, change: 0.20481258\n",
            "Epoch 21, change: 0.01613316\n",
            "Epoch 22, change: 0.01760040\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 22, change: 0.01674738\n",
            "Epoch 22, change: 0.01856631\n",
            "Epoch 22, change: 0.01712619\n",
            "Epoch 2, change: 0.26839238\n",
            "Epoch 22, change: 0.01549425\n",
            "Epoch 2, change: 0.26072030\n",
            "Epoch 3, change: 0.13519003\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 22, change: 0.01544394\n",
            "Epoch 23, change: 0.01676696\n",
            "Epoch 2, change: 0.24026389\n",
            "Epoch 23, change: 0.01623893\n",
            "Epoch 23, change: 0.01763639\n",
            "Epoch 23, change: 0.01630765\n",
            "Epoch 3, change: 0.16365349\n",
            "Epoch 23, change: 0.01487175\n",
            "Epoch 3, change: 0.15066811\n",
            "Epoch 2, change: 0.23577432\n",
            "Epoch 2, change: 0.23621369\n",
            "Epoch 4, change: 0.10474624\n",
            "Epoch 23, change: 0.01477972\n",
            "Epoch 24, change: 0.01608670\n",
            "Epoch 24, change: 0.01670873\n",
            "Epoch 24, change: 0.01524727\n",
            "Epoch 3, change: 0.16515273\n",
            "Epoch 24, change: 0.01574402\n",
            "Epoch 4, change: 0.10118243\n",
            "Epoch 24, change: 0.01406322\n",
            "Epoch 4, change: 0.10750670\n",
            "Epoch 3, change: 0.13210117\n",
            "Epoch 24, change: 0.01396851\n",
            "Epoch 3, change: 0.14357850\n",
            "Epoch 5, change: 0.07767469\n",
            "Epoch 25, change: 0.01498509\n",
            "Epoch 25, change: 0.01572651\n",
            "Epoch 25, change: 0.01469152\n",
            "Epoch 4, change: 0.11494027\n",
            "Epoch 25, change: 0.01527278\n",
            "Epoch 25, change: 0.01324357\n",
            "Epoch 5, change: 0.08241219\n",
            "Epoch 5, change: 0.09851732\n",
            "Epoch 4, change: 0.09862646\n",
            "Epoch 4, change: 0.11177661\n",
            "Epoch 25, change: 0.01339492\n",
            "Epoch 26, change: 0.01437088\n",
            "Epoch 6, change: 0.06313556\n",
            "Epoch 26, change: 0.01498021\n",
            "Epoch 26, change: 0.01423804\n",
            "Epoch 5, change: 0.08199359\n",
            "Epoch 26, change: 0.01474133\n",
            "Epoch 26, change: 0.01276481\n",
            "Epoch 6, change: 0.06789475\n",
            "Epoch 6, change: 0.07618094\n",
            "Epoch 5, change: 0.08270404\n",
            "Epoch 26, change: 0.01284572\n",
            "Epoch 27, change: 0.01375587\n",
            "Epoch 5, change: 0.08919613\n",
            "Epoch 7, change: 0.05518689\n",
            "Epoch 27, change: 0.01427467\n",
            "Epoch 27, change: 0.01359976\n",
            "Epoch 6, change: 0.06420175\n",
            "Epoch 27, change: 0.01410489\n",
            "Epoch 27, change: 0.01234085\n",
            "Epoch 7, change: 0.05942644\n",
            "Epoch 28, change: 0.01310502\n",
            "Epoch 6, change: 0.06849273\n",
            "Epoch 27, change: 0.01226582\n",
            "Epoch 7, change: 0.06120155\n",
            "Epoch 28, change: 0.01339318\n",
            "Epoch 8, change: 0.04799405\n",
            "Epoch 6, change: 0.07228460\n",
            "Epoch 28, change: 0.01300211\n",
            "Epoch 7, change: 0.05701192\n",
            "Epoch 28, change: 0.01361254\n",
            "Epoch 28, change: 0.01186008\n",
            "Epoch 8, change: 0.04947848\n",
            "Epoch 29, change: 0.01241272\n",
            "Epoch 7, change: 0.05840439\n",
            "Epoch 28, change: 0.01158498\n",
            "Epoch 29, change: 0.01261998\n",
            "Epoch 8, change: 0.05266593\n",
            "Epoch 9, change: 0.04136411\n",
            "Epoch 7, change: 0.06278762\n",
            "Epoch 29, change: 0.01232672\n",
            "Epoch 29, change: 0.01303341\n",
            "Epoch 8, change: 0.04970023\n",
            "Epoch 29, change: 0.01124574\n",
            "Epoch 9, change: 0.04041934\n",
            "Epoch 30, change: 0.01199382\n",
            "Epoch 30, change: 0.01181534\n",
            "Epoch 29, change: 0.01124917\n",
            "Epoch 8, change: 0.05159677\n",
            "Epoch 9, change: 0.04754931\n",
            "Epoch 8, change: 0.05039751\n",
            "Epoch 30, change: 0.01170004\n",
            "Epoch 10, change: 0.03808453\n",
            "Epoch 30, change: 0.01254918\n",
            "Epoch 9, change: 0.04258792\n",
            "Epoch 30, change: 0.01072312\n",
            "Epoch 10, change: 0.03666591\n",
            "Epoch 31, change: 0.01166741\n",
            "Epoch 31, change: 0.01136534\n",
            "Epoch 30, change: 0.01077150\n",
            "Epoch 10, change: 0.03896600\n",
            "Epoch 9, change: 0.04524519\n",
            "Epoch 31, change: 0.01091022\n",
            "Epoch 9, change: 0.04423353\n",
            "Epoch 11, change: 0.03450712\n",
            "Epoch 31, change: 0.01198980\n",
            "Epoch 10, change: 0.03497899\n",
            "Epoch 31, change: 0.01034516\n",
            "Epoch 11, change: 0.03267886\n",
            "Epoch 32, change: 0.01088570\n",
            "Epoch 32, change: 0.01100082\n",
            "Epoch 31, change: 0.01025005\n",
            "Epoch 32, change: 0.01043267\n",
            "Epoch 10, change: 0.04024075\n",
            "Epoch 10, change: 0.03807340\n",
            "Epoch 11, change: 0.03355865\n",
            "Epoch 12, change: 0.03219962\n",
            "Epoch 32, change: 0.01154709\n",
            "Epoch 11, change: 0.03259179\n",
            "Epoch 32, change: 0.00990260\n",
            "Epoch 33, change: 0.01056123\n",
            "Epoch 33, change: 0.01044617\n",
            "Epoch 12, change: 0.02628594\n",
            "Epoch 32, change: 0.00988742\n",
            "Epoch 33, change: 0.00997436\n",
            "Epoch 11, change: 0.03783239\n",
            "Epoch 12, change: 0.03115312\n",
            "Epoch 11, change: 0.03415953\n",
            "Epoch 13, change: 0.03046182\n",
            "Epoch 33, change: 0.01077897\n",
            "Epoch 33, change: 0.00955989\n",
            "Epoch 12, change: 0.02915127\n",
            "Epoch 34, change: 0.01012516\n",
            "Epoch 34, change: 0.01008558\n",
            "Epoch 33, change: 0.00954878\n",
            "Epoch 13, change: 0.02486963\n",
            "Epoch 34, change: 0.00952040\n",
            "Epoch 12, change: 0.03404680\n",
            "Epoch 13, change: 0.02780404\n",
            "Epoch 12, change: 0.03084176\n",
            "Epoch 14, change: 0.02839718\n",
            "Epoch 34, change: 0.01044023\n",
            "Epoch 13, change: 0.02721401\n",
            "Epoch 34, change: 0.00917326\n",
            "Epoch 35, change: 0.00970450\n",
            "Epoch 35, change: 0.00962300\n",
            "Epoch 34, change: 0.00929168\n",
            "Epoch 35, change: 0.00904177\n",
            "Epoch 14, change: 0.02226513\n",
            "Epoch 13, change: 0.03255201\n",
            "Epoch 14, change: 0.02501743\n",
            "Epoch 13, change: 0.02982526\n",
            "Epoch 15, change: 0.02669271\n",
            "Epoch 35, change: 0.01007586\n",
            "Epoch 35, change: 0.00891357\n",
            "Epoch 14, change: 0.02588134\n",
            "Epoch 36, change: 0.00936594\n",
            "Epoch 36, change: 0.00927439\n",
            "Epoch 35, change: 0.00897736\n",
            "Epoch 36, change: 0.00861666\n",
            "Epoch 15, change: 0.02081113\n",
            "Epoch 14, change: 0.02987565\n",
            "Epoch 15, change: 0.02246689\n",
            "Epoch 14, change: 0.02752214\n",
            "Epoch 16, change: 0.02544724\n",
            "Epoch 36, change: 0.00973232\n",
            "Epoch 36, change: 0.00858410\n",
            "Epoch 15, change: 0.02391344\n",
            "Epoch 37, change: 0.00906466\n",
            "Epoch 36, change: 0.00887914\n",
            "Epoch 37, change: 0.00894265\n",
            "Epoch 37, change: 0.00829446\n",
            "Epoch 16, change: 0.01967884\n",
            "Epoch 16, change: 0.02087550\n",
            "Epoch 15, change: 0.02682648\n",
            "Epoch 15, change: 0.02583019\n",
            "Epoch 37, change: 0.00942522\n",
            "Epoch 17, change: 0.02412677\n",
            "Epoch 37, change: 0.00821094\n",
            "Epoch 16, change: 0.02210569\n",
            "Epoch 38, change: 0.00874650\n",
            "Epoch 37, change: 0.00863994\n",
            "Epoch 38, change: 0.00870164\n",
            "Epoch 38, change: 0.00795290\n",
            "Epoch 17, change: 0.01858305\n",
            "Epoch 17, change: 0.01897876\n",
            "Epoch 16, change: 0.02595135\n",
            "Epoch 16, change: 0.02357044\n",
            "Epoch 38, change: 0.00906817\n",
            "Epoch 18, change: 0.02251130\n",
            "Epoch 38, change: 0.00788170\n",
            "Epoch 39, change: 0.00850721\n",
            "Epoch 17, change: 0.02075953\n",
            "Epoch 38, change: 0.00835178\n",
            "Epoch 39, change: 0.00848747\n",
            "Epoch 39, change: 0.00759801\n",
            "Epoch 18, change: 0.01776396\n",
            "Epoch 18, change: 0.01734558\n",
            "Epoch 17, change: 0.02419013\n",
            "Epoch 17, change: 0.02331008\n",
            "Epoch 39, change: 0.00867954\n",
            "Epoch 19, change: 0.02165038\n",
            "Epoch 39, change: 0.00763580\n",
            "Epoch 40, change: 0.00822042\n",
            "Epoch 18, change: 0.01902943\n",
            "Epoch 40, change: 0.00828894\n",
            "Epoch 39, change: 0.00820042\n",
            "Epoch 40, change: 0.00723269\n",
            "Epoch 19, change: 0.01691592\n",
            "Epoch 19, change: 0.01635755\n",
            "Epoch 18, change: 0.02185622\n",
            "Epoch 18, change: 0.02185341\n",
            "Epoch 40, change: 0.00835030\n",
            "Epoch 40, change: 0.00734011\n",
            "Epoch 20, change: 0.02048700\n",
            "Epoch 41, change: 0.00798294\n",
            "Epoch 19, change: 0.01880899\n",
            "Epoch 41, change: 0.00809980\n",
            "Epoch 40, change: 0.00798061\n",
            "Epoch 41, change: 0.00691796\n",
            "Epoch 20, change: 0.01641376\n",
            "Epoch 20, change: 0.01555931\n",
            "Epoch 19, change: 0.02074036\n",
            "Epoch 19, change: 0.02112478\n",
            "Epoch 41, change: 0.00804636\n",
            "Epoch 41, change: 0.00715604\n",
            "Epoch 21, change: 0.01975016\n",
            "Epoch 42, change: 0.00765198\n",
            "Epoch 42, change: 0.00793031\n",
            "Epoch 20, change: 0.01728893\n",
            "Epoch 41, change: 0.00778525\n",
            "Epoch 42, change: 0.00666932\n",
            "Epoch 21, change: 0.01554195\n",
            "Epoch 21, change: 0.01499409\n",
            "Epoch 20, change: 0.01966273\n",
            "Epoch 20, change: 0.02043875\n",
            "Epoch 42, change: 0.00775655\n",
            "Epoch 42, change: 0.00691745\n",
            "Epoch 22, change: 0.01888631\n",
            "Epoch 43, change: 0.00741153\n",
            "Epoch 43, change: 0.00769958\n",
            "Epoch 42, change: 0.00757633\n",
            "Epoch 21, change: 0.01672966\n",
            "Epoch 43, change: 0.00632071\n",
            "Epoch 22, change: 0.01512742\n",
            "Epoch 22, change: 0.01440200\n",
            "Epoch 43, change: 0.00663715\n",
            "Epoch 21, change: 0.01879047\n",
            "Epoch 21, change: 0.01870088\n",
            "Epoch 43, change: 0.00745435\n",
            "Epoch 23, change: 0.01804746\n",
            "Epoch 44, change: 0.00719195\n",
            "Epoch 44, change: 0.00754696\n",
            "Epoch 43, change: 0.00736922\n",
            "Epoch 22, change: 0.01631556\n",
            "Epoch 44, change: 0.00606019\n",
            "Epoch 23, change: 0.01417798\n",
            "Epoch 23, change: 0.01395407\n",
            "Epoch 44, change: 0.00640186\n",
            "Epoch 22, change: 0.01766185\n",
            "Epoch 44, change: 0.00717580\n",
            "Epoch 22, change: 0.01825148\n",
            "Epoch 24, change: 0.01748237\n",
            "Epoch 45, change: 0.00700296\n",
            "Epoch 45, change: 0.00737767\n",
            "Epoch 44, change: 0.00717631\n",
            "Epoch 23, change: 0.01563603\n",
            "Epoch 45, change: 0.00584981\n",
            "Epoch 24, change: 0.01382236\n",
            "Epoch 45, change: 0.00620614\n",
            "Epoch 45, change: 0.00689594\n",
            "Epoch 24, change: 0.01346020\n",
            "Epoch 23, change: 0.01688733\n",
            "Epoch 23, change: 0.01758973\n",
            "Epoch 46, change: 0.00682877\n",
            "Epoch 46, change: 0.00720158\n",
            "Epoch 25, change: 0.01667621\n",
            "Epoch 45, change: 0.00686599\n",
            "Epoch 24, change: 0.01520268\n",
            "Epoch 46, change: 0.00561504\n",
            "Epoch 46, change: 0.00670384\n",
            "Epoch 46, change: 0.00599462\n",
            "Epoch 25, change: 0.01330287\n",
            "Epoch 25, change: 0.01289067\n",
            "Epoch 24, change: 0.01699283\n",
            "Epoch 47, change: 0.00655374\n",
            "Epoch 24, change: 0.01632209\n",
            "Epoch 46, change: 0.00674858\n",
            "Epoch 26, change: 0.01592886\n",
            "Epoch 47, change: 0.00704369\n",
            "Epoch 25, change: 0.01430010\n",
            "Epoch 47, change: 0.00539119\n",
            "Epoch 47, change: 0.00649645\n",
            "Epoch 47, change: 0.00580980\n",
            "Epoch 26, change: 0.01286190\n",
            "Epoch 25, change: 0.01637936\n",
            "Epoch 48, change: 0.00637496\n",
            "Epoch 26, change: 0.01240809\n",
            "Epoch 25, change: 0.01559923\n",
            "Epoch 47, change: 0.00657295\n",
            "Epoch 48, change: 0.00689021\n",
            "Epoch 27, change: 0.01544054\n",
            "Epoch 26, change: 0.01410628\n",
            "Epoch 48, change: 0.00519774\n",
            "Epoch 48, change: 0.00558919\n",
            "Epoch 48, change: 0.00624435\n",
            "Epoch 27, change: 0.01245503\n",
            "Epoch 49, change: 0.00619740\n",
            "Epoch 26, change: 0.01538956\n",
            "Epoch 27, change: 0.01212948\n",
            "Epoch 26, change: 0.01529573\n",
            "Epoch 48, change: 0.00640749\n",
            "Epoch 49, change: 0.00673071\n",
            "Epoch 28, change: 0.01489192\n",
            "Epoch 49, change: 0.00507882\n",
            "Epoch 27, change: 0.01370874\n",
            "Epoch 49, change: 0.00596131\n",
            "Epoch 49, change: 0.00543006\n",
            "Epoch 28, change: 0.01207186\n",
            "Epoch 27, change: 0.01452404\n",
            "Epoch 27, change: 0.01508759\n",
            "Epoch 50, change: 0.00600302\n",
            "Epoch 28, change: 0.01164755\n",
            "Epoch 49, change: 0.00628330\n",
            "Epoch 50, change: 0.00660556\n",
            "Epoch 29, change: 0.01445057\n",
            "Epoch 50, change: 0.00496697\n",
            "Epoch 28, change: 0.01319802\n",
            "Epoch 50, change: 0.00525242\n",
            "Epoch 50, change: 0.00576692\n",
            "Epoch 28, change: 0.01363642\n",
            "Epoch 29, change: 0.01156292\n",
            "Epoch 51, change: 0.00582234\n",
            "Epoch 28, change: 0.01466265\n",
            "Epoch 29, change: 0.01119282\n",
            "Epoch 50, change: 0.00618085\n",
            "Epoch 51, change: 0.00646620\n",
            "Epoch 51, change: 0.00480957\n",
            "Epoch 29, change: 0.01279668\n",
            "Epoch 30, change: 0.01395171\n",
            "Epoch 51, change: 0.00507762\n",
            "Epoch 51, change: 0.00557916\n",
            "Epoch 29, change: 0.01315928\n",
            "Epoch 52, change: 0.00563433\n",
            "Epoch 30, change: 0.01132629\n",
            "Epoch 29, change: 0.01394998\n",
            "Epoch 30, change: 0.01100132\n",
            "Epoch 51, change: 0.00598998\n",
            "Epoch 52, change: 0.00635586\n",
            "Epoch 52, change: 0.00468507\n",
            "Epoch 31, change: 0.01354438\n",
            "Epoch 30, change: 0.01242844\n",
            "Epoch 52, change: 0.00490770\n",
            "Epoch 52, change: 0.00538089\n",
            "Epoch 30, change: 0.01295368\n",
            "Epoch 53, change: 0.00548780\n",
            "Epoch 31, change: 0.01080601\n",
            "Epoch 31, change: 0.01061333\n",
            "Epoch 30, change: 0.01353760\n",
            "Epoch 53, change: 0.00621671\n",
            "Epoch 52, change: 0.00580256\n",
            "Epoch 53, change: 0.00457246\n",
            "Epoch 32, change: 0.01308627\n",
            "Epoch 31, change: 0.01229286\n",
            "Epoch 53, change: 0.00479004\n",
            "Epoch 53, change: 0.00521318\n",
            "Epoch 54, change: 0.00537301\n",
            "Epoch 31, change: 0.01248549\n",
            "Epoch 32, change: 0.01040303\n",
            "Epoch 32, change: 0.01055324\n",
            "Epoch 31, change: 0.01312264\n",
            "Epoch 54, change: 0.00604621\n",
            "Epoch 53, change: 0.00566196\n",
            "Epoch 54, change: 0.00441182\n",
            "Epoch 32, change: 0.01179227\n",
            "Epoch 33, change: 0.01262197\n",
            "Epoch 54, change: 0.00462976\n",
            "Epoch 54, change: 0.00505358\n",
            "Epoch 55, change: 0.00520719\n",
            "Epoch 32, change: 0.01188412\n",
            "Epoch 33, change: 0.01014881\n",
            "Epoch 33, change: 0.01001884\n",
            "Epoch 32, change: 0.01264697\n",
            "Epoch 55, change: 0.00593265\n",
            "Epoch 54, change: 0.00553377\n",
            "Epoch 55, change: 0.00427192\n",
            "Epoch 33, change: 0.01149026\n",
            "Epoch 55, change: 0.00449864\n",
            "Epoch 34, change: 0.01231469\n",
            "Epoch 55, change: 0.00486631\n",
            "Epoch 56, change: 0.00506592\n",
            "Epoch 33, change: 0.01146643\n",
            "Epoch 34, change: 0.00996119\n",
            "Epoch 34, change: 0.00981639\n",
            "Epoch 56, change: 0.00583227\n",
            "Epoch 33, change: 0.01242534\n",
            "Epoch 55, change: 0.00539737\n",
            "Epoch 56, change: 0.00419862\n",
            "Epoch 56, change: 0.00433444\n",
            "Epoch 34, change: 0.01113915\n",
            "Epoch 35, change: 0.01200931\n",
            "Epoch 56, change: 0.00474221\n",
            "Epoch 57, change: 0.00497233\n",
            "Epoch 34, change: 0.01126433\n",
            "Epoch 57, change: 0.00572442\n",
            "Epoch 35, change: 0.00965416\n",
            "Epoch 35, change: 0.00933246\n",
            "Epoch 34, change: 0.01188716\n",
            "Epoch 56, change: 0.00527083\n",
            "Epoch 57, change: 0.00408152\n",
            "Epoch 57, change: 0.00422955\n",
            "Epoch 36, change: 0.01152358\n",
            "Epoch 35, change: 0.01099151\n",
            "Epoch 57, change: 0.00458365\n",
            "Epoch 58, change: 0.00488485\n",
            "Epoch 35, change: 0.01076704\n",
            "Epoch 58, change: 0.00558388\n",
            "Epoch 36, change: 0.00924074\n",
            "Epoch 36, change: 0.00932749\n",
            "Epoch 35, change: 0.01162501\n",
            "Epoch 57, change: 0.00517928\n",
            "Epoch 58, change: 0.00394185\n",
            "Epoch 37, change: 0.01119887\n",
            "Epoch 58, change: 0.00409361\n",
            "Epoch 58, change: 0.00443820\n",
            "Epoch 36, change: 0.01073397\n",
            "Epoch 59, change: 0.00477891\n",
            "Epoch 36, change: 0.01039035\n",
            "Epoch 37, change: 0.00911554\n",
            "Epoch 37, change: 0.00884799\n",
            "Epoch 59, change: 0.00546674\n",
            "Epoch 36, change: 0.01133556\n",
            "Epoch 58, change: 0.00503288\n",
            "Epoch 59, change: 0.00383564\n",
            "Epoch 59, change: 0.00396270\n",
            "Epoch 38, change: 0.01083854\n",
            "Epoch 59, change: 0.00429468\n",
            "Epoch 37, change: 0.01031988\n",
            "Epoch 60, change: 0.00465924\n",
            "Epoch 37, change: 0.01006325\n",
            "Epoch 38, change: 0.00878352\n",
            "Epoch 60, change: 0.00537207\n",
            "Epoch 37, change: 0.01090231\n",
            "Epoch 59, change: 0.00492008\n",
            "Epoch 38, change: 0.00868167\n",
            "Epoch 60, change: 0.00375486\n",
            "Epoch 60, change: 0.00387247\n",
            "Epoch 39, change: 0.01060927\n",
            "Epoch 60, change: 0.00415989\n",
            "Epoch 38, change: 0.01014583\n",
            "Epoch 61, change: 0.00457247\n",
            "Epoch 38, change: 0.00990005\n",
            "Epoch 61, change: 0.00528764\n",
            "Epoch 39, change: 0.00856051\n",
            "Epoch 60, change: 0.00481274\n",
            "Epoch 38, change: 0.01072757\n",
            "Epoch 39, change: 0.00839386\n",
            "Epoch 61, change: 0.00368681\n",
            "Epoch 61, change: 0.00376443\n",
            "Epoch 40, change: 0.01027738\n",
            "Epoch 61, change: 0.00403845\n",
            "Epoch 62, change: 0.00448872\n",
            "Epoch 39, change: 0.00988037\n",
            "Epoch 39, change: 0.00955709\n",
            "Epoch 62, change: 0.00520227\n",
            "Epoch 61, change: 0.00467322\n",
            "Epoch 40, change: 0.00843395\n",
            "Epoch 39, change: 0.01039464\n",
            "Epoch 40, change: 0.00829899\n",
            "Epoch 62, change: 0.00355898\n",
            "Epoch 62, change: 0.00364917\n",
            "Epoch 41, change: 0.01003756\n",
            "Epoch 62, change: 0.00392169\n",
            "Epoch 63, change: 0.00440338\n",
            "Epoch 40, change: 0.00969891\n",
            "Epoch 63, change: 0.00512001\n",
            "Epoch 40, change: 0.00939631\n",
            "Epoch 62, change: 0.00454579\n",
            "Epoch 41, change: 0.00813411\n",
            "Epoch 41, change: 0.00808460\n",
            "Epoch 40, change: 0.01013145\n",
            "Epoch 63, change: 0.00344144\n",
            "Epoch 63, change: 0.00352300\n",
            "Epoch 42, change: 0.00980433\n",
            "Epoch 64, change: 0.00432588\n",
            "Epoch 63, change: 0.00380526\n",
            "Epoch 41, change: 0.00945009\n",
            "Epoch 64, change: 0.00496014\n",
            "Epoch 41, change: 0.00901232\n",
            "Epoch 63, change: 0.00430047\n",
            "Epoch 42, change: 0.00794689\n",
            "Epoch 42, change: 0.00782424\n",
            "Epoch 41, change: 0.00983536\n",
            "Epoch 64, change: 0.00343171\n",
            "Epoch 64, change: 0.00336004\n",
            "Epoch 43, change: 0.00955718\n",
            "Epoch 65, change: 0.00424484\n",
            "Epoch 64, change: 0.00369328\n",
            "Epoch 42, change: 0.00928633\n",
            "Epoch 65, change: 0.00486173\n",
            "Epoch 64, change: 0.00421413\n",
            "Epoch 42, change: 0.00882569\n",
            "Epoch 43, change: 0.00780265\n",
            "Epoch 42, change: 0.00965723\n",
            "Epoch 65, change: 0.00332972\n",
            "Epoch 43, change: 0.00759028\n",
            "Epoch 65, change: 0.00324434\n",
            "Epoch 44, change: 0.00924733\n",
            "Epoch 66, change: 0.00417300\n",
            "Epoch 65, change: 0.00361971\n",
            "Epoch 66, change: 0.00477835\n",
            "Epoch 43, change: 0.00910711\n",
            "Epoch 65, change: 0.00409978\n",
            "Epoch 43, change: 0.00858325\n",
            "Epoch 44, change: 0.00759010\n",
            "Epoch 43, change: 0.00944060\n",
            "Epoch 66, change: 0.00325230\n",
            "Epoch 44, change: 0.00743897\n",
            "Epoch 66, change: 0.00317636\n",
            "Epoch 67, change: 0.00409428\n",
            "Epoch 66, change: 0.00354216\n",
            "Epoch 45, change: 0.00898421\n",
            "Epoch 67, change: 0.00469259\n",
            "Epoch 44, change: 0.00886744\n",
            "Epoch 66, change: 0.00396598\n",
            "Epoch 44, change: 0.00842915\n",
            "Epoch 44, change: 0.00914071\n",
            "Epoch 45, change: 0.00744074\n",
            "Epoch 67, change: 0.00314901\n",
            "Epoch 45, change: 0.00732921\n",
            "Epoch 67, change: 0.00311248\n",
            "Epoch 68, change: 0.00401756\n",
            "Epoch 67, change: 0.00344675\n",
            "Epoch 46, change: 0.00879334\n",
            "Epoch 68, change: 0.00459184\n",
            "Epoch 67, change: 0.00390192\n",
            "Epoch 45, change: 0.00873177\n",
            "Epoch 45, change: 0.00816142\n",
            "Epoch 46, change: 0.00717557\n",
            "Epoch 68, change: 0.00306403\n",
            "Epoch 45, change: 0.00895023\n",
            "Epoch 46, change: 0.00706844\n",
            "Epoch 68, change: 0.00302794\n",
            "Epoch 69, change: 0.00394478\n",
            "Epoch 68, change: 0.00336404\n",
            "Epoch 47, change: 0.00855153\n",
            "Epoch 69, change: 0.00449867\n",
            "Epoch 68, change: 0.00383088\n",
            "Epoch 46, change: 0.00852188\n",
            "Epoch 46, change: 0.00801110\n",
            "Epoch 69, change: 0.00299263\n",
            "Epoch 46, change: 0.00869282\n",
            "Epoch 47, change: 0.00703545\n",
            "Epoch 69, change: 0.00293263\n",
            "Epoch 70, change: 0.00387550\n",
            "Epoch 47, change: 0.00694223\n",
            "Epoch 69, change: 0.00329878\n",
            "Epoch 48, change: 0.00839188\n",
            "Epoch 70, change: 0.00441399\n",
            "Epoch 69, change: 0.00367424\n",
            "Epoch 47, change: 0.00830946\n",
            "Epoch 47, change: 0.00785574\n",
            "Epoch 70, change: 0.00291219\n",
            "Epoch 47, change: 0.00851107\n",
            "Epoch 71, change: 0.00380582\n",
            "Epoch 48, change: 0.00690905\n",
            "Epoch 70, change: 0.00285601\n",
            "Epoch 48, change: 0.00676943\n",
            "Epoch 70, change: 0.00321826\n",
            "Epoch 71, change: 0.00433689\n",
            "Epoch 49, change: 0.00813354\n",
            "Epoch 70, change: 0.00358149\n",
            "Epoch 48, change: 0.00820503\n",
            "Epoch 48, change: 0.00766030\n",
            "Epoch 71, change: 0.00282399\n",
            "Epoch 48, change: 0.00826702\n",
            "Epoch 72, change: 0.00373823\n",
            "Epoch 71, change: 0.00280046\n",
            "Epoch 49, change: 0.00678471\n",
            "Epoch 49, change: 0.00664379\n",
            "Epoch 71, change: 0.00312638\n",
            "Epoch 72, change: 0.00425768\n",
            "Epoch 71, change: 0.00349314\n",
            "Epoch 50, change: 0.00799742\n",
            "Epoch 49, change: 0.00802135\n",
            "Epoch 49, change: 0.00734609\n",
            "Epoch 72, change: 0.00277065\n",
            "Epoch 49, change: 0.00814606\n",
            "Epoch 72, change: 0.00272292\n",
            "Epoch 50, change: 0.00652036\n",
            "Epoch 73, change: 0.00367407\n",
            "Epoch 72, change: 0.00304985\n",
            "Epoch 50, change: 0.00643317\n",
            "Epoch 72, change: 0.00342107\n",
            "Epoch 73, change: 0.00417926\n",
            "Epoch 51, change: 0.00762141\n",
            "Epoch 50, change: 0.00785911\n",
            "Epoch 50, change: 0.00726391\n",
            "Epoch 73, change: 0.00269354\n",
            "Epoch 73, change: 0.00265553\n",
            "Epoch 50, change: 0.00790843\n",
            "Epoch 74, change: 0.00361033\n",
            "Epoch 51, change: 0.00647674\n",
            "Epoch 73, change: 0.00298518\n",
            "Epoch 51, change: 0.00634535\n",
            "Epoch 73, change: 0.00334452\n",
            "Epoch 74, change: 0.00409533\n",
            "Epoch 52, change: 0.00746607\n",
            "Epoch 51, change: 0.00769213\n",
            "Epoch 74, change: 0.00261004\n",
            "Epoch 51, change: 0.00710229\n",
            "Epoch 51, change: 0.00776179\n",
            "Epoch 74, change: 0.00256455\n",
            "Epoch 75, change: 0.00354880\n",
            "Epoch 74, change: 0.00291474\n",
            "Epoch 52, change: 0.00630804\n",
            "Epoch 52, change: 0.00617955\n",
            "Epoch 74, change: 0.00325662\n",
            "Epoch 75, change: 0.00401992\n",
            "Epoch 53, change: 0.00725747\n",
            "Epoch 52, change: 0.00757036\n",
            "Epoch 75, change: 0.00253602\n",
            "Epoch 52, change: 0.00694314\n",
            "Epoch 75, change: 0.00249497\n",
            "Epoch 76, change: 0.00349143\n",
            "Epoch 52, change: 0.00758773\n",
            "Epoch 75, change: 0.00285337\n",
            "Epoch 53, change: 0.00612874\n",
            "Epoch 76, change: 0.00395783\n",
            "Epoch 75, change: 0.00316028\n",
            "Epoch 53, change: 0.00607051\n",
            "Epoch 54, change: 0.00702213\n",
            "Epoch 76, change: 0.00249901\n",
            "Epoch 53, change: 0.00738474\n",
            "Epoch 53, change: 0.00678509\n",
            "Epoch 77, change: 0.00343708\n",
            "Epoch 76, change: 0.00245014\n",
            "Epoch 53, change: 0.00741154\n",
            "Epoch 76, change: 0.00278704\n",
            "Epoch 54, change: 0.00596104\n",
            "Epoch 77, change: 0.00388568\n",
            "Epoch 54, change: 0.00591326\n",
            "Epoch 76, change: 0.00307537\n",
            "Epoch 55, change: 0.00680561\n",
            "Epoch 77, change: 0.00242571\n",
            "Epoch 54, change: 0.00728300\n",
            "Epoch 54, change: 0.00667392\n",
            "Epoch 78, change: 0.00336802\n",
            "Epoch 77, change: 0.00238534\n",
            "Epoch 77, change: 0.00272081\n",
            "Epoch 54, change: 0.00722339\n",
            "Epoch 55, change: 0.00593605\n",
            "Epoch 78, change: 0.00379833\n",
            "Epoch 77, change: 0.00300536\n",
            "Epoch 55, change: 0.00583580\n",
            "Epoch 56, change: 0.00666366\n",
            "Epoch 78, change: 0.00236970\n",
            "Epoch 55, change: 0.00713939\n",
            "Epoch 55, change: 0.00644519\n",
            "Epoch 79, change: 0.00330666\n",
            "Epoch 78, change: 0.00233049\n",
            "Epoch 78, change: 0.00266021\n",
            "Epoch 55, change: 0.00713022\n",
            "Epoch 79, change: 0.00373268\n",
            "Epoch 56, change: 0.00581099\n",
            "Epoch 56, change: 0.00571340\n",
            "Epoch 78, change: 0.00295728\n",
            "Epoch 79, change: 0.00231701\n",
            "Epoch 57, change: 0.00647672\n",
            "Epoch 56, change: 0.00699298\n",
            "Epoch 56, change: 0.00632332\n",
            "Epoch 80, change: 0.00325354\n",
            "Epoch 79, change: 0.00228402\n",
            "Epoch 79, change: 0.00261521\n",
            "Epoch 56, change: 0.00679516\n",
            "Epoch 80, change: 0.00365865\n",
            "Epoch 57, change: 0.00561755\n",
            "Epoch 79, change: 0.00288700\n",
            "Epoch 57, change: 0.00555530\n",
            "Epoch 80, change: 0.00225418\n",
            "Epoch 58, change: 0.00636927\n",
            "Epoch 57, change: 0.00687401\n",
            "Epoch 57, change: 0.00613715\n",
            "Epoch 81, change: 0.00320054\n",
            "Epoch 80, change: 0.00220801\n",
            "Epoch 57, change: 0.00670893\n",
            "Epoch 80, change: 0.00254405\n",
            "Epoch 81, change: 0.00359734\n",
            "Epoch 80, change: 0.00280735\n",
            "Epoch 58, change: 0.00548498\n",
            "Epoch 58, change: 0.00543874\n",
            "Epoch 81, change: 0.00219447\n",
            "Epoch 59, change: 0.00617230\n",
            "Epoch 58, change: 0.00676153\n",
            "Epoch 58, change: 0.00608836\n",
            "Epoch 82, change: 0.00314980\n",
            "Epoch 81, change: 0.00213832\n",
            "Epoch 58, change: 0.00652639\n",
            "Epoch 81, change: 0.00249527\n",
            "Epoch 82, change: 0.00354774\n",
            "Epoch 81, change: 0.00273628\n",
            "Epoch 59, change: 0.00528491\n",
            "Epoch 59, change: 0.00540484\n",
            "Epoch 82, change: 0.00216752\n",
            "Epoch 60, change: 0.00604768\n",
            "Epoch 83, change: 0.00309085\n",
            "Epoch 59, change: 0.00595137\n",
            "Epoch 59, change: 0.00662818\n",
            "Epoch 82, change: 0.00209026\n",
            "Epoch 59, change: 0.00633211\n",
            "Epoch 82, change: 0.00243424\n",
            "Epoch 83, change: 0.00348179\n",
            "Epoch 82, change: 0.00266318\n",
            "Epoch 60, change: 0.00523047\n",
            "Epoch 83, change: 0.00211543\n",
            "Epoch 60, change: 0.00531004\n",
            "Epoch 61, change: 0.00594073\n",
            "Epoch 84, change: 0.00303781\n",
            "Epoch 60, change: 0.00577871\n",
            "Epoch 83, change: 0.00203466\n",
            "Epoch 60, change: 0.00644851\n",
            "Epoch 84, change: 0.00341164\n",
            "Epoch 60, change: 0.00619141\n",
            "Epoch 83, change: 0.00237757\n",
            "Epoch 83, change: 0.00261300\n",
            "Epoch 61, change: 0.00512461\n",
            "Epoch 84, change: 0.00205054\n",
            "Epoch 61, change: 0.00519737\n",
            "Epoch 62, change: 0.00580847\n",
            "Epoch 85, change: 0.00298854\n",
            "Epoch 84, change: 0.00198812\n",
            "Epoch 61, change: 0.00570486\n",
            "Epoch 61, change: 0.00637460\n",
            "Epoch 85, change: 0.00333788\n",
            "Epoch 84, change: 0.00232768\n",
            "Epoch 61, change: 0.00600233\n",
            "Epoch 84, change: 0.00254458\n",
            "Epoch 62, change: 0.00502202\n",
            "Epoch 85, change: 0.00200062\n",
            "Epoch 62, change: 0.00510581\n",
            "Epoch 63, change: 0.00568218\n",
            "Epoch 86, change: 0.00293814\n",
            "Epoch 85, change: 0.00194426\n",
            "Epoch 62, change: 0.00554692\n",
            "Epoch 62, change: 0.00623705\n",
            "Epoch 86, change: 0.00328861\n",
            "Epoch 85, change: 0.00227096\n",
            "Epoch 62, change: 0.00583369\n",
            "Epoch 85, change: 0.00246998\n",
            "Epoch 63, change: 0.00491745\n",
            "Epoch 86, change: 0.00196863\n",
            "Epoch 64, change: 0.00556866\n",
            "Epoch 63, change: 0.00499729\n",
            "Epoch 87, change: 0.00289148\n",
            "Epoch 86, change: 0.00189772\n",
            "Epoch 63, change: 0.00614050\n",
            "Epoch 87, change: 0.00323818\n",
            "Epoch 63, change: 0.00545611\n",
            "Epoch 86, change: 0.00222347\n",
            "Epoch 63, change: 0.00573337\n",
            "Epoch 86, change: 0.00242439\n",
            "Epoch 87, change: 0.00190969\n",
            "Epoch 65, change: 0.00548307\n",
            "Epoch 64, change: 0.00481224\n",
            "Epoch 87, change: 0.00184429\n",
            "Epoch 88, change: 0.00284166\n",
            "Epoch 64, change: 0.00490744\n",
            "Epoch 88, change: 0.00318394\n",
            "Epoch 64, change: 0.00597656\n",
            "Epoch 64, change: 0.00537238\n",
            "Epoch 87, change: 0.00217634\n",
            "Epoch 64, change: 0.00556577\n",
            "Epoch 87, change: 0.00237670\n",
            "Epoch 88, change: 0.00187206\n",
            "Epoch 66, change: 0.00539318\n",
            "Epoch 65, change: 0.00472696\n",
            "Epoch 89, change: 0.00279373\n",
            "Epoch 88, change: 0.00179971\n",
            "Epoch 65, change: 0.00479995\n",
            "Epoch 89, change: 0.00311013\n",
            "Epoch 65, change: 0.00590000\n",
            "Epoch 65, change: 0.00522672\n",
            "Epoch 88, change: 0.00212350\n",
            "Epoch 65, change: 0.00541828\n",
            "Epoch 88, change: 0.00233002\n",
            "Epoch 89, change: 0.00182763\n",
            "Epoch 66, change: 0.00463118\n",
            "Epoch 90, change: 0.00274920\n",
            "Epoch 89, change: 0.00175708\n",
            "Epoch 67, change: 0.00530045\n",
            "Epoch 66, change: 0.00472226\n",
            "Epoch 90, change: 0.00304212\n",
            "Epoch 66, change: 0.00578081\n",
            "Epoch 89, change: 0.00207993\n",
            "Epoch 66, change: 0.00520301\n",
            "Epoch 89, change: 0.00228881\n",
            "Epoch 66, change: 0.00530455\n",
            "Epoch 90, change: 0.00177542\n",
            "Epoch 91, change: 0.00270368\n",
            "Epoch 67, change: 0.00452736\n",
            "Epoch 90, change: 0.00171917\n",
            "Epoch 67, change: 0.00461390\n",
            "Epoch 68, change: 0.00519451\n",
            "Epoch 91, change: 0.00299287\n",
            "Epoch 67, change: 0.00560403\n",
            "Epoch 67, change: 0.00511553\n",
            "Epoch 90, change: 0.00203941\n",
            "Epoch 90, change: 0.00224593\n",
            "Epoch 67, change: 0.00517273\n",
            "Epoch 91, change: 0.00173397\n",
            "Epoch 92, change: 0.00266189\n",
            "Epoch 91, change: 0.00168589\n",
            "Epoch 68, change: 0.00448646\n",
            "Epoch 68, change: 0.00454301\n",
            "Epoch 69, change: 0.00508936\n",
            "Epoch 92, change: 0.00293763\n",
            "Epoch 68, change: 0.00553838\n",
            "Epoch 68, change: 0.00503762\n",
            "Epoch 91, change: 0.00199413\n",
            "Epoch 91, change: 0.00220301\n",
            "Epoch 68, change: 0.00503580\n",
            "Epoch 92, change: 0.00170164\n",
            "Epoch 93, change: 0.00262109\n",
            "Epoch 92, change: 0.00164792\n",
            "Epoch 69, change: 0.00440283\n",
            "Epoch 69, change: 0.00446906\n",
            "Epoch 70, change: 0.00500727\n",
            "Epoch 93, change: 0.00288593\n",
            "Epoch 69, change: 0.00539661\n",
            "Epoch 92, change: 0.00194695\n",
            "Epoch 69, change: 0.00496828\n",
            "Epoch 92, change: 0.00216144\n",
            "Epoch 93, change: 0.00166647\n",
            "Epoch 69, change: 0.00491773\n",
            "Epoch 94, change: 0.00258067\n",
            "Epoch 93, change: 0.00161326\n",
            "Epoch 70, change: 0.00429956\n",
            "Epoch 70, change: 0.00445798\n",
            "Epoch 94, change: 0.00283428\n",
            "Epoch 71, change: 0.00493165\n",
            "Epoch 93, change: 0.00190655\n",
            "Epoch 70, change: 0.00490521\n",
            "Epoch 70, change: 0.00533546\n",
            "Epoch 93, change: 0.00212231\n",
            "Epoch 94, change: 0.00162144\n",
            "Epoch 70, change: 0.00478946\n",
            "Epoch 95, change: 0.00253606\n",
            "Epoch 94, change: 0.00158108\n",
            "Epoch 71, change: 0.00437977\n",
            "Epoch 71, change: 0.00421194\n",
            "Epoch 72, change: 0.00484189\n",
            "Epoch 95, change: 0.00278495\n",
            "Epoch 94, change: 0.00186921\n",
            "Epoch 95, change: 0.00159670\n",
            "Epoch 71, change: 0.00484457\n",
            "Epoch 71, change: 0.00520869\n",
            "Epoch 94, change: 0.00208505\n",
            "Epoch 71, change: 0.00465775\n",
            "Epoch 96, change: 0.00249093\n",
            "Epoch 72, change: 0.00432827\n",
            "Epoch 72, change: 0.00413051\n",
            "Epoch 95, change: 0.00154724\n",
            "Epoch 96, change: 0.00273266\n",
            "Epoch 73, change: 0.00474158\n",
            "Epoch 95, change: 0.00182785\n",
            "Epoch 96, change: 0.00156229\n",
            "Epoch 72, change: 0.00476848\n",
            "Epoch 72, change: 0.00510907\n",
            "Epoch 95, change: 0.00204225\n",
            "Epoch 72, change: 0.00458472\n",
            "Epoch 97, change: 0.00245188\n",
            "Epoch 73, change: 0.00426166\n",
            "Epoch 73, change: 0.00407198\n",
            "Epoch 96, change: 0.00151447\n",
            "Epoch 97, change: 0.00268518\n",
            "Epoch 74, change: 0.00466090\n",
            "Epoch 96, change: 0.00178281\n",
            "Epoch 97, change: 0.00152241\n",
            "Epoch 73, change: 0.00504554\n",
            "Epoch 73, change: 0.00470975\n",
            "Epoch 96, change: 0.00200546\n",
            "Epoch 73, change: 0.00445240\n",
            "Epoch 98, change: 0.00241069\n",
            "Epoch 97, change: 0.00147545\n",
            "Epoch 74, change: 0.00421943\n",
            "Epoch 74, change: 0.00399463\n",
            "Epoch 98, change: 0.00263806\n",
            "Epoch 75, change: 0.00458131\n",
            "Epoch 97, change: 0.00174265\n",
            "Epoch 98, change: 0.00148823\n",
            "Epoch 97, change: 0.00196721\n",
            "Epoch 74, change: 0.00466153\n",
            "Epoch 74, change: 0.00491835\n",
            "Epoch 99, change: 0.00237405\n",
            "Epoch 74, change: 0.00436178\n",
            "Epoch 75, change: 0.00418729\n",
            "Epoch 98, change: 0.00144033\n",
            "Epoch 99, change: 0.00259514\n",
            "Epoch 75, change: 0.00390442\n",
            "Epoch 76, change: 0.00452262\n",
            "Epoch 98, change: 0.00171322\n",
            "Epoch 99, change: 0.00146129\n",
            "Epoch 98, change: 0.00193209\n",
            "Epoch 75, change: 0.00484165\n",
            "Epoch 75, change: 0.00458738\n",
            "Epoch 100, change: 0.00233468\n",
            "Epoch 75, change: 0.00425341\n",
            "Epoch 76, change: 0.00410299\n",
            "Epoch 99, change: 0.00141137\n",
            "Epoch 100, change: 0.00254701\n",
            "Epoch 76, change: 0.00384980\n",
            "Epoch 77, change: 0.00442792\n",
            "Epoch 99, change: 0.00168526\n",
            "Epoch 100, change: 0.00143527\n",
            "Epoch 99, change: 0.00189327\n",
            "Epoch 76, change: 0.00474244\n",
            "Epoch 76, change: 0.00453838\n",
            "Epoch 101, change: 0.00229922\n",
            "Epoch 76, change: 0.00418015\n",
            "Epoch 101, change: 0.00249931\n",
            "Epoch 100, change: 0.00138333\n",
            "Epoch 77, change: 0.00406722\n",
            "Epoch 77, change: 0.00379854\n",
            "Epoch 78, change: 0.00437550\n",
            "Epoch 100, change: 0.00163707\n",
            "Epoch 101, change: 0.00139827\n",
            "Epoch 100, change: 0.00185607\n",
            "Epoch 77, change: 0.00466259\n",
            "Epoch 77, change: 0.00447448\n",
            "Epoch 102, change: 0.00226131\n",
            "Epoch 77, change: 0.00409028\n",
            "Epoch 101, change: 0.00135570\n",
            "Epoch 78, change: 0.00400163\n",
            "Epoch 102, change: 0.00245910\n",
            "Epoch 78, change: 0.00373318\n",
            "Epoch 101, change: 0.00160338\n",
            "Epoch 79, change: 0.00426103\n",
            "Epoch 102, change: 0.00137163\n",
            "Epoch 101, change: 0.00181927\n",
            "Epoch 78, change: 0.00457519\n",
            "Epoch 103, change: 0.00222571\n",
            "Epoch 78, change: 0.00441702\n",
            "Epoch 78, change: 0.00395251\n",
            "Epoch 102, change: 0.00132421\n",
            "Epoch 103, change: 0.00241133\n",
            "Epoch 79, change: 0.00393503\n",
            "Epoch 102, change: 0.00156791\n",
            "Epoch 79, change: 0.00364756\n",
            "Epoch 103, change: 0.00133987\n",
            "Epoch 80, change: 0.00422815\n",
            "Epoch 102, change: 0.00178758\n",
            "Epoch 104, change: 0.00219244\n",
            "Epoch 79, change: 0.00451100\n",
            "Epoch 79, change: 0.00437883\n",
            "Epoch 79, change: 0.00388471\n",
            "Epoch 103, change: 0.00129084\n",
            "Epoch 104, change: 0.00236487\n",
            "Epoch 80, change: 0.00390013\n",
            "Epoch 103, change: 0.00153542\n",
            "Epoch 104, change: 0.00131797\n",
            "Epoch 80, change: 0.00360308\n",
            "Epoch 103, change: 0.00175710\n",
            "Epoch 81, change: 0.00415845\n",
            "Epoch 105, change: 0.00215710\n",
            "Epoch 80, change: 0.00442000\n",
            "Epoch 80, change: 0.00431973\n",
            "Epoch 80, change: 0.00382266\n",
            "Epoch 104, change: 0.00126760\n",
            "Epoch 105, change: 0.00232610\n",
            "Epoch 81, change: 0.00383762\n",
            "Epoch 105, change: 0.00129708\n",
            "Epoch 104, change: 0.00150815\n",
            "Epoch 81, change: 0.00352690\n",
            "Epoch 104, change: 0.00172337\n",
            "Epoch 82, change: 0.00411393\n",
            "Epoch 106, change: 0.00212301\n",
            "Epoch 81, change: 0.00434821\n",
            "Epoch 81, change: 0.00427248\n",
            "Epoch 81, change: 0.00374257\n",
            "Epoch 105, change: 0.00124050\n",
            "Epoch 106, change: 0.00228826\n",
            "Epoch 82, change: 0.00381833\n",
            "Epoch 105, change: 0.00147036\n",
            "Epoch 106, change: 0.00127462\n",
            "Epoch 82, change: 0.00345871\n",
            "Epoch 107, change: 0.00209142\n",
            "Epoch 105, change: 0.00168883\n",
            "Epoch 83, change: 0.00405080\n",
            "Epoch 82, change: 0.00418733\n",
            "Epoch 82, change: 0.00427583\n",
            "Epoch 106, change: 0.00121647\n",
            "Epoch 82, change: 0.00364983\n",
            "Epoch 107, change: 0.00225153\n",
            "Epoch 83, change: 0.00376865\n",
            "Epoch 107, change: 0.00124082\n",
            "Epoch 106, change: 0.00143702\n",
            "Epoch 108, change: 0.00205967\n",
            "Epoch 106, change: 0.00165913\n",
            "Epoch 83, change: 0.00341680\n",
            "Epoch 84, change: 0.00399407\n",
            "Epoch 83, change: 0.00414845\n",
            "Epoch 83, change: 0.00420807\n",
            "Epoch 107, change: 0.00119172\n",
            "Epoch 108, change: 0.00221207\n",
            "Epoch 83, change: 0.00355896\n",
            "Epoch 108, change: 0.00122355\n",
            "Epoch 107, change: 0.00141420\n",
            "Epoch 84, change: 0.00372238\n",
            "Epoch 109, change: 0.00202844\n",
            "Epoch 107, change: 0.00162740\n",
            "Epoch 84, change: 0.00335252\n",
            "Epoch 85, change: 0.00387194\n",
            "Epoch 84, change: 0.00410427\n",
            "Epoch 84, change: 0.00409821\n",
            "Epoch 108, change: 0.00116820\n",
            "Epoch 109, change: 0.00216848\n",
            "Epoch 84, change: 0.00348463\n",
            "Epoch 109, change: 0.00120651\n",
            "Epoch 108, change: 0.00138904\n",
            "Epoch 85, change: 0.00367359\n",
            "Epoch 110, change: 0.00199174\n",
            "Epoch 108, change: 0.00159979\n",
            "Epoch 85, change: 0.00330830\n",
            "Epoch 86, change: 0.00386032\n",
            "Epoch 85, change: 0.00405959\n",
            "Epoch 85, change: 0.00405630\n",
            "Epoch 109, change: 0.00114368\n",
            "Epoch 110, change: 0.00213107\n",
            "Epoch 110, change: 0.00118973\n",
            "Epoch 85, change: 0.00344490\n",
            "Epoch 109, change: 0.00136689\n",
            "Epoch 111, change: 0.00196171\n",
            "Epoch 86, change: 0.00361466\n",
            "Epoch 109, change: 0.00157270\n",
            "Epoch 86, change: 0.00324101\n",
            "Epoch 87, change: 0.00379801\n",
            "Epoch 86, change: 0.00400355\n",
            "Epoch 86, change: 0.00396185\n",
            "Epoch 110, change: 0.00111659\n",
            "Epoch 111, change: 0.00209326\n",
            "Epoch 111, change: 0.00117319\n",
            "Epoch 86, change: 0.00335040\n",
            "Epoch 110, change: 0.00134660\n",
            "Epoch 112, change: 0.00193022\n",
            "Epoch 110, change: 0.00153990\n",
            "Epoch 87, change: 0.00360126\n",
            "Epoch 87, change: 0.00318849\n",
            "Epoch 88, change: 0.00371655\n",
            "Epoch 111, change: 0.00109589\n",
            "Epoch 112, change: 0.00205969\n",
            "Epoch 87, change: 0.00396055\n",
            "Epoch 87, change: 0.00392302\n",
            "Epoch 112, change: 0.00115689\n",
            "Epoch 87, change: 0.00326827\n",
            "Epoch 111, change: 0.00132446\n",
            "Epoch 113, change: 0.00189998\n",
            "Epoch 111, change: 0.00151188\n",
            "Epoch 88, change: 0.00353197\n",
            "Epoch 88, change: 0.00311342\n",
            "Epoch 89, change: 0.00367031\n",
            "Epoch 112, change: 0.00107107\n",
            "Epoch 113, change: 0.00202014\n",
            "Epoch 88, change: 0.00384723\n",
            "Epoch 88, change: 0.00392859\n",
            "Epoch 113, change: 0.00114083\n",
            "Epoch 88, change: 0.00318199\n",
            "Epoch 112, change: 0.00130476\n",
            "Epoch 112, change: 0.00148376\n",
            "Epoch 114, change: 0.00187005\n",
            "Epoch 89, change: 0.00308717\n",
            "Epoch 89, change: 0.00347091\n",
            "Epoch 90, change: 0.00360424\n",
            "Epoch 114, change: 0.00198237\n",
            "Epoch 113, change: 0.00104969\n",
            "Epoch 114, change: 0.00112505\n",
            "Epoch 89, change: 0.00386839\n",
            "Epoch 89, change: 0.00375690\n",
            "Epoch 89, change: 0.00314295\n",
            "Epoch 113, change: 0.00128455\n",
            "Epoch 113, change: 0.00145755\n",
            "Epoch 115, change: 0.00184170\n",
            "Epoch 90, change: 0.00345105\n",
            "Epoch 90, change: 0.00302466\n",
            "Epoch 91, change: 0.00355742\n",
            "Epoch 115, change: 0.00195073\n",
            "Epoch 114, change: 0.00102985\n",
            "Epoch 115, change: 0.00110948\n",
            "Epoch 90, change: 0.00381490\n",
            "Epoch 90, change: 0.00371290\n",
            "Epoch 114, change: 0.00126488\n",
            "Epoch 90, change: 0.00307155\n",
            "Epoch 116, change: 0.00181397\n",
            "Epoch 114, change: 0.00143057\n",
            "Epoch 91, change: 0.00340780\n",
            "Epoch 91, change: 0.00297755\n",
            "Epoch 92, change: 0.00348767\n",
            "Epoch 116, change: 0.00191900\n",
            "Epoch 115, change: 0.00101050\n",
            "Epoch 116, change: 0.00109407\n",
            "Epoch 91, change: 0.00378498\n",
            "Epoch 91, change: 0.00362197\n",
            "Epoch 115, change: 0.00124635\n",
            "Epoch 91, change: 0.00302585\n",
            "Epoch 117, change: 0.00178702\n",
            "Epoch 115, change: 0.00140529\n",
            "Epoch 92, change: 0.00337679\n",
            "Epoch 92, change: 0.00293348\n",
            "Epoch 93, change: 0.00346100\n",
            "Epoch 117, change: 0.00187926\n",
            "Epoch 116, change: 0.00098590\n",
            "Epoch 117, change: 0.00107899\n",
            "Epoch 92, change: 0.00375088\n",
            "Epoch 92, change: 0.00357533\n",
            "Epoch 116, change: 0.00122720\n",
            "Epoch 92, change: 0.00293117\n",
            "Epoch 118, change: 0.00175759\n",
            "Epoch 116, change: 0.00137882\n",
            "Epoch 93, change: 0.00288763\n",
            "Epoch 93, change: 0.00332075\n",
            "Epoch 118, change: 0.00184209\n",
            "Epoch 94, change: 0.00338251\n",
            "Epoch 117, change: 0.00096727\n",
            "Epoch 118, change: 0.00106405\n",
            "Epoch 93, change: 0.00368431\n",
            "Epoch 117, change: 0.00120777\n",
            "Epoch 93, change: 0.00348867\n",
            "Epoch 119, change: 0.00172945\n",
            "Epoch 93, change: 0.00289461\n",
            "Epoch 117, change: 0.00135377\n",
            "Epoch 119, change: 0.00181338\n",
            "Epoch 94, change: 0.00284091\n",
            "Epoch 95, change: 0.00334260\n",
            "Epoch 94, change: 0.00330711\n",
            "Epoch 118, change: 0.00094833\n",
            "Epoch 119, change: 0.00104935\n",
            "Epoch 94, change: 0.00366283\n",
            "Epoch 118, change: 0.00119043\n",
            "Epoch 94, change: 0.00344184\n",
            "Epoch 120, change: 0.00170317\n",
            "Epoch 118, change: 0.00132906\n",
            "Epoch 94, change: 0.00282590\n",
            "Epoch 120, change: 0.00178268\n",
            "Epoch 95, change: 0.00279647\n",
            "Epoch 96, change: 0.00328688\n",
            "Epoch 95, change: 0.00323091\n",
            "Epoch 119, change: 0.00092698\n",
            "Epoch 120, change: 0.00103490\n",
            "Epoch 95, change: 0.00362011\n",
            "Epoch 119, change: 0.00117275\n",
            "Epoch 121, change: 0.00167832\n",
            "Epoch 95, change: 0.00338664\n",
            "Epoch 119, change: 0.00130501\n",
            "Epoch 95, change: 0.00278119\n",
            "Epoch 121, change: 0.00175247\n",
            "Epoch 96, change: 0.00274621\n",
            "Epoch 120, change: 0.00090957\n",
            "Epoch 97, change: 0.00325751\n",
            "Epoch 96, change: 0.00320715\n",
            "Epoch 121, change: 0.00102056\n",
            "Epoch 120, change: 0.00115519\n",
            "Epoch 96, change: 0.00359034\n",
            "Epoch 96, change: 0.00330520\n",
            "Epoch 122, change: 0.00165230\n",
            "Epoch 120, change: 0.00128223\n",
            "Epoch 96, change: 0.00271839\n",
            "Epoch 122, change: 0.00171770\n",
            "Epoch 121, change: 0.00089326\n",
            "Epoch 97, change: 0.00270709\n",
            "Epoch 98, change: 0.00317557\n",
            "Epoch 97, change: 0.00316727\n",
            "Epoch 122, change: 0.00100648\n",
            "Epoch 121, change: 0.00113913\n",
            "Epoch 97, change: 0.00354508\n",
            "Epoch 97, change: 0.00326194\n",
            "Epoch 123, change: 0.00162838\n",
            "Epoch 121, change: 0.00125995\n",
            "Epoch 97, change: 0.00266273\n",
            "Epoch 123, change: 0.00169019\n",
            "Epoch 122, change: 0.00087451\n",
            "Epoch 98, change: 0.00266221\n",
            "Epoch 99, change: 0.00316187\n",
            "Epoch 123, change: 0.00099261\n",
            "Epoch 98, change: 0.00310537\n",
            "Epoch 122, change: 0.00112142\n",
            "Epoch 98, change: 0.00348116\n",
            "Epoch 124, change: 0.00160300\n",
            "Epoch 122, change: 0.00123672\n",
            "Epoch 98, change: 0.00318900\n",
            "Epoch 124, change: 0.00165847\n",
            "Epoch 98, change: 0.00261075\n",
            "Epoch 123, change: 0.00085603\n",
            "Epoch 99, change: 0.00262605\n",
            "Epoch 124, change: 0.00097888\n",
            "Epoch 100, change: 0.00310020\n",
            "Epoch 99, change: 0.00308694\n",
            "Epoch 123, change: 0.00110275\n",
            "Epoch 99, change: 0.00346442\n",
            "Epoch 125, change: 0.00157544\n",
            "Epoch 123, change: 0.00121455\n",
            "Epoch 99, change: 0.00313760\n",
            "Epoch 125, change: 0.00162973\n",
            "Epoch 99, change: 0.00256628\n",
            "Epoch 124, change: 0.00083994\n",
            "Epoch 125, change: 0.00096539\n",
            "Epoch 100, change: 0.00257801\n",
            "Epoch 101, change: 0.00304897\n",
            "Epoch 100, change: 0.00304405\n",
            "Epoch 124, change: 0.00108550\n",
            "Epoch 100, change: 0.00341505\n",
            "Epoch 126, change: 0.00155102\n",
            "Epoch 124, change: 0.00119357\n",
            "Epoch 126, change: 0.00159466\n",
            "Epoch 100, change: 0.00309459\n",
            "Epoch 100, change: 0.00252431\n",
            "Epoch 125, change: 0.00082735\n",
            "Epoch 126, change: 0.00095214\n",
            "Epoch 101, change: 0.00253906\n",
            "Epoch 102, change: 0.00302913\n",
            "Epoch 101, change: 0.00300762\n",
            "Epoch 125, change: 0.00106935\n",
            "Epoch 101, change: 0.00338278\n",
            "Epoch 127, change: 0.00152815\n",
            "Epoch 125, change: 0.00117126\n",
            "Epoch 127, change: 0.00156359\n",
            "Epoch 101, change: 0.00302150\n",
            "Epoch 101, change: 0.00246146\n",
            "Epoch 126, change: 0.00081517\n",
            "Epoch 127, change: 0.00093905\n",
            "Epoch 102, change: 0.00249855\n",
            "Epoch 103, change: 0.00295775\n",
            "Epoch 102, change: 0.00298271\n",
            "Epoch 126, change: 0.00105342\n",
            "Epoch 128, change: 0.00150471\n",
            "Epoch 102, change: 0.00335046\n",
            "Epoch 126, change: 0.00115142\n",
            "Epoch 128, change: 0.00153475\n",
            "Epoch 102, change: 0.00298364\n",
            "Epoch 102, change: 0.00242608\n",
            "Epoch 127, change: 0.00080315\n",
            "Epoch 128, change: 0.00092609\n",
            "Epoch 103, change: 0.00245288\n",
            "Epoch 127, change: 0.00103630\n",
            "Epoch 104, change: 0.00293702\n",
            "Epoch 103, change: 0.00293044\n",
            "Epoch 129, change: 0.00148220\n",
            "Epoch 127, change: 0.00112982\n",
            "Epoch 103, change: 0.00331415\n",
            "Epoch 129, change: 0.00150530\n",
            "Epoch 103, change: 0.00293964\n",
            "Epoch 103, change: 0.00236533\n",
            "Epoch 128, change: 0.00079125\n",
            "Epoch 129, change: 0.00091337\n",
            "Epoch 104, change: 0.00243210\n",
            "Epoch 128, change: 0.00102036\n",
            "Epoch 105, change: 0.00288828\n",
            "Epoch 104, change: 0.00289062\n",
            "Epoch 130, change: 0.00145907\n",
            "Epoch 128, change: 0.00110948\n",
            "Epoch 130, change: 0.00147821\n",
            "Epoch 104, change: 0.00328225\n",
            "Epoch 104, change: 0.00288134\n",
            "Epoch 129, change: 0.00077962\n",
            "Epoch 104, change: 0.00231945\n",
            "Epoch 130, change: 0.00090081\n",
            "Epoch 105, change: 0.00239707\n",
            "Epoch 129, change: 0.00100527\n",
            "Epoch 106, change: 0.00284123\n",
            "Epoch 131, change: 0.00143719\n",
            "Epoch 105, change: 0.00288237\n",
            "Epoch 131, change: 0.00145085\n",
            "Epoch 129, change: 0.00109131\n",
            "Epoch 105, change: 0.00324042\n",
            "Epoch 105, change: 0.00283963\n",
            "Epoch 130, change: 0.00076819\n",
            "Epoch 105, change: 0.00228574\n",
            "Epoch 131, change: 0.00088844\n",
            "Epoch 106, change: 0.00234726\n",
            "Epoch 130, change: 0.00099054\n",
            "Epoch 107, change: 0.00280344\n",
            "Epoch 132, change: 0.00141502\n",
            "Epoch 106, change: 0.00282854\n",
            "Epoch 132, change: 0.00142355\n",
            "Epoch 130, change: 0.00107339\n",
            "Epoch 106, change: 0.00321194\n",
            "Epoch 106, change: 0.00278549\n",
            "Epoch 131, change: 0.00075689\n",
            "Epoch 106, change: 0.00224145\n",
            "Epoch 132, change: 0.00087628\n",
            "Epoch 131, change: 0.00097525\n",
            "Epoch 107, change: 0.00232083\n",
            "Epoch 108, change: 0.00276425\n",
            "Epoch 133, change: 0.00139380\n",
            "Epoch 107, change: 0.00278948\n",
            "Epoch 133, change: 0.00139494\n",
            "Epoch 131, change: 0.00105438\n",
            "Epoch 107, change: 0.00317672\n",
            "Epoch 107, change: 0.00273248\n",
            "Epoch 132, change: 0.00074580\n",
            "Epoch 133, change: 0.00086421\n",
            "Epoch 107, change: 0.00218996\n",
            "Epoch 132, change: 0.00096118\n",
            "Epoch 108, change: 0.00228822\n",
            "Epoch 134, change: 0.00137322\n",
            "Epoch 109, change: 0.00271683\n",
            "Epoch 134, change: 0.00136876\n",
            "Epoch 108, change: 0.00276187\n",
            "Epoch 132, change: 0.00103367\n",
            "Epoch 108, change: 0.00314064\n",
            "Epoch 108, change: 0.00269161\n",
            "Epoch 133, change: 0.00073485\n",
            "Epoch 134, change: 0.00085235\n",
            "Epoch 108, change: 0.00214265\n",
            "Epoch 133, change: 0.00094656\n",
            "Epoch 109, change: 0.00226528\n",
            "Epoch 135, change: 0.00135203\n",
            "Epoch 135, change: 0.00133961\n",
            "Epoch 110, change: 0.00269600\n",
            "Epoch 133, change: 0.00101435\n",
            "Epoch 109, change: 0.00273093\n",
            "Epoch 109, change: 0.00310915\n",
            "Epoch 134, change: 0.00072395\n",
            "Epoch 109, change: 0.00265792\n",
            "Epoch 135, change: 0.00084066\n",
            "Epoch 109, change: 0.00211017\n",
            "Epoch 134, change: 0.00093162\n",
            "Epoch 110, change: 0.00219538\n",
            "Epoch 136, change: 0.00133164\n",
            "Epoch 136, change: 0.00131665\n",
            "Epoch 111, change: 0.00265738\n",
            "Epoch 134, change: 0.00099623\n",
            "Epoch 110, change: 0.00269077\n",
            "Epoch 110, change: 0.00307711\n",
            "Epoch 135, change: 0.00071335\n",
            "Epoch 136, change: 0.00082917\n",
            "Epoch 110, change: 0.00261853\n",
            "Epoch 110, change: 0.00206970\n",
            "Epoch 135, change: 0.00091759\n",
            "Epoch 111, change: 0.00218757\n",
            "Epoch 137, change: 0.00131239\n",
            "Epoch 137, change: 0.00129472\n",
            "Epoch 135, change: 0.00097983\n",
            "Epoch 112, change: 0.00262379\n",
            "Epoch 111, change: 0.00264885\n",
            "Epoch 111, change: 0.00305031\n",
            "Epoch 136, change: 0.00070285\n",
            "Epoch 137, change: 0.00081786\n",
            "Epoch 111, change: 0.00255308\n",
            "Epoch 136, change: 0.00090502\n",
            "Epoch 111, change: 0.00203110\n",
            "Epoch 138, change: 0.00126992\n",
            "Epoch 138, change: 0.00129118\n",
            "Epoch 112, change: 0.00214398\n",
            "Epoch 136, change: 0.00096084\n",
            "Epoch 113, change: 0.00257907\n",
            "Epoch 112, change: 0.00263463\n",
            "Epoch 137, change: 0.00069255\n",
            "Epoch 112, change: 0.00301136\n",
            "Epoch 138, change: 0.00080659\n",
            "Epoch 137, change: 0.00089174\n",
            "Epoch 112, change: 0.00251956\n",
            "Epoch 112, change: 0.00199592\n",
            "Epoch 139, change: 0.00124584\n",
            "Epoch 113, change: 0.00212015\n",
            "Epoch 139, change: 0.00127212\n",
            "Epoch 137, change: 0.00094399\n",
            "Epoch 114, change: 0.00254053\n",
            "Epoch 113, change: 0.00260749\n",
            "Epoch 138, change: 0.00068240\n",
            "Epoch 113, change: 0.00298823\n",
            "Epoch 139, change: 0.00079554\n",
            "Epoch 138, change: 0.00087951\n",
            "Epoch 113, change: 0.00247859\n",
            "Epoch 113, change: 0.00195768\n",
            "Epoch 140, change: 0.00122168\n",
            "Epoch 140, change: 0.00125418\n",
            "Epoch 114, change: 0.00208017\n",
            "Epoch 138, change: 0.00092814\n",
            "Epoch 115, change: 0.00251431\n",
            "Epoch 114, change: 0.00257079\n",
            "Epoch 139, change: 0.00067242\n",
            "Epoch 114, change: 0.00295666\n",
            "Epoch 140, change: 0.00078466\n",
            "Epoch 139, change: 0.00086518\n",
            "Epoch 114, change: 0.00243443\n",
            "Epoch 141, change: 0.00120063\n",
            "Epoch 114, change: 0.00195637\n",
            "Epoch 141, change: 0.00123410\n",
            "Epoch 115, change: 0.00205678\n",
            "Epoch 139, change: 0.00091309\n",
            "Epoch 116, change: 0.00249247\n",
            "Epoch 140, change: 0.00066258\n",
            "Epoch 115, change: 0.00252524\n",
            "Epoch 141, change: 0.00077392\n",
            "Epoch 115, change: 0.00293505\n",
            "Epoch 140, change: 0.00085286\n",
            "Epoch 142, change: 0.00117765\n",
            "Epoch 142, change: 0.00121472\n",
            "Epoch 115, change: 0.00241302\n",
            "Epoch 115, change: 0.00191923\n",
            "Epoch 116, change: 0.00202139\n",
            "Epoch 140, change: 0.00089547\n",
            "Epoch 117, change: 0.00245306\n",
            "Epoch 141, change: 0.00065288\n",
            "Epoch 116, change: 0.00251294\n",
            "Epoch 142, change: 0.00076334\n",
            "Epoch 141, change: 0.00084094\n",
            "Epoch 116, change: 0.00289089\n",
            "Epoch 143, change: 0.00115393\n",
            "Epoch 143, change: 0.00119672\n",
            "Epoch 116, change: 0.00236253\n",
            "Epoch 116, change: 0.00189133\n",
            "Epoch 117, change: 0.00199699\n",
            "Epoch 141, change: 0.00087914\n",
            "Epoch 118, change: 0.00242334\n",
            "Epoch 142, change: 0.00064337\n",
            "Epoch 117, change: 0.00246149\n",
            "Epoch 143, change: 0.00075292\n",
            "Epoch 117, change: 0.00286864\n",
            "Epoch 142, change: 0.00082442\n",
            "Epoch 144, change: 0.00113513\n",
            "Epoch 144, change: 0.00117852\n",
            "Epoch 117, change: 0.00232600\n",
            "Epoch 117, change: 0.00186646\n",
            "Epoch 142, change: 0.00086450\n",
            "Epoch 118, change: 0.00196154\n",
            "Epoch 119, change: 0.00237895\n",
            "Epoch 143, change: 0.00063399\n",
            "Epoch 144, change: 0.00074261\n",
            "Epoch 118, change: 0.00243111\n",
            "Epoch 145, change: 0.00111213\n",
            "Epoch 118, change: 0.00283472\n",
            "Epoch 143, change: 0.00081212\n",
            "Epoch 145, change: 0.00116164\n",
            "Epoch 118, change: 0.00228606\n",
            "Epoch 143, change: 0.00085058\n",
            "Epoch 118, change: 0.00184277\n",
            "Epoch 119, change: 0.00194523\n",
            "Epoch 120, change: 0.00233775\n",
            "Epoch 144, change: 0.00062476\n",
            "Epoch 145, change: 0.00073246\n",
            "Epoch 119, change: 0.00241167\n",
            "Epoch 146, change: 0.00109341\n",
            "Epoch 144, change: 0.00080067\n",
            "Epoch 146, change: 0.00114487\n",
            "Epoch 119, change: 0.00281210\n",
            "Epoch 119, change: 0.00225600\n",
            "Epoch 144, change: 0.00083491\n",
            "Epoch 119, change: 0.00181147\n",
            "Epoch 120, change: 0.00191413\n",
            "Epoch 145, change: 0.00061555\n",
            "Epoch 121, change: 0.00231415\n",
            "Epoch 146, change: 0.00072245\n",
            "Epoch 120, change: 0.00239053\n",
            "Epoch 147, change: 0.00107405\n",
            "Epoch 145, change: 0.00078821\n",
            "Epoch 147, change: 0.00112756\n",
            "Epoch 120, change: 0.00279137\n",
            "Epoch 120, change: 0.00221977\n",
            "Epoch 145, change: 0.00081899\n",
            "Epoch 120, change: 0.00178209\n",
            "Epoch 121, change: 0.00188467\n",
            "Epoch 146, change: 0.00060657\n",
            "Epoch 147, change: 0.00071259\n",
            "Epoch 122, change: 0.00229376\n",
            "Epoch 121, change: 0.00236044\n",
            "Epoch 148, change: 0.00105156\n",
            "Epoch 146, change: 0.00077567\n",
            "Epoch 148, change: 0.00111044\n",
            "Epoch 121, change: 0.00277013\n",
            "Epoch 121, change: 0.00217444\n",
            "Epoch 146, change: 0.00080477\n",
            "Epoch 121, change: 0.00176534\n",
            "Epoch 122, change: 0.00185599\n",
            "Epoch 148, change: 0.00070287\n",
            "Epoch 147, change: 0.00059770\n",
            "Epoch 123, change: 0.00223910\n",
            "Epoch 149, change: 0.00103224\n",
            "Epoch 122, change: 0.00232258\n",
            "Epoch 149, change: 0.00109398\n",
            "Epoch 147, change: 0.00076513\n",
            "Epoch 122, change: 0.00271729\n",
            "Epoch 122, change: 0.00215204\n",
            "Epoch 147, change: 0.00079109\n",
            "Epoch 122, change: 0.00173906\n",
            "Epoch 123, change: 0.00182782\n",
            "Epoch 149, change: 0.00069328\n",
            "Epoch 148, change: 0.00058900\n",
            "Epoch 124, change: 0.00221865\n",
            "Epoch 123, change: 0.00229319\n",
            "Epoch 150, change: 0.00101261\n",
            "Epoch 150, change: 0.00107730\n",
            "Epoch 148, change: 0.00075367\n",
            "Epoch 123, change: 0.00270146\n",
            "Epoch 123, change: 0.00212288\n",
            "Epoch 148, change: 0.00077778\n",
            "Epoch 123, change: 0.00171667\n",
            "Epoch 124, change: 0.00179516\n",
            "Epoch 150, change: 0.00068382\n",
            "Epoch 149, change: 0.00058043\n",
            "Epoch 125, change: 0.00219447\n",
            "Epoch 149, change: 0.00074176\n",
            "Epoch 151, change: 0.00106151\n",
            "Epoch 151, change: 0.00099601\n",
            "Epoch 124, change: 0.00227040\n",
            "Epoch 124, change: 0.00267191\n",
            "Epoch 124, change: 0.00207732\n",
            "Epoch 149, change: 0.00076297\n",
            "Epoch 124, change: 0.00170005\n",
            "Epoch 151, change: 0.00067450\n",
            "Epoch 125, change: 0.00177887\n",
            "Epoch 150, change: 0.00057199\n",
            "Epoch 126, change: 0.00216709\n",
            "Epoch 150, change: 0.00073065\n",
            "Epoch 152, change: 0.00097907\n",
            "Epoch 152, change: 0.00104465\n",
            "Epoch 125, change: 0.00223380\n",
            "Epoch 125, change: 0.00265207\n",
            "Epoch 150, change: 0.00075010\n",
            "Epoch 125, change: 0.00205244\n",
            "Epoch 152, change: 0.00066529\n",
            "Epoch 125, change: 0.00167074\n",
            "Epoch 151, change: 0.00056364\n",
            "Epoch 126, change: 0.00173898\n",
            "Epoch 127, change: 0.00214099\n",
            "Epoch 151, change: 0.00071938\n",
            "Epoch 153, change: 0.00095986\n",
            "Epoch 153, change: 0.00102984\n",
            "Epoch 126, change: 0.00221649\n",
            "Epoch 126, change: 0.00262552\n",
            "Epoch 151, change: 0.00073678\n",
            "Epoch 153, change: 0.00065622\n",
            "Epoch 126, change: 0.00202171\n",
            "Epoch 126, change: 0.00165286\n",
            "Epoch 152, change: 0.00055542\n",
            "Epoch 127, change: 0.00172913\n",
            "Epoch 128, change: 0.00211219\n",
            "Epoch 152, change: 0.00070862\n",
            "Epoch 154, change: 0.00094506\n",
            "Epoch 154, change: 0.00101502\n",
            "Epoch 127, change: 0.00218032\n",
            "Epoch 127, change: 0.00259591\n",
            "Epoch 152, change: 0.00072374\n",
            "Epoch 154, change: 0.00064730\n",
            "Epoch 127, change: 0.00199913\n",
            "Epoch 127, change: 0.00164160\n",
            "Epoch 153, change: 0.00054734\n",
            "Epoch 128, change: 0.00170094\n",
            "Epoch 129, change: 0.00207818\n",
            "Epoch 155, change: 0.00100045\n",
            "Epoch 153, change: 0.00069837\n",
            "Epoch 155, change: 0.00092541\n",
            "Epoch 128, change: 0.00214761\n",
            "Epoch 155, change: 0.00063846\n",
            "Epoch 128, change: 0.00256948\n",
            "Epoch 153, change: 0.00071174\n",
            "Epoch 128, change: 0.00196547\n",
            "Epoch 128, change: 0.00160077\n",
            "Epoch 154, change: 0.00053935\n",
            "Epoch 129, change: 0.00167533\n",
            "Epoch 156, change: 0.00098350\n",
            "Epoch 154, change: 0.00068738\n",
            "Epoch 156, change: 0.00090698\n",
            "Epoch 130, change: 0.00205691\n",
            "Epoch 129, change: 0.00212882\n",
            "Epoch 129, change: 0.00254172\n",
            "Epoch 156, change: 0.00062976\n",
            "Epoch 154, change: 0.00069904\n",
            "Epoch 129, change: 0.00192814\n",
            "Epoch 129, change: 0.00159131\n",
            "Epoch 155, change: 0.00053152\n",
            "Epoch 157, change: 0.00089108\n",
            "Epoch 157, change: 0.00096909\n",
            "Epoch 155, change: 0.00067792\n",
            "Epoch 130, change: 0.00165857\n",
            "Epoch 131, change: 0.00202242\n",
            "Epoch 130, change: 0.00208646\n",
            "Epoch 155, change: 0.00068737\n",
            "Epoch 130, change: 0.00252348\n",
            "Epoch 157, change: 0.00062119\n",
            "Epoch 130, change: 0.00189699\n",
            "Epoch 130, change: 0.00157111\n",
            "Epoch 156, change: 0.00052383\n",
            "Epoch 158, change: 0.00087530\n",
            "Epoch 158, change: 0.00095509\n",
            "Epoch 156, change: 0.00066805\n",
            "Epoch 131, change: 0.00163254\n",
            "Epoch 132, change: 0.00200232\n",
            "Epoch 131, change: 0.00207446\n",
            "Epoch 156, change: 0.00067508\n",
            "Epoch 158, change: 0.00061275\n",
            "Epoch 131, change: 0.00249659\n",
            "Epoch 131, change: 0.00155148\n",
            "Epoch 131, change: 0.00186507\n",
            "Epoch 157, change: 0.00051626\n",
            "Epoch 159, change: 0.00085967\n",
            "Epoch 159, change: 0.00094042\n",
            "Epoch 157, change: 0.00065711\n",
            "Epoch 132, change: 0.00160295\n",
            "Epoch 133, change: 0.00198201\n",
            "Epoch 132, change: 0.00204886\n",
            "Epoch 159, change: 0.00060440\n",
            "Epoch 157, change: 0.00066307\n",
            "Epoch 132, change: 0.00247141\n",
            "Epoch 132, change: 0.00152971\n",
            "Epoch 158, change: 0.00050873\n",
            "Epoch 132, change: 0.00184385\n",
            "Epoch 160, change: 0.00084374\n",
            "Epoch 158, change: 0.00064733\n",
            "Epoch 160, change: 0.00092650\n",
            "Epoch 133, change: 0.00159085\n",
            "Epoch 134, change: 0.00196496\n",
            "Epoch 160, change: 0.00059618\n",
            "Epoch 158, change: 0.00065198\n",
            "Epoch 133, change: 0.00202183\n",
            "Epoch 133, change: 0.00244653\n",
            "Epoch 159, change: 0.00050125\n",
            "Epoch 133, change: 0.00150337\n",
            "Epoch 161, change: 0.00082662\n",
            "Epoch 159, change: 0.00063727\n",
            "Epoch 133, change: 0.00182141\n",
            "Epoch 161, change: 0.00091262\n",
            "Epoch 134, change: 0.00156358\n",
            "Epoch 135, change: 0.00194785\n",
            "Epoch 161, change: 0.00058806\n",
            "Epoch 159, change: 0.00064003\n",
            "Epoch 134, change: 0.00199748\n",
            "Epoch 134, change: 0.00242636\n",
            "Epoch 162, change: 0.00081283\n",
            "Epoch 160, change: 0.00049399\n",
            "Epoch 134, change: 0.00148615\n",
            "Epoch 134, change: 0.00178592\n",
            "Epoch 160, change: 0.00062809\n",
            "Epoch 162, change: 0.00089899\n",
            "Epoch 135, change: 0.00153687\n",
            "Epoch 136, change: 0.00192668\n",
            "Epoch 162, change: 0.00058005\n",
            "Epoch 160, change: 0.00062940\n",
            "Epoch 135, change: 0.00240514\n",
            "Epoch 135, change: 0.00195837\n",
            "Epoch 161, change: 0.00048683\n",
            "Epoch 163, change: 0.00079951\n",
            "Epoch 135, change: 0.00147418\n",
            "Epoch 161, change: 0.00061891\n",
            "Epoch 163, change: 0.00088596\n",
            "Epoch 135, change: 0.00176404\n",
            "Epoch 136, change: 0.00152588\n",
            "Epoch 137, change: 0.00191209\n",
            "Epoch 163, change: 0.00057217\n",
            "Epoch 161, change: 0.00061833\n",
            "Epoch 136, change: 0.00192522\n",
            "Epoch 136, change: 0.00238064\n",
            "Epoch 164, change: 0.00078444\n",
            "Epoch 162, change: 0.00047974\n",
            "Epoch 162, change: 0.00060854\n",
            "Epoch 164, change: 0.00087322\n",
            "Epoch 136, change: 0.00145670\n",
            "Epoch 136, change: 0.00173363\n",
            "Epoch 137, change: 0.00150298\n",
            "Epoch 138, change: 0.00189321\n",
            "Epoch 164, change: 0.00056439\n",
            "Epoch 162, change: 0.00060808\n",
            "Epoch 137, change: 0.00235777\n",
            "Epoch 137, change: 0.00191797\n",
            "Epoch 165, change: 0.00077035\n",
            "Epoch 163, change: 0.00047278\n",
            "Epoch 163, change: 0.00059992\n",
            "Epoch 165, change: 0.00086081\n",
            "Epoch 137, change: 0.00142983\n",
            "Epoch 137, change: 0.00170969\n",
            "Epoch 138, change: 0.00147570\n",
            "Epoch 165, change: 0.00055671\n",
            "Epoch 139, change: 0.00187992\n",
            "Epoch 163, change: 0.00059754\n",
            "Epoch 138, change: 0.00232859\n",
            "Epoch 138, change: 0.00189036\n",
            "Epoch 166, change: 0.00075615\n",
            "Epoch 164, change: 0.00046594\n",
            "Epoch 166, change: 0.00084761\n",
            "Epoch 164, change: 0.00059099\n",
            "Epoch 138, change: 0.00168230\n",
            "Epoch 138, change: 0.00141573\n",
            "Epoch 139, change: 0.00146265\n",
            "Epoch 166, change: 0.00054918\n",
            "Epoch 140, change: 0.00185957\n",
            "Epoch 164, change: 0.00058650\n",
            "Epoch 139, change: 0.00231504\n",
            "Epoch 167, change: 0.00074356\n",
            "Epoch 139, change: 0.00186876\n",
            "Epoch 165, change: 0.00045918\n",
            "Epoch 167, change: 0.00083432\n",
            "Epoch 165, change: 0.00058135\n",
            "Epoch 139, change: 0.00165962\n",
            "Epoch 140, change: 0.00143877\n",
            "Epoch 139, change: 0.00139514\n",
            "Epoch 167, change: 0.00054174\n",
            "Epoch 141, change: 0.00184295\n",
            "Epoch 165, change: 0.00057641\n",
            "Epoch 140, change: 0.00228975\n",
            "Epoch 168, change: 0.00072882\n",
            "Epoch 140, change: 0.00183508\n",
            "Epoch 166, change: 0.00045249\n",
            "Epoch 166, change: 0.00057283\n",
            "Epoch 168, change: 0.00082208\n",
            "Epoch 140, change: 0.00163541\n",
            "Epoch 141, change: 0.00141537\n",
            "Epoch 140, change: 0.00137782\n",
            "Epoch 168, change: 0.00053433\n",
            "Epoch 142, change: 0.00182705\n",
            "Epoch 166, change: 0.00056617\n",
            "Epoch 141, change: 0.00227255\n",
            "Epoch 169, change: 0.00071635\n",
            "Epoch 167, change: 0.00044596\n",
            "Epoch 141, change: 0.00181471\n",
            "Epoch 167, change: 0.00056451\n",
            "Epoch 169, change: 0.00081010\n",
            "Epoch 141, change: 0.00161217\n",
            "Epoch 142, change: 0.00140203\n",
            "Epoch 169, change: 0.00052708\n",
            "Epoch 141, change: 0.00136074\n",
            "Epoch 167, change: 0.00055685\n",
            "Epoch 143, change: 0.00181068\n",
            "Epoch 170, change: 0.00070417\n",
            "Epoch 142, change: 0.00225091\n",
            "Epoch 168, change: 0.00043948\n",
            "Epoch 142, change: 0.00179574\n",
            "Epoch 168, change: 0.00055595\n",
            "Epoch 170, change: 0.00079787\n",
            "Epoch 170, change: 0.00051993\n",
            "Epoch 142, change: 0.00158863\n",
            "Epoch 143, change: 0.00138248\n",
            "Epoch 142, change: 0.00134822\n",
            "Epoch 168, change: 0.00054745\n",
            "Epoch 144, change: 0.00179664\n",
            "Epoch 171, change: 0.00068987\n",
            "Epoch 143, change: 0.00221988\n",
            "Epoch 169, change: 0.00043308\n",
            "Epoch 169, change: 0.00054819\n",
            "Epoch 171, change: 0.00078611\n",
            "Epoch 143, change: 0.00177581\n",
            "Epoch 171, change: 0.00051284\n",
            "Epoch 143, change: 0.00156625\n",
            "Epoch 143, change: 0.00132915\n",
            "Epoch 144, change: 0.00136585\n",
            "Epoch 169, change: 0.00053885\n",
            "Epoch 172, change: 0.00067801\n",
            "Epoch 145, change: 0.00178211\n",
            "Epoch 144, change: 0.00220761\n",
            "Epoch 170, change: 0.00042681\n",
            "Epoch 170, change: 0.00054003\n",
            "Epoch 172, change: 0.00077451\n",
            "Epoch 144, change: 0.00174648\n",
            "Epoch 172, change: 0.00050589\n",
            "Epoch 144, change: 0.00154461\n",
            "Epoch 144, change: 0.00131443\n",
            "Epoch 170, change: 0.00052813\n",
            "Epoch 145, change: 0.00133672\n",
            "Epoch 173, change: 0.00066619\n",
            "Epoch 146, change: 0.00176352\n",
            "Epoch 145, change: 0.00218638\n",
            "Epoch 171, change: 0.00042062\n",
            "Epoch 173, change: 0.00076321\n",
            "Epoch 171, change: 0.00053163\n",
            "Epoch 145, change: 0.00171989\n",
            "Epoch 173, change: 0.00049902\n",
            "Epoch 145, change: 0.00151940\n",
            "Epoch 145, change: 0.00129833\n",
            "Epoch 171, change: 0.00051897\n",
            "Epoch 146, change: 0.00132810\n",
            "Epoch 174, change: 0.00065394\n",
            "Epoch 147, change: 0.00174807\n",
            "Epoch 146, change: 0.00216974\n",
            "Epoch 172, change: 0.00041453\n",
            "Epoch 174, change: 0.00075175\n",
            "Epoch 172, change: 0.00052320\n",
            "Epoch 146, change: 0.00171004\n",
            "Epoch 174, change: 0.00049226\n",
            "Epoch 146, change: 0.00150458\n",
            "Epoch 146, change: 0.00127890\n",
            "Epoch 172, change: 0.00051055\n",
            "Epoch 175, change: 0.00064162\n",
            "Epoch 147, change: 0.00131275\n",
            "Epoch 148, change: 0.00173268\n",
            "Epoch 173, change: 0.00040853\n",
            "Epoch 147, change: 0.00214373\n",
            "Epoch 175, change: 0.00074092\n",
            "Epoch 173, change: 0.00051595\n",
            "Epoch 147, change: 0.00168183\n",
            "Epoch 175, change: 0.00048556\n",
            "Epoch 147, change: 0.00148190\n",
            "Epoch 173, change: 0.00050156\n",
            "Epoch 147, change: 0.00126863\n",
            "Epoch 176, change: 0.00063082\n",
            "Epoch 148, change: 0.00128712\n",
            "Epoch 174, change: 0.00040264\n",
            "Epoch 176, change: 0.00073018\n",
            "Epoch 149, change: 0.00171892\n",
            "Epoch 148, change: 0.00212830\n",
            "Epoch 174, change: 0.00050789\n",
            "Epoch 148, change: 0.00166414\n",
            "Epoch 176, change: 0.00047899\n",
            "Epoch 174, change: 0.00049273\n",
            "Epoch 148, change: 0.00146897\n",
            "Epoch 148, change: 0.00125265\n",
            "Epoch 177, change: 0.00062095\n",
            "Epoch 149, change: 0.00127047\n",
            "Epoch 175, change: 0.00039684\n",
            "Epoch 177, change: 0.00071931\n",
            "Epoch 150, change: 0.00170527\n",
            "Epoch 175, change: 0.00050019\n",
            "Epoch 149, change: 0.00210268\n",
            "Epoch 177, change: 0.00047248\n",
            "Epoch 149, change: 0.00163925\n",
            "Epoch 175, change: 0.00048469\n",
            "Epoch 149, change: 0.00123537\n",
            "Epoch 149, change: 0.00144932\n",
            "Epoch 178, change: 0.00061024\n",
            "Epoch 150, change: 0.00125515\n",
            "Epoch 176, change: 0.00039113\n",
            "Epoch 178, change: 0.00070838\n",
            "Epoch 176, change: 0.00049296\n",
            "Epoch 151, change: 0.00169084\n",
            "Epoch 150, change: 0.00208697\n",
            "Epoch 178, change: 0.00046607\n",
            "Epoch 150, change: 0.00161698\n",
            "Epoch 176, change: 0.00047610\n",
            "Epoch 150, change: 0.00143488\n",
            "Epoch 179, change: 0.00059846\n",
            "Epoch 150, change: 0.00122454\n",
            "Epoch 177, change: 0.00038537\n",
            "Epoch 179, change: 0.00069801\n",
            "Epoch 151, change: 0.00123549\n",
            "Epoch 177, change: 0.00048554\n",
            "Epoch 152, change: 0.00167182\n",
            "Epoch 151, change: 0.00207022\n",
            "Epoch 179, change: 0.00045975\n",
            "Epoch 151, change: 0.00161489\n",
            "Epoch 177, change: 0.00046779\n",
            "Epoch 180, change: 0.00058729\n",
            "Epoch 151, change: 0.00141824\n",
            "Epoch 151, change: 0.00120882\n",
            "Epoch 178, change: 0.00037982\n",
            "Epoch 180, change: 0.00068741\n",
            "Epoch 178, change: 0.00047830\n",
            "Epoch 152, change: 0.00122704\n",
            "Epoch 153, change: 0.00165915\n",
            "Epoch 152, change: 0.00204859\n",
            "Epoch 180, change: 0.00045350\n",
            "Epoch 178, change: 0.00045966\n",
            "Epoch 152, change: 0.00158078\n",
            "Epoch 152, change: 0.00140814\n",
            "Epoch 181, change: 0.00057597\n",
            "Epoch 179, change: 0.00037434\n",
            "Epoch 152, change: 0.00119732\n",
            "Epoch 181, change: 0.00067723\n",
            "Epoch 179, change: 0.00047070\n",
            "Epoch 153, change: 0.00120981\n",
            "Epoch 154, change: 0.00164590\n",
            "Epoch 153, change: 0.00203338\n",
            "Epoch 181, change: 0.00044736\n",
            "Epoch 179, change: 0.00045190\n",
            "Epoch 153, change: 0.00157541\n",
            "Epoch 182, change: 0.00056506\n",
            "Epoch 153, change: 0.00138341\n",
            "Epoch 180, change: 0.00036895\n",
            "Epoch 182, change: 0.00066778\n",
            "Epoch 153, change: 0.00118064\n",
            "Epoch 180, change: 0.00046387\n",
            "Epoch 154, change: 0.00119327\n",
            "Epoch 155, change: 0.00163002\n",
            "Epoch 182, change: 0.00044129\n",
            "Epoch 154, change: 0.00200551\n",
            "Epoch 180, change: 0.00044397\n",
            "Epoch 154, change: 0.00153059\n",
            "Epoch 183, change: 0.00055594\n",
            "Epoch 154, change: 0.00137309\n",
            "Epoch 181, change: 0.00036360\n",
            "Epoch 183, change: 0.00065773\n",
            "Epoch 154, change: 0.00116553\n",
            "Epoch 181, change: 0.00045686\n",
            "Epoch 155, change: 0.00117565\n",
            "Epoch 156, change: 0.00161739\n",
            "Epoch 183, change: 0.00043530\n",
            "Epoch 155, change: 0.00199023\n",
            "Epoch 181, change: 0.00043627\n",
            "Epoch 155, change: 0.00152495\n",
            "Epoch 184, change: 0.00054597\n",
            "Epoch 184, change: 0.00064806\n",
            "Epoch 182, change: 0.00035828\n",
            "Epoch 155, change: 0.00136027\n",
            "Epoch 182, change: 0.00045073\n",
            "Epoch 155, change: 0.00115376\n",
            "Epoch 184, change: 0.00042941\n",
            "Epoch 156, change: 0.00115952\n",
            "Epoch 157, change: 0.00160432\n",
            "Epoch 156, change: 0.00197077\n",
            "Epoch 182, change: 0.00042892\n",
            "Epoch 185, change: 0.00053717\n",
            "Epoch 185, change: 0.00063860\n",
            "Epoch 183, change: 0.00035310\n",
            "Epoch 156, change: 0.00150437\n",
            "Epoch 156, change: 0.00133911\n",
            "Epoch 183, change: 0.00044370\n",
            "Epoch 156, change: 0.00114092\n",
            "Epoch 185, change: 0.00042361\n",
            "Epoch 157, change: 0.00114488\n",
            "Epoch 157, change: 0.00195424\n",
            "Epoch 158, change: 0.00159204\n",
            "Epoch 183, change: 0.00042158\n",
            "Epoch 186, change: 0.00052783\n",
            "Epoch 184, change: 0.00034799\n",
            "Epoch 186, change: 0.00062885\n",
            "Epoch 157, change: 0.00148785\n",
            "Epoch 157, change: 0.00132687\n",
            "Epoch 184, change: 0.00043661\n",
            "Epoch 157, change: 0.00113098\n",
            "Epoch 186, change: 0.00041789\n",
            "Epoch 158, change: 0.00114103\n",
            "Epoch 158, change: 0.00193760\n",
            "Epoch 159, change: 0.00157588\n",
            "Epoch 184, change: 0.00041457\n",
            "Epoch 187, change: 0.00051960\n",
            "Epoch 187, change: 0.00061985\n",
            "Epoch 185, change: 0.00034297\n",
            "Epoch 158, change: 0.00146817\n",
            "Epoch 158, change: 0.00131222\n",
            "Epoch 185, change: 0.00042949\n",
            "Epoch 187, change: 0.00041223\n",
            "Epoch 158, change: 0.00111776\n",
            "Epoch 159, change: 0.00191460\n",
            "Epoch 159, change: 0.00112037\n",
            "Epoch 160, change: 0.00156219\n",
            "Epoch 185, change: 0.00040796\n",
            "Epoch 188, change: 0.00050834\n",
            "Epoch 188, change: 0.00061100\n",
            "Epoch 186, change: 0.00033801\n",
            "Epoch 159, change: 0.00144574\n",
            "Epoch 186, change: 0.00042301\n",
            "Epoch 159, change: 0.00129519\n",
            "Epoch 188, change: 0.00040660\n",
            "Epoch 159, change: 0.00110444\n",
            "Epoch 160, change: 0.00190129\n",
            "Epoch 160, change: 0.00111464\n",
            "Epoch 161, change: 0.00154869\n",
            "Epoch 186, change: 0.00040053\n",
            "Epoch 189, change: 0.00049899\n",
            "Epoch 189, change: 0.00060164\n",
            "Epoch 187, change: 0.00033313\n",
            "Epoch 187, change: 0.00041690\n",
            "Epoch 160, change: 0.00142918\n",
            "Epoch 160, change: 0.00128505\n",
            "Epoch 189, change: 0.00040110\n",
            "Epoch 160, change: 0.00108889\n",
            "Epoch 161, change: 0.00188457\n",
            "Epoch 161, change: 0.00109779\n",
            "Epoch 162, change: 0.00153706\n",
            "Epoch 187, change: 0.00039343\n",
            "Epoch 190, change: 0.00049118\n",
            "Epoch 190, change: 0.00059276\n",
            "Epoch 188, change: 0.00032831\n",
            "Epoch 188, change: 0.00041056\n",
            "Epoch 161, change: 0.00140639\n",
            "Epoch 161, change: 0.00126631\n",
            "Epoch 190, change: 0.00039565\n",
            "Epoch 161, change: 0.00107746\n",
            "Epoch 162, change: 0.00187162\n",
            "Epoch 163, change: 0.00152554\n",
            "Epoch 162, change: 0.00108757\n",
            "Epoch 188, change: 0.00038660\n",
            "Epoch 191, change: 0.00048316\n",
            "Epoch 191, change: 0.00058422\n",
            "Epoch 189, change: 0.00032356\n",
            "Epoch 189, change: 0.00040514\n",
            "Epoch 162, change: 0.00139415\n",
            "Epoch 162, change: 0.00125944\n",
            "Epoch 191, change: 0.00039030\n",
            "Epoch 162, change: 0.00106540\n",
            "Epoch 163, change: 0.00185564\n",
            "Epoch 164, change: 0.00151297\n",
            "Epoch 163, change: 0.00107924\n",
            "Epoch 189, change: 0.00038014\n",
            "Epoch 192, change: 0.00047557\n",
            "Epoch 192, change: 0.00057558\n",
            "Epoch 190, change: 0.00031889\n",
            "Epoch 190, change: 0.00039992\n",
            "Epoch 192, change: 0.00038502\n",
            "Epoch 163, change: 0.00139324\n",
            "Epoch 163, change: 0.00124100\n",
            "Epoch 163, change: 0.00105449\n",
            "Epoch 164, change: 0.00183583\n",
            "Epoch 164, change: 0.00106220\n",
            "Epoch 193, change: 0.00046824\n",
            "Epoch 165, change: 0.00150068\n",
            "Epoch 190, change: 0.00037362\n",
            "Epoch 193, change: 0.00056708\n",
            "Epoch 191, change: 0.00031431\n",
            "Epoch 191, change: 0.00039474\n",
            "Epoch 193, change: 0.00037980\n",
            "Epoch 164, change: 0.00136723\n",
            "Epoch 164, change: 0.00122696\n",
            "Epoch 164, change: 0.00104043\n",
            "Epoch 165, change: 0.00180921\n",
            "Epoch 194, change: 0.00046099\n",
            "Epoch 165, change: 0.00105023\n",
            "Epoch 191, change: 0.00036701\n",
            "Epoch 166, change: 0.00148843\n",
            "Epoch 194, change: 0.00055886\n",
            "Epoch 192, change: 0.00030978\n",
            "Epoch 192, change: 0.00038954\n",
            "Epoch 194, change: 0.00037466\n",
            "Epoch 165, change: 0.00121654\n",
            "Epoch 165, change: 0.00134183\n",
            "Epoch 165, change: 0.00103220\n",
            "Epoch 166, change: 0.00179856\n",
            "Epoch 195, change: 0.00044795\n",
            "Epoch 192, change: 0.00036087\n",
            "Epoch 166, change: 0.00104020\n",
            "Epoch 167, change: 0.00147740\n",
            "Epoch 195, change: 0.00055063\n",
            "Epoch 193, change: 0.00030528\n",
            "Epoch 193, change: 0.00038452\n",
            "Epoch 195, change: 0.00036959\n",
            "Epoch 166, change: 0.00120231\n",
            "Epoch 166, change: 0.00133206\n",
            "Epoch 166, change: 0.00101760\n",
            "Epoch 167, change: 0.00178313\n",
            "Epoch 196, change: 0.00043949\n",
            "Epoch 168, change: 0.00145948\n",
            "Epoch 193, change: 0.00035460\n",
            "Epoch 196, change: 0.00054265\n",
            "Epoch 167, change: 0.00103310\n",
            "Epoch 194, change: 0.00030086\n",
            "Epoch 194, change: 0.00037955\n",
            "Epoch 196, change: 0.00036459\n",
            "Epoch 167, change: 0.00118361\n",
            "Epoch 167, change: 0.00131366\n",
            "Epoch 167, change: 0.00100781\n",
            "Epoch 197, change: 0.00043261\n",
            "Epoch 168, change: 0.00176622\n",
            "Epoch 197, change: 0.00053447\n",
            "Epoch 169, change: 0.00144936\n",
            "Epoch 194, change: 0.00034890\n",
            "Epoch 168, change: 0.00101762\n",
            "Epoch 195, change: 0.00029652\n",
            "Epoch 195, change: 0.00037463\n",
            "Epoch 197, change: 0.00035967\n",
            "Epoch 168, change: 0.00117676\n",
            "Epoch 168, change: 0.00129718\n",
            "Epoch 198, change: 0.00042547\n",
            "Epoch 169, change: 0.00174970\n",
            "Epoch 168, change: 0.00099606\n",
            "Epoch 198, change: 0.00052685\n",
            "Epoch 170, change: 0.00143559\n",
            "Epoch 195, change: 0.00034337\n",
            "Epoch 169, change: 0.00100868\n",
            "Epoch 196, change: 0.00029223\n",
            "Epoch 196, change: 0.00036981\n",
            "Epoch 198, change: 0.00035479\n",
            "Epoch 169, change: 0.00116381\n",
            "Epoch 199, change: 0.00041820\n",
            "Epoch 169, change: 0.00129001\n",
            "Epoch 169, change: 0.00098716\n",
            "Epoch 170, change: 0.00173513\n",
            "Epoch 199, change: 0.00051900\n",
            "Epoch 196, change: 0.00033764\n",
            "Epoch 171, change: 0.00142400\n",
            "Epoch 197, change: 0.00028801\n",
            "Epoch 170, change: 0.00100265\n",
            "Epoch 197, change: 0.00036504\n",
            "Epoch 199, change: 0.00034998\n",
            "Epoch 170, change: 0.00115419\n",
            "Epoch 200, change: 0.00040978\n",
            "Epoch 170, change: 0.00127030\n",
            "Epoch 200, change: 0.00051164\n",
            "Epoch 171, change: 0.00171858\n",
            "Epoch 170, change: 0.00097591\n",
            "Epoch 197, change: 0.00033124\n",
            "Epoch 172, change: 0.00141106\n",
            "Epoch 198, change: 0.00028385\n",
            "Epoch 171, change: 0.00098659\n",
            "Epoch 198, change: 0.00036030\n",
            "Epoch 200, change: 0.00034525\n",
            "Epoch 201, change: 0.00040294\n",
            "Epoch 171, change: 0.00113404\n",
            "Epoch 201, change: 0.00050428\n",
            "Epoch 171, change: 0.00124790\n",
            "Epoch 172, change: 0.00170763\n",
            "Epoch 171, change: 0.00096720\n",
            "Epoch 198, change: 0.00032609\n",
            "Epoch 173, change: 0.00140172\n",
            "Epoch 199, change: 0.00027977\n",
            "Epoch 172, change: 0.00097494\n",
            "Epoch 199, change: 0.00035565\n",
            "Epoch 201, change: 0.00034058\n",
            "Epoch 202, change: 0.00039567\n",
            "Epoch 172, change: 0.00112884\n",
            "Epoch 202, change: 0.00049650\n",
            "Epoch 172, change: 0.00123764\n",
            "Epoch 173, change: 0.00168792\n",
            "Epoch 199, change: 0.00032030\n",
            "Epoch 200, change: 0.00027574\n",
            "Epoch 174, change: 0.00139069\n",
            "Epoch 172, change: 0.00094899\n",
            "Epoch 173, change: 0.00096547\n",
            "Epoch 200, change: 0.00035106\n",
            "Epoch 202, change: 0.00033599\n",
            "Epoch 203, change: 0.00038941\n",
            "Epoch 203, change: 0.00048928\n",
            "Epoch 173, change: 0.00122164\n",
            "Epoch 173, change: 0.00111806\n",
            "Epoch 200, change: 0.00031445\n",
            "Epoch 174, change: 0.00167243\n",
            "Epoch 201, change: 0.00027177\n",
            "Epoch 173, change: 0.00094300\n",
            "Epoch 175, change: 0.00137542\n",
            "Epoch 174, change: 0.00095679\n",
            "Epoch 201, change: 0.00034654\n",
            "Epoch 203, change: 0.00033142\n",
            "Epoch 204, change: 0.00038229\n",
            "Epoch 204, change: 0.00048232\n",
            "Epoch 175, change: 0.00165890\n",
            "Epoch 201, change: 0.00030883\n",
            "Epoch 174, change: 0.00110133\n",
            "Epoch 174, change: 0.00121177\n",
            "Epoch 202, change: 0.00026781\n",
            "Epoch 174, change: 0.00093487\n",
            "Epoch 175, change: 0.00095122\n",
            "Epoch 202, change: 0.00034208\n",
            "Epoch 204, change: 0.00032696\n",
            "Epoch 176, change: 0.00136659\n",
            "Epoch 205, change: 0.00037566\n",
            "Epoch 205, change: 0.00047536\n",
            "Epoch 176, change: 0.00164865\n",
            "Epoch 202, change: 0.00030380\n",
            "Epoch 175, change: 0.00108935\n",
            "Epoch 175, change: 0.00119336\n",
            "Epoch 203, change: 0.00026396\n",
            "Epoch 176, change: 0.00094287\n",
            "Epoch 175, change: 0.00092278\n",
            "Epoch 205, change: 0.00032255\n",
            "Epoch 203, change: 0.00033765\n",
            "Epoch 177, change: 0.00135421\n",
            "Epoch 206, change: 0.00036886\n",
            "Epoch 206, change: 0.00046804\n",
            "Epoch 177, change: 0.00162551\n",
            "Epoch 203, change: 0.00029874\n",
            "Epoch 176, change: 0.00107501\n",
            "Epoch 176, change: 0.00118121\n",
            "Epoch 204, change: 0.00026017\n",
            "Epoch 177, change: 0.00092534\n",
            "Epoch 206, change: 0.00031820\n",
            "Epoch 178, change: 0.00134435\n",
            "Epoch 176, change: 0.00091170\n",
            "Epoch 204, change: 0.00033329\n",
            "Epoch 207, change: 0.00036241\n",
            "Epoch 207, change: 0.00046136\n",
            "Epoch 204, change: 0.00029358\n",
            "Epoch 178, change: 0.00161761\n",
            "Epoch 205, change: 0.00025643\n",
            "Epoch 177, change: 0.00116552\n",
            "Epoch 177, change: 0.00107030\n",
            "Epoch 207, change: 0.00031386\n",
            "Epoch 178, change: 0.00091376\n",
            "Epoch 205, change: 0.00032900\n",
            "Epoch 179, change: 0.00133370\n",
            "Epoch 177, change: 0.00090136\n",
            "Epoch 208, change: 0.00035631\n",
            "Epoch 208, change: 0.00045479\n",
            "Epoch 205, change: 0.00028855\n",
            "Epoch 179, change: 0.00160741\n",
            "Epoch 206, change: 0.00025274\n",
            "Epoch 178, change: 0.00115583\n",
            "Epoch 178, change: 0.00104984\n",
            "Epoch 208, change: 0.00030961\n",
            "Epoch 179, change: 0.00090218\n",
            "Epoch 206, change: 0.00032477\n",
            "Epoch 180, change: 0.00132164\n",
            "Epoch 178, change: 0.00089211\n",
            "Epoch 209, change: 0.00035001\n",
            "Epoch 209, change: 0.00044817\n",
            "Epoch 206, change: 0.00028378\n",
            "Epoch 180, change: 0.00159258\n",
            "Epoch 207, change: 0.00024912\n",
            "Epoch 179, change: 0.00114729\n",
            "Epoch 179, change: 0.00104214\n",
            "Epoch 209, change: 0.00030542\n",
            "Epoch 207, change: 0.00032060\n",
            "Epoch 180, change: 0.00089990\n",
            "Epoch 181, change: 0.00131182\n",
            "Epoch 179, change: 0.00088416\n",
            "Epoch 210, change: 0.00034407\n",
            "Epoch 210, change: 0.00044136\n",
            "Epoch 207, change: 0.00027896\n",
            "Epoch 181, change: 0.00156392\n",
            "Epoch 208, change: 0.00024550\n",
            "Epoch 180, change: 0.00113290\n",
            "Epoch 210, change: 0.00030130\n",
            "Epoch 180, change: 0.00103038\n",
            "Epoch 208, change: 0.00031649\n",
            "Epoch 181, change: 0.00088702\n",
            "Epoch 182, change: 0.00129992\n",
            "Epoch 180, change: 0.00087120\n",
            "Epoch 211, change: 0.00033834\n",
            "Epoch 211, change: 0.00043477\n",
            "Epoch 208, change: 0.00027422\n",
            "Epoch 182, change: 0.00155675\n",
            "Epoch 209, change: 0.00024191\n",
            "Epoch 211, change: 0.00029723\n",
            "Epoch 181, change: 0.00112259\n",
            "Epoch 209, change: 0.00031244\n",
            "Epoch 181, change: 0.00101974\n",
            "Epoch 182, change: 0.00088003\n",
            "Epoch 183, change: 0.00128950\n",
            "Epoch 212, change: 0.00033221\n",
            "Epoch 181, change: 0.00086443\n",
            "Epoch 212, change: 0.00042847\n",
            "Epoch 209, change: 0.00026940\n",
            "Epoch 183, change: 0.00153918\n",
            "Epoch 210, change: 0.00023844\n",
            "Epoch 212, change: 0.00029320\n",
            "Epoch 210, change: 0.00030843\n",
            "Epoch 182, change: 0.00111136\n",
            "Epoch 182, change: 0.00100731\n",
            "Epoch 213, change: 0.00032607\n",
            "Epoch 183, change: 0.00087257\n",
            "Epoch 184, change: 0.00127986\n",
            "Epoch 182, change: 0.00085615\n",
            "Epoch 213, change: 0.00042230\n",
            "Epoch 210, change: 0.00026472\n",
            "Epoch 184, change: 0.00152969\n",
            "Epoch 211, change: 0.00023499\n",
            "Epoch 213, change: 0.00028925\n",
            "Epoch 211, change: 0.00030437\n",
            "Epoch 183, change: 0.00110164\n",
            "Epoch 214, change: 0.00032070\n",
            "Epoch 183, change: 0.00099752\n",
            "Epoch 184, change: 0.00085905\n",
            "Epoch 185, change: 0.00126927\n",
            "Epoch 183, change: 0.00084344\n",
            "Epoch 214, change: 0.00041600\n",
            "Epoch 211, change: 0.00026021\n",
            "Epoch 212, change: 0.00023160\n",
            "Epoch 185, change: 0.00151490\n",
            "Epoch 214, change: 0.00028533\n",
            "Epoch 212, change: 0.00030045\n",
            "Epoch 215, change: 0.00031575\n",
            "Epoch 184, change: 0.00109176\n",
            "Epoch 184, change: 0.00099031\n",
            "Epoch 185, change: 0.00084974\n",
            "Epoch 186, change: 0.00125810\n",
            "Epoch 184, change: 0.00083606\n",
            "Epoch 215, change: 0.00041009\n",
            "Epoch 212, change: 0.00025589\n",
            "Epoch 213, change: 0.00022825\n",
            "Epoch 186, change: 0.00150122\n",
            "Epoch 215, change: 0.00028149\n",
            "Epoch 213, change: 0.00029658\n",
            "Epoch 216, change: 0.00030953\n",
            "Epoch 185, change: 0.00108053\n",
            "Epoch 185, change: 0.00097705\n",
            "Epoch 186, change: 0.00084264\n",
            "Epoch 187, change: 0.00124938\n",
            "Epoch 216, change: 0.00040425\n",
            "Epoch 185, change: 0.00082829\n",
            "Epoch 213, change: 0.00025154\n",
            "Epoch 214, change: 0.00022498\n",
            "Epoch 187, change: 0.00148879\n",
            "Epoch 216, change: 0.00027767\n",
            "Epoch 214, change: 0.00029276\n",
            "Epoch 217, change: 0.00030405\n",
            "Epoch 186, change: 0.00107130\n",
            "Epoch 187, change: 0.00083561\n",
            "Epoch 186, change: 0.00096840\n",
            "Epoch 217, change: 0.00039811\n",
            "Epoch 188, change: 0.00123793\n",
            "Epoch 186, change: 0.00081742\n",
            "Epoch 214, change: 0.00024763\n",
            "Epoch 215, change: 0.00022174\n",
            "Epoch 188, change: 0.00147288\n",
            "Epoch 215, change: 0.00028900\n",
            "Epoch 217, change: 0.00027392\n",
            "Epoch 218, change: 0.00029877\n",
            "Epoch 187, change: 0.00106188\n",
            "Epoch 187, change: 0.00095491\n",
            "Epoch 188, change: 0.00082706\n",
            "Epoch 218, change: 0.00039237\n",
            "Epoch 189, change: 0.00122888\n",
            "Epoch 215, change: 0.00024323\n",
            "Epoch 187, change: 0.00081015\n",
            "Epoch 216, change: 0.00021856\n",
            "Epoch 189, change: 0.00146215\n",
            "Epoch 216, change: 0.00028527\n",
            "Epoch 218, change: 0.00027022\n",
            "Epoch 219, change: 0.00029394\n",
            "Epoch 188, change: 0.00105091\n",
            "Epoch 219, change: 0.00038686\n",
            "Epoch 188, change: 0.00094576\n",
            "Epoch 189, change: 0.00081269\n",
            "Epoch 190, change: 0.00121965\n",
            "Epoch 188, change: 0.00080114\n",
            "Epoch 216, change: 0.00023905\n",
            "Epoch 217, change: 0.00021537\n",
            "Epoch 217, change: 0.00028162\n",
            "Epoch 190, change: 0.00144741\n",
            "Epoch 219, change: 0.00026659\n",
            "Epoch 220, change: 0.00028901\n",
            "Epoch 220, change: 0.00038106\n",
            "Epoch 189, change: 0.00104290\n",
            "Epoch 189, change: 0.00093689\n",
            "Epoch 190, change: 0.00081016\n",
            "Epoch 191, change: 0.00120994\n",
            "Epoch 189, change: 0.00079195\n",
            "Epoch 217, change: 0.00023491\n",
            "Epoch 218, change: 0.00021229\n",
            "Epoch 218, change: 0.00027798\n",
            "Epoch 191, change: 0.00143520\n",
            "Epoch 220, change: 0.00026300\n",
            "Epoch 221, change: 0.00028320\n",
            "Epoch 221, change: 0.00037554\n",
            "Epoch 190, change: 0.00102954\n",
            "Epoch 190, change: 0.00092545\n",
            "Epoch 191, change: 0.00080123\n",
            "Epoch 192, change: 0.00119867\n",
            "Epoch 218, change: 0.00023086\n",
            "Epoch 190, change: 0.00078332\n",
            "Epoch 219, change: 0.00020922\n",
            "Epoch 219, change: 0.00027441\n",
            "Epoch 192, change: 0.00142572\n",
            "Epoch 221, change: 0.00025941\n",
            "Epoch 222, change: 0.00027832\n",
            "Epoch 222, change: 0.00036991\n",
            "Epoch 191, change: 0.00102210\n",
            "Epoch 191, change: 0.00091782\n",
            "Epoch 192, change: 0.00079506\n",
            "Epoch 193, change: 0.00118877\n",
            "Epoch 219, change: 0.00022699\n",
            "Epoch 191, change: 0.00077580\n",
            "Epoch 220, change: 0.00020621\n",
            "Epoch 220, change: 0.00027088\n",
            "Epoch 222, change: 0.00025591\n",
            "Epoch 193, change: 0.00141344\n",
            "Epoch 223, change: 0.00027372\n",
            "Epoch 223, change: 0.00036459\n",
            "Epoch 192, change: 0.00101275\n",
            "Epoch 192, change: 0.00090552\n",
            "Epoch 193, change: 0.00078490\n",
            "Epoch 194, change: 0.00117923\n",
            "Epoch 220, change: 0.00022316\n",
            "Epoch 192, change: 0.00076741\n",
            "Epoch 221, change: 0.00026740\n",
            "Epoch 223, change: 0.00025245\n",
            "Epoch 221, change: 0.00020323\n",
            "Epoch 194, change: 0.00139363\n",
            "Epoch 224, change: 0.00026920\n",
            "Epoch 224, change: 0.00035922\n",
            "Epoch 193, change: 0.00100477\n",
            "Epoch 193, change: 0.00089874\n",
            "Epoch 195, change: 0.00117090\n",
            "Epoch 194, change: 0.00077471\n",
            "Epoch 221, change: 0.00021945\n",
            "Epoch 193, change: 0.00076039\n",
            "Epoch 222, change: 0.00026397\n",
            "Epoch 224, change: 0.00024906\n",
            "Epoch 222, change: 0.00020029\n",
            "Epoch 195, change: 0.00138526\n",
            "Epoch 225, change: 0.00026440\n",
            "Epoch 225, change: 0.00035393\n",
            "Epoch 194, change: 0.00099563\n",
            "Epoch 194, change: 0.00089036\n",
            "Epoch 196, change: 0.00116215\n",
            "Epoch 195, change: 0.00076659\n",
            "Epoch 222, change: 0.00021586\n",
            "Epoch 194, change: 0.00075116\n",
            "Epoch 223, change: 0.00026059\n",
            "Epoch 225, change: 0.00024568\n",
            "Epoch 223, change: 0.00019741\n",
            "Epoch 196, change: 0.00137672\n",
            "Epoch 226, change: 0.00026006\n",
            "Epoch 226, change: 0.00034899\n",
            "Epoch 195, change: 0.00088223\n",
            "Epoch 195, change: 0.00098373\n",
            "Epoch 223, change: 0.00021243\n",
            "Epoch 197, change: 0.00115325\n",
            "Epoch 196, change: 0.00076164\n",
            "Epoch 224, change: 0.00025726\n",
            "Epoch 226, change: 0.00024236\n",
            "Epoch 195, change: 0.00074393\n",
            "Epoch 224, change: 0.00019456\n",
            "Epoch 227, change: 0.00025539\n",
            "Epoch 197, change: 0.00135760\n",
            "Epoch 227, change: 0.00034401\n",
            "Epoch 224, change: 0.00020908\n",
            "Epoch 196, change: 0.00097584\n",
            "Epoch 196, change: 0.00086539\n",
            "Epoch 198, change: 0.00114257\n",
            "Epoch 197, change: 0.00075289\n",
            "Epoch 225, change: 0.00025392\n",
            "Epoch 196, change: 0.00073608\n",
            "Epoch 227, change: 0.00023909\n",
            "Epoch 225, change: 0.00019177\n",
            "Epoch 228, change: 0.00025159\n",
            "Epoch 198, change: 0.00134787\n",
            "Epoch 228, change: 0.00033871\n",
            "Epoch 225, change: 0.00020552\n",
            "Epoch 198, change: 0.00074369\n",
            "Epoch 197, change: 0.00096567\n",
            "Epoch 197, change: 0.00085907\n",
            "Epoch 199, change: 0.00113342\n",
            "Epoch 226, change: 0.00025064\n",
            "Epoch 197, change: 0.00072778\n",
            "Epoch 228, change: 0.00023585\n",
            "Epoch 229, change: 0.00024821\n",
            "Epoch 226, change: 0.00018900\n",
            "Epoch 199, change: 0.00133540\n",
            "Epoch 229, change: 0.00033380\n",
            "Epoch 226, change: 0.00020149\n",
            "Epoch 199, change: 0.00074081\n",
            "Epoch 198, change: 0.00085168\n",
            "Epoch 198, change: 0.00095864\n",
            "Epoch 200, change: 0.00112565\n",
            "Epoch 227, change: 0.00024742\n",
            "Epoch 198, change: 0.00072169\n",
            "Epoch 229, change: 0.00023267\n",
            "Epoch 230, change: 0.00024480\n",
            "Epoch 227, change: 0.00018627\n",
            "Epoch 200, change: 0.00132790\n",
            "Epoch 230, change: 0.00032888\n",
            "Epoch 227, change: 0.00019805\n",
            "Epoch 199, change: 0.00084325\n",
            "Epoch 200, change: 0.00072938\n",
            "Epoch 199, change: 0.00094785\n",
            "Epoch 228, change: 0.00024425\n",
            "Epoch 201, change: 0.00111703\n",
            "Epoch 230, change: 0.00022953\n",
            "Epoch 199, change: 0.00071178\n",
            "Epoch 231, change: 0.00024150\n",
            "Epoch 228, change: 0.00018359\n",
            "Epoch 201, change: 0.00131331\n",
            "Epoch 231, change: 0.00032428\n",
            "Epoch 228, change: 0.00019478\n",
            "Epoch 200, change: 0.00083233\n",
            "Epoch 229, change: 0.00024112\n",
            "Epoch 201, change: 0.00072145\n",
            "Epoch 200, change: 0.00094098\n",
            "Epoch 202, change: 0.00110752\n",
            "Epoch 231, change: 0.00022643\n",
            "Epoch 232, change: 0.00023823\n",
            "Epoch 200, change: 0.00070662\n",
            "Epoch 229, change: 0.00018096\n",
            "Epoch 202, change: 0.00130198\n",
            "Epoch 232, change: 0.00031965\n",
            "Epoch 229, change: 0.00019132\n",
            "Epoch 230, change: 0.00023801\n",
            "Epoch 202, change: 0.00071655\n",
            "Epoch 201, change: 0.00082211\n",
            "Epoch 233, change: 0.00023505\n",
            "Epoch 201, change: 0.00093006\n",
            "Epoch 232, change: 0.00022337\n",
            "Epoch 203, change: 0.00109972\n",
            "Epoch 201, change: 0.00069909\n",
            "Epoch 230, change: 0.00017836\n",
            "Epoch 203, change: 0.00129059\n",
            "Epoch 233, change: 0.00031478\n",
            "Epoch 230, change: 0.00018815\n",
            "Epoch 231, change: 0.00023495\n",
            "Epoch 234, change: 0.00023190\n",
            "Epoch 233, change: 0.00022035\n",
            "Epoch 203, change: 0.00070972\n",
            "Epoch 202, change: 0.00081479\n",
            "Epoch 202, change: 0.00092330\n",
            "Epoch 202, change: 0.00069134\n",
            "Epoch 204, change: 0.00108759\n",
            "Epoch 231, change: 0.00017580\n",
            "Epoch 234, change: 0.00031026\n",
            "Epoch 204, change: 0.00127806\n",
            "Epoch 231, change: 0.00018498\n",
            "Epoch 232, change: 0.00023194\n",
            "Epoch 235, change: 0.00022867\n",
            "Epoch 234, change: 0.00021738\n",
            "Epoch 203, change: 0.00080673\n",
            "Epoch 203, change: 0.00091520\n",
            "Epoch 204, change: 0.00070334\n",
            "Epoch 203, change: 0.00068528\n",
            "Epoch 232, change: 0.00017324\n",
            "Epoch 205, change: 0.00108013\n",
            "Epoch 235, change: 0.00030591\n",
            "Epoch 205, change: 0.00126655\n",
            "Epoch 232, change: 0.00018206\n",
            "Epoch 233, change: 0.00022896\n",
            "Epoch 236, change: 0.00022558\n",
            "Epoch 235, change: 0.00021444\n",
            "Epoch 204, change: 0.00080031\n",
            "Epoch 205, change: 0.00069810\n",
            "Epoch 204, change: 0.00090523\n",
            "Epoch 204, change: 0.00067419\n",
            "Epoch 233, change: 0.00017074\n",
            "Epoch 206, change: 0.00107283\n",
            "Epoch 236, change: 0.00030153\n",
            "Epoch 206, change: 0.00125773\n",
            "Epoch 233, change: 0.00017897\n",
            "Epoch 234, change: 0.00022603\n",
            "Epoch 237, change: 0.00022259\n",
            "Epoch 236, change: 0.00021155\n",
            "Epoch 205, change: 0.00078791\n",
            "Epoch 205, change: 0.00089792\n",
            "Epoch 206, change: 0.00068480\n",
            "Epoch 205, change: 0.00066935\n",
            "Epoch 234, change: 0.00016829\n",
            "Epoch 207, change: 0.00106239\n",
            "Epoch 237, change: 0.00029743\n",
            "Epoch 207, change: 0.00124524\n",
            "Epoch 234, change: 0.00017605\n",
            "Epoch 235, change: 0.00022312\n",
            "Epoch 238, change: 0.00021963\n",
            "Epoch 237, change: 0.00020869\n",
            "Epoch 206, change: 0.00078003\n",
            "Epoch 206, change: 0.00088947\n",
            "Epoch 207, change: 0.00067998\n",
            "Epoch 235, change: 0.00016588\n",
            "Epoch 206, change: 0.00066213\n",
            "Epoch 238, change: 0.00029312\n",
            "Epoch 208, change: 0.00105480\n",
            "Epoch 208, change: 0.00123220\n",
            "Epoch 235, change: 0.00017309\n",
            "Epoch 236, change: 0.00022025\n",
            "Epoch 239, change: 0.00021667\n",
            "Epoch 238, change: 0.00020588\n",
            "Epoch 207, change: 0.00077343\n",
            "Epoch 207, change: 0.00088181\n",
            "Epoch 236, change: 0.00016349\n",
            "Epoch 208, change: 0.00067419\n",
            "Epoch 207, change: 0.00065549\n",
            "Epoch 239, change: 0.00028823\n",
            "Epoch 209, change: 0.00104701\n",
            "Epoch 209, change: 0.00122396\n",
            "Epoch 236, change: 0.00017028\n",
            "Epoch 240, change: 0.00021379\n",
            "Epoch 239, change: 0.00020309\n",
            "Epoch 237, change: 0.00021743\n",
            "Epoch 208, change: 0.00076655\n",
            "Epoch 237, change: 0.00016113\n",
            "Epoch 208, change: 0.00087320\n",
            "Epoch 209, change: 0.00066599\n",
            "Epoch 240, change: 0.00028416\n",
            "Epoch 208, change: 0.00065003\n",
            "Epoch 210, change: 0.00103906\n",
            "Epoch 210, change: 0.00121491\n",
            "Epoch 237, change: 0.00016703\n",
            "Epoch 241, change: 0.00021086\n",
            "Epoch 240, change: 0.00020035\n",
            "Epoch 238, change: 0.00021465\n",
            "Epoch 238, change: 0.00015880\n",
            "Epoch 209, change: 0.00075985\n",
            "Epoch 209, change: 0.00086513\n",
            "Epoch 241, change: 0.00027999\n",
            "Epoch 210, change: 0.00066036\n",
            "Epoch 209, change: 0.00064251\n",
            "Epoch 211, change: 0.00102948\n",
            "Epoch 211, change: 0.00119929\n",
            "Epoch 238, change: 0.00016441\n",
            "Epoch 242, change: 0.00020795\n",
            "Epoch 241, change: 0.00019765\n",
            "Epoch 239, change: 0.00021189\n",
            "Epoch 239, change: 0.00015652\n",
            "Epoch 210, change: 0.00075325\n",
            "Epoch 210, change: 0.00085774\n",
            "Epoch 242, change: 0.00027595\n",
            "Epoch 211, change: 0.00065502\n",
            "Epoch 210, change: 0.00063728\n",
            "Epoch 212, change: 0.00102220\n",
            "Epoch 243, change: 0.00020517\n",
            "Epoch 212, change: 0.00119178\n",
            "Epoch 239, change: 0.00016164\n",
            "Epoch 242, change: 0.00019498\n",
            "Epoch 240, change: 0.00020916\n",
            "Epoch 240, change: 0.00015428\n",
            "Epoch 211, change: 0.00074706\n",
            "Epoch 243, change: 0.00027199\n",
            "Epoch 211, change: 0.00084950\n",
            "Epoch 212, change: 0.00065051\n",
            "Epoch 211, change: 0.00063113\n",
            "Epoch 213, change: 0.00101389\n",
            "Epoch 244, change: 0.00020243\n",
            "Epoch 240, change: 0.00015870\n",
            "Epoch 213, change: 0.00118297\n",
            "Epoch 243, change: 0.00019235\n",
            "Epoch 241, change: 0.00020648\n",
            "Epoch 241, change: 0.00015206\n",
            "Epoch 212, change: 0.00073952\n",
            "Epoch 244, change: 0.00026806\n",
            "Epoch 212, change: 0.00084278\n",
            "Epoch 213, change: 0.00064600\n",
            "Epoch 212, change: 0.00062242\n",
            "Epoch 214, change: 0.00100655\n",
            "Epoch 245, change: 0.00019969\n",
            "Epoch 241, change: 0.00015614\n",
            "Epoch 244, change: 0.00018976\n",
            "Epoch 214, change: 0.00117025\n",
            "Epoch 242, change: 0.00020383\n",
            "Epoch 242, change: 0.00014984\n",
            "Epoch 213, change: 0.00072078\n",
            "Epoch 245, change: 0.00026425\n",
            "Epoch 213, change: 0.00083584\n",
            "Epoch 214, change: 0.00064155\n",
            "Epoch 213, change: 0.00061572\n",
            "Epoch 215, change: 0.00099897\n",
            "Epoch 246, change: 0.00019701\n",
            "Epoch 242, change: 0.00015369\n",
            "Epoch 245, change: 0.00018719\n",
            "Epoch 215, change: 0.00116358\n",
            "Epoch 243, change: 0.00020122\n",
            "Epoch 243, change: 0.00014769\n",
            "Epoch 246, change: 0.00026039\n",
            "Epoch 214, change: 0.00071814\n",
            "Epoch 214, change: 0.00082563\n",
            "Epoch 215, change: 0.00063710\n",
            "Epoch 214, change: 0.00060979\n",
            "Epoch 216, change: 0.00099037\n",
            "Epoch 247, change: 0.00019441\n",
            "Epoch 243, change: 0.00015098\n",
            "Epoch 246, change: 0.00018467\n",
            "Epoch 216, change: 0.00114751\n",
            "Epoch 244, change: 0.00019864\n",
            "Epoch 244, change: 0.00014556\n",
            "Epoch 247, change: 0.00025663\n",
            "Epoch 215, change: 0.00070940\n",
            "Epoch 215, change: 0.00082021\n",
            "Epoch 215, change: 0.00060399\n",
            "Epoch 216, change: 0.00063271\n",
            "Epoch 248, change: 0.00019181\n",
            "Epoch 217, change: 0.00098348\n",
            "Epoch 244, change: 0.00014828\n",
            "Epoch 247, change: 0.00018217\n",
            "Epoch 217, change: 0.00113883\n",
            "Epoch 245, change: 0.00019611\n",
            "Epoch 245, change: 0.00014347\n",
            "Epoch 248, change: 0.00025313\n",
            "Epoch 216, change: 0.00070249\n",
            "Epoch 216, change: 0.00059725\n",
            "Epoch 216, change: 0.00081320\n",
            "Epoch 217, change: 0.00062836\n",
            "Epoch 249, change: 0.00018917\n",
            "Epoch 248, change: 0.00017972\n",
            "Epoch 245, change: 0.00014574\n",
            "Epoch 218, change: 0.00097473\n",
            "Epoch 218, change: 0.00113030\n",
            "Epoch 246, change: 0.00019360\n",
            "Epoch 246, change: 0.00014141\n",
            "Epoch 249, change: 0.00024947\n",
            "Epoch 217, change: 0.00069716\n",
            "Epoch 217, change: 0.00059211\n",
            "Epoch 250, change: 0.00018661\n",
            "Epoch 217, change: 0.00080614\n",
            "Epoch 218, change: 0.00062400\n",
            "Epoch 249, change: 0.00017730\n",
            "Epoch 246, change: 0.00014337\n",
            "Epoch 219, change: 0.00096790\n",
            "Epoch 219, change: 0.00111949\n",
            "Epoch 247, change: 0.00019109\n",
            "Epoch 247, change: 0.00013936\n",
            "Epoch 250, change: 0.00024594\n",
            "Epoch 218, change: 0.00068909\n",
            "Epoch 251, change: 0.00018414\n",
            "Epoch 218, change: 0.00058575\n",
            "Epoch 218, change: 0.00079565\n",
            "Epoch 219, change: 0.00061971\n",
            "Epoch 250, change: 0.00017490\n",
            "Epoch 247, change: 0.00014095\n",
            "Epoch 220, change: 0.00110959\n",
            "Epoch 248, change: 0.00018864\n",
            "Epoch 220, change: 0.00096039\n",
            "Epoch 248, change: 0.00013735\n",
            "Epoch 251, change: 0.00024176\n",
            "Epoch 219, change: 0.00068353\n",
            "Epoch 252, change: 0.00018166\n",
            "Epoch 219, change: 0.00057944\n",
            "Epoch 251, change: 0.00017254\n",
            "Epoch 219, change: 0.00079075\n",
            "Epoch 220, change: 0.00061543\n",
            "Epoch 248, change: 0.00013865\n",
            "Epoch 249, change: 0.00018622\n",
            "Epoch 221, change: 0.00109991\n",
            "Epoch 221, change: 0.00095203\n",
            "Epoch 252, change: 0.00023828\n",
            "Epoch 249, change: 0.00013537\n",
            "Epoch 220, change: 0.00067269\n",
            "Epoch 253, change: 0.00017917\n",
            "Epoch 252, change: 0.00017021\n",
            "Epoch 220, change: 0.00078396\n",
            "Epoch 220, change: 0.00057357\n",
            "Epoch 249, change: 0.00013620\n",
            "Epoch 221, change: 0.00061119\n",
            "Epoch 250, change: 0.00018383\n",
            "Epoch 222, change: 0.00109184\n",
            "Epoch 222, change: 0.00094550\n",
            "Epoch 253, change: 0.00023489\n",
            "Epoch 250, change: 0.00013343\n",
            "Epoch 221, change: 0.00066705\n",
            "Epoch 254, change: 0.00017677\n",
            "Epoch 253, change: 0.00016791\n",
            "Epoch 221, change: 0.00056836\n",
            "Epoch 250, change: 0.00013387\n",
            "Epoch 221, change: 0.00077760\n",
            "Epoch 251, change: 0.00018148\n",
            "Epoch 223, change: 0.00108229\n",
            "Epoch 222, change: 0.00060700\n",
            "Epoch 223, change: 0.00093708\n",
            "Epoch 254, change: 0.00023146\n",
            "Epoch 251, change: 0.00013152\n",
            "Epoch 222, change: 0.00066131\n",
            "Epoch 255, change: 0.00017436\n",
            "Epoch 254, change: 0.00016565\n",
            "Epoch 251, change: 0.00013166\n",
            "Epoch 222, change: 0.00056094\n",
            "Epoch 224, change: 0.00107564\n",
            "Epoch 222, change: 0.00077096\n",
            "Epoch 252, change: 0.00017916\n",
            "Epoch 223, change: 0.00060279\n",
            "Epoch 224, change: 0.00093077\n",
            "Epoch 255, change: 0.00022819\n",
            "Epoch 252, change: 0.00012963\n",
            "Epoch 256, change: 0.00017207\n",
            "Epoch 223, change: 0.00065560\n",
            "Epoch 255, change: 0.00016342\n",
            "Epoch 252, change: 0.00012956\n",
            "Epoch 223, change: 0.00055750\n",
            "Epoch 253, change: 0.00017685\n",
            "Epoch 225, change: 0.00106231\n",
            "Epoch 223, change: 0.00076436\n",
            "Epoch 224, change: 0.00059867\n",
            "Epoch 256, change: 0.00022483\n",
            "Epoch 225, change: 0.00092402\n",
            "Epoch 253, change: 0.00012775\n",
            "Epoch 257, change: 0.00016977\n",
            "Epoch 224, change: 0.00064741\n",
            "Epoch 256, change: 0.00016121\n",
            "Epoch 253, change: 0.00012737\n",
            "Epoch 226, change: 0.00105714\n",
            "Epoch 254, change: 0.00017460\n",
            "Epoch 224, change: 0.00055197\n",
            "Epoch 224, change: 0.00075356\n",
            "Epoch 225, change: 0.00059453\n",
            "Epoch 257, change: 0.00022156\n",
            "Epoch 226, change: 0.00091561\n",
            "Epoch 254, change: 0.00012590\n",
            "Epoch 258, change: 0.00016750\n",
            "Epoch 225, change: 0.00063947\n",
            "Epoch 257, change: 0.00015903\n",
            "Epoch 254, change: 0.00012535\n",
            "Epoch 255, change: 0.00017237\n",
            "Epoch 225, change: 0.00054544\n",
            "Epoch 227, change: 0.00104392\n",
            "Epoch 225, change: 0.00074854\n",
            "Epoch 258, change: 0.00021847\n",
            "Epoch 226, change: 0.00059044\n",
            "Epoch 255, change: 0.00012409\n",
            "Epoch 227, change: 0.00090953\n",
            "Epoch 259, change: 0.00016529\n",
            "Epoch 226, change: 0.00063379\n",
            "Epoch 258, change: 0.00015690\n",
            "Epoch 255, change: 0.00012325\n",
            "Epoch 256, change: 0.00017017\n",
            "Epoch 228, change: 0.00103579\n",
            "Epoch 226, change: 0.00054152\n",
            "Epoch 226, change: 0.00074231\n",
            "Epoch 259, change: 0.00021533\n",
            "Epoch 256, change: 0.00012231\n",
            "Epoch 227, change: 0.00058638\n",
            "Epoch 228, change: 0.00090162\n",
            "Epoch 260, change: 0.00016304\n",
            "Epoch 227, change: 0.00062905\n",
            "Epoch 259, change: 0.00015478\n",
            "Epoch 256, change: 0.00012105\n",
            "Epoch 257, change: 0.00016798\n",
            "Epoch 229, change: 0.00102687\n",
            "Epoch 227, change: 0.00053573\n",
            "Epoch 260, change: 0.00021209\n",
            "Epoch 227, change: 0.00073469\n",
            "Epoch 257, change: 0.00012054\n",
            "Epoch 228, change: 0.00058237\n",
            "Epoch 229, change: 0.00089525\n",
            "Epoch 261, change: 0.00016082\n",
            "Epoch 228, change: 0.00062339\n",
            "Epoch 260, change: 0.00015268\n",
            "Epoch 257, change: 0.00011902\n",
            "Epoch 258, change: 0.00016580\n",
            "Epoch 228, change: 0.00052751\n",
            "Epoch 230, change: 0.00101392\n",
            "Epoch 261, change: 0.00020901\n",
            "Epoch 228, change: 0.00072838\n",
            "Epoch 258, change: 0.00011881\n",
            "Epoch 230, change: 0.00088796\n",
            "Epoch 229, change: 0.00057838\n",
            "Epoch 262, change: 0.00015869\n",
            "Epoch 229, change: 0.00061825\n",
            "Epoch 261, change: 0.00015062\n",
            "Epoch 258, change: 0.00011697\n",
            "Epoch 259, change: 0.00016368\n",
            "Epoch 229, change: 0.00052276\n",
            "Epoch 262, change: 0.00020602\n",
            "Epoch 231, change: 0.00100877\n",
            "Epoch 259, change: 0.00011710\n",
            "Epoch 229, change: 0.00072131\n",
            "Epoch 230, change: 0.00057436\n",
            "Epoch 231, change: 0.00088116\n",
            "Epoch 263, change: 0.00015656\n",
            "Epoch 262, change: 0.00014859\n",
            "Epoch 259, change: 0.00011501\n",
            "Epoch 230, change: 0.00061252\n",
            "Epoch 260, change: 0.00016158\n",
            "Epoch 263, change: 0.00020296\n",
            "Epoch 230, change: 0.00051871\n",
            "Epoch 232, change: 0.00099890\n",
            "Epoch 260, change: 0.00011542\n",
            "Epoch 230, change: 0.00071476\n",
            "Epoch 231, change: 0.00057045\n",
            "Epoch 232, change: 0.00087470\n",
            "Epoch 264, change: 0.00015447\n",
            "Epoch 263, change: 0.00014659\n",
            "Epoch 231, change: 0.00060699\n",
            "Epoch 260, change: 0.00011309\n",
            "Epoch 261, change: 0.00015952\n",
            "Epoch 264, change: 0.00020002\n",
            "Epoch 261, change: 0.00011375\n",
            "Epoch 233, change: 0.00098967\n",
            "Epoch 231, change: 0.00051362\n",
            "Epoch 231, change: 0.00070932\n",
            "Epoch 232, change: 0.00056652\n",
            "Epoch 265, change: 0.00015238\n",
            "Epoch 264, change: 0.00014462\n",
            "Epoch 233, change: 0.00086875\n",
            "Epoch 261, change: 0.00011124\n",
            "Epoch 232, change: 0.00060259\n",
            "Epoch 262, change: 0.00015747\n",
            "Epoch 265, change: 0.00019717\n",
            "Epoch 262, change: 0.00011212\n",
            "Epoch 234, change: 0.00098326\n",
            "Epoch 232, change: 0.00050903\n",
            "Epoch 232, change: 0.00070346\n",
            "Epoch 233, change: 0.00056263\n",
            "Epoch 266, change: 0.00015033\n",
            "Epoch 265, change: 0.00014266\n",
            "Epoch 234, change: 0.00086115\n",
            "Epoch 262, change: 0.00010930\n",
            "Epoch 263, change: 0.00015546\n",
            "Epoch 233, change: 0.00059833\n",
            "Epoch 266, change: 0.00019440\n",
            "Epoch 263, change: 0.00011051\n",
            "Epoch 235, change: 0.00097323\n",
            "Epoch 233, change: 0.00050211\n",
            "Epoch 233, change: 0.00069746\n",
            "Epoch 267, change: 0.00014833\n",
            "Epoch 234, change: 0.00055877\n",
            "Epoch 266, change: 0.00014074\n",
            "Epoch 235, change: 0.00085572\n",
            "Epoch 263, change: 0.00010747\n",
            "Epoch 234, change: 0.00059429\n",
            "Epoch 264, change: 0.00015346\n",
            "Epoch 267, change: 0.00019166\n",
            "Epoch 236, change: 0.00096351\n",
            "Epoch 264, change: 0.00010893\n",
            "Epoch 234, change: 0.00049808\n",
            "Epoch 268, change: 0.00014638\n",
            "Epoch 235, change: 0.00055495\n",
            "Epoch 267, change: 0.00013884\n",
            "Epoch 234, change: 0.00068884\n",
            "Epoch 236, change: 0.00084674\n",
            "Epoch 264, change: 0.00010572\n",
            "Epoch 235, change: 0.00058877\n",
            "Epoch 265, change: 0.00015150\n",
            "Epoch 268, change: 0.00018894\n",
            "Epoch 265, change: 0.00010737\n",
            "Epoch 237, change: 0.00095637\n",
            "Epoch 235, change: 0.00049382\n",
            "Epoch 269, change: 0.00014438\n",
            "Epoch 268, change: 0.00013696\n",
            "Epoch 236, change: 0.00055115\n",
            "Epoch 235, change: 0.00068402\n",
            "Epoch 237, change: 0.00084128\n",
            "Epoch 265, change: 0.00010397\n",
            "Epoch 266, change: 0.00014956\n",
            "Epoch 236, change: 0.00058537\n",
            "Epoch 269, change: 0.00018623\n",
            "Epoch 266, change: 0.00010583\n",
            "Epoch 238, change: 0.00094679\n",
            "Epoch 236, change: 0.00048852\n",
            "Epoch 270, change: 0.00014245\n",
            "Epoch 269, change: 0.00013512\n",
            "Epoch 237, change: 0.00054739\n",
            "Epoch 236, change: 0.00067859\n",
            "Epoch 266, change: 0.00010228\n",
            "Epoch 238, change: 0.00083522\n",
            "Epoch 267, change: 0.00014765\n",
            "Epoch 270, change: 0.00018355\n",
            "Epoch 237, change: 0.00058072\n",
            "Epoch 239, change: 0.00093916\n",
            "Epoch 267, change: 0.00010427\n",
            "Epoch 237, change: 0.00048448\n",
            "Epoch 271, change: 0.00014052\n",
            "Epoch 270, change: 0.00013329\n",
            "Epoch 238, change: 0.00054366\n",
            "Epoch 237, change: 0.00067142\n",
            "Epoch 239, change: 0.00082851\n",
            "Epoch 267, change: 0.00010047\n",
            "Epoch 271, change: 0.00018091\n",
            "Epoch 268, change: 0.00014575\n",
            "Epoch 238, change: 0.00057705\n",
            "Epoch 268, change: 0.00010277\n",
            "Epoch 240, change: 0.00093272\n",
            "Epoch 272, change: 0.00013865\n",
            "Epoch 238, change: 0.00047711\n",
            "Epoch 271, change: 0.00013150\n",
            "Epoch 239, change: 0.00053994\n",
            "Epoch 238, change: 0.00066564\n",
            "convergence after 268 epochs took 285 seconds\n",
            "Epoch 240, change: 0.00082222\n",
            "Epoch 272, change: 0.00017837\n",
            "Epoch 269, change: 0.00014389\n",
            "Epoch 269, change: 0.00010129\n",
            "Epoch 239, change: 0.00057273\n",
            "Epoch 241, change: 0.00092323\n",
            "Epoch 273, change: 0.00013681\n",
            "Epoch 239, change: 0.00047377\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.40194D-02\n",
            "Epoch 272, change: 0.00012973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 240, change: 0.00053617\n",
            "Epoch 239, change: 0.00065967\n",
            "Epoch 273, change: 0.00017586\n",
            "Epoch 241, change: 0.00081557\n",
            "Epoch 270, change: 0.00014205\n",
            "convergence after 270 epochs took 286 seconds\n",
            "Epoch 240, change: 0.00056818\n",
            "Epoch 242, change: 0.00091480\n",
            "Epoch 274, change: 0.00013495\n",
            "Epoch 240, change: 0.00046896\n",
            "Epoch 273, change: 0.00012799\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.41774D-02\n",
            "Epoch 274, change: 0.00017314\n",
            "Epoch 241, change: 0.00053252\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 240, change: 0.00065463\n",
            "Epoch 242, change: 0.00080944\n",
            "Epoch 271, change: 0.00014022\n",
            "Epoch 241, change: 0.00056346\n",
            "Epoch 241, change: 0.00046414\n",
            "Epoch 275, change: 0.00013318\n",
            "Epoch 243, change: 0.00090787\n",
            "Epoch 274, change: 0.00012626\n",
            "Epoch 275, change: 0.00017043\n",
            "Epoch 242, change: 0.00052887\n",
            "Epoch 241, change: 0.00064941\n",
            "Epoch 242, change: 0.00046045\n",
            "Epoch 272, change: 0.00013843\n",
            "Epoch 243, change: 0.00080348\n",
            "Epoch 276, change: 0.00013143\n",
            "Epoch 242, change: 0.00055996\n",
            "Epoch 244, change: 0.00089832\n",
            "Epoch 276, change: 0.00016799\n",
            "Epoch 275, change: 0.00012455\n",
            "Epoch 243, change: 0.00045589\n",
            "Epoch 243, change: 0.00052527\n",
            "Epoch 273, change: 0.00013665\n",
            "Epoch 242, change: 0.00064369\n",
            "Epoch 244, change: 0.00079720\n",
            "Epoch 277, change: 0.00012968\n",
            "Epoch 243, change: 0.00055568\n",
            "Epoch 277, change: 0.00016551\n",
            "Epoch 245, change: 0.00089244\n",
            "Epoch 276, change: 0.00012287\n",
            "Epoch 244, change: 0.00045140\n",
            "\n",
            "At iterate   50    f=  2.48657D-01    |proj g|=  8.58704D-04\n",
            "Epoch 274, change: 0.00013490\n",
            "Epoch 244, change: 0.00052166\n",
            "Epoch 278, change: 0.00012791\n",
            "Epoch 243, change: 0.00063566\n",
            "Epoch 278, change: 0.00016308\n",
            "Epoch 245, change: 0.00079086\n",
            "Epoch 246, change: 0.00088283\n",
            "Epoch 244, change: 0.00055105\n",
            "Epoch 277, change: 0.00012121\n",
            "Epoch 245, change: 0.00044807\n",
            "Epoch 275, change: 0.00013318\n",
            "Epoch 279, change: 0.00016077\n",
            "Epoch 279, change: 0.00012617\n",
            "Epoch 245, change: 0.00051811\n",
            "Epoch 246, change: 0.00078556\n",
            "Epoch 244, change: 0.00063161\n",
            "Epoch 247, change: 0.00087803\n",
            "Epoch 246, change: 0.00044486\n",
            "Epoch 245, change: 0.00054784\n",
            "Epoch 278, change: 0.00011957\n",
            "\n",
            "At iterate   50    f=  2.49618D-01    |proj g|=  2.02680D-03\n",
            "Epoch 280, change: 0.00015839\n",
            "Epoch 276, change: 0.00013147\n",
            "Epoch 280, change: 0.00012450\n",
            "Epoch 246, change: 0.00051455\n",
            "Epoch 247, change: 0.00077868\n",
            "Epoch 245, change: 0.00062614\n",
            "Epoch 247, change: 0.00044124\n",
            "Epoch 248, change: 0.00087008\n",
            "Epoch 279, change: 0.00011796\n",
            "Epoch 246, change: 0.00054357\n",
            "Epoch 281, change: 0.00015611\n",
            "Epoch 277, change: 0.00012979\n",
            "Epoch 281, change: 0.00012286\n",
            "Epoch 248, change: 0.00043802\n",
            "Epoch 247, change: 0.00051104\n",
            "Epoch 246, change: 0.00061965\n",
            "Epoch 248, change: 0.00077317\n",
            "Epoch 249, change: 0.00086071\n",
            "Epoch 282, change: 0.00015382\n",
            "Epoch 280, change: 0.00011637\n",
            "Epoch 247, change: 0.00053994\n",
            "Epoch 282, change: 0.00012122\n",
            "Epoch 278, change: 0.00012812\n",
            "Epoch 249, change: 0.00043475\n",
            "Epoch 248, change: 0.00050755\n",
            "\n",
            "At iterate  100    f=  2.25728D-01    |proj g|=  9.29805D-04\n",
            "Epoch 247, change: 0.00061440\n",
            "Epoch 249, change: 0.00076720\n",
            "Epoch 283, change: 0.00015157\n",
            "Epoch 250, change: 0.00085277\n",
            "Epoch 281, change: 0.00011480\n",
            "Epoch 248, change: 0.00053459\n",
            "Epoch 250, change: 0.00043134\n",
            "Epoch 283, change: 0.00011957\n",
            "Epoch 279, change: 0.00012648\n",
            "Epoch 284, change: 0.00014938\n",
            "Epoch 249, change: 0.00050409\n",
            "Epoch 250, change: 0.00076220\n",
            "Epoch 248, change: 0.00060902\n",
            "Epoch 251, change: 0.00084621\n",
            "Epoch 282, change: 0.00011325\n",
            "Epoch 251, change: 0.00042816\n",
            "Epoch 249, change: 0.00053128\n",
            "Epoch 284, change: 0.00011796\n",
            "Epoch 280, change: 0.00012487\n",
            "Epoch 285, change: 0.00014726\n",
            "\n",
            "At iterate  100    f=  2.28005D-01    |proj g|=  3.96574D-04\n",
            "Epoch 250, change: 0.00050066\n",
            "Epoch 251, change: 0.00075567\n",
            "Epoch 249, change: 0.00060322\n",
            "Epoch 252, change: 0.00042499\n",
            "Epoch 252, change: 0.00083871\n",
            "Epoch 283, change: 0.00011172\n",
            "Epoch 250, change: 0.00052712\n",
            "Epoch 286, change: 0.00014507\n",
            "Epoch 285, change: 0.00011639\n",
            "Epoch 281, change: 0.00012328\n",
            "Epoch 253, change: 0.00042171\n",
            "Epoch 251, change: 0.00049721\n",
            "Epoch 252, change: 0.00075041\n",
            "Epoch 253, change: 0.00083200\n",
            "Epoch 250, change: 0.00059795\n",
            "Epoch 284, change: 0.00011022\n",
            "Epoch 287, change: 0.00014297\n",
            "Epoch 286, change: 0.00011485\n",
            "Epoch 282, change: 0.00012170\n",
            "Epoch 251, change: 0.00052330\n",
            "Epoch 254, change: 0.00041839\n",
            "Epoch 252, change: 0.00049382\n",
            "Epoch 285, change: 0.00010873\n",
            "Epoch 254, change: 0.00082346\n",
            "Epoch 253, change: 0.00074384\n",
            "Epoch 251, change: 0.00059335\n",
            "Epoch 288, change: 0.00014083\n",
            "\n",
            "At iterate  150    f=  2.19493D-01    |proj g|=  2.73578D-04\n",
            "Epoch 287, change: 0.00011335\n",
            "Epoch 283, change: 0.00012013\n",
            "Epoch 252, change: 0.00051958\n",
            "Epoch 255, change: 0.00041539\n",
            "Epoch 286, change: 0.00010727\n",
            "Epoch 254, change: 0.00073820\n",
            "Epoch 289, change: 0.00013882\n",
            "Epoch 255, change: 0.00081778\n",
            "Epoch 253, change: 0.00049046\n",
            "Epoch 252, change: 0.00058745\n",
            "Epoch 288, change: 0.00011182\n",
            "Epoch 284, change: 0.00011859\n",
            "Epoch 253, change: 0.00051624\n",
            "Epoch 256, change: 0.00041233\n",
            "Epoch 287, change: 0.00010582\n",
            "Epoch 290, change: 0.00013683\n",
            "Epoch 254, change: 0.00048712\n",
            "Epoch 255, change: 0.00073336\n",
            "Epoch 256, change: 0.00080525\n",
            "\n",
            "At iterate  150    f=  2.21330D-01    |proj g|=  3.43288D-04\n",
            "Epoch 289, change: 0.00011031\n",
            "Epoch 253, change: 0.00058229\n",
            "Epoch 285, change: 0.00011707\n",
            "Epoch 254, change: 0.00051258\n",
            "Epoch 257, change: 0.00040923\n",
            "Epoch 288, change: 0.00010440\n",
            "Epoch 291, change: 0.00013487\n",
            "Epoch 256, change: 0.00072778\n",
            "Epoch 255, change: 0.00048379\n",
            "Epoch 257, change: 0.00079950\n",
            "Epoch 290, change: 0.00010884\n",
            "Epoch 254, change: 0.00057720\n",
            "Epoch 286, change: 0.00011558\n",
            "Epoch 255, change: 0.00050783\n",
            "Epoch 258, change: 0.00040618\n",
            "Epoch 289, change: 0.00010299\n",
            "Epoch 292, change: 0.00013294\n",
            "Epoch 257, change: 0.00072194\n",
            "Epoch 256, change: 0.00048049\n",
            "Epoch 291, change: 0.00010738\n",
            "Epoch 258, change: 0.00079231\n",
            "Epoch 255, change: 0.00057238\n",
            "\n",
            "At iterate  200    f=  2.17493D-01    |proj g|=  2.39255D-04\n",
            "Epoch 287, change: 0.00011411\n",
            "Epoch 256, change: 0.00050422\n",
            "Epoch 259, change: 0.00040308\n",
            "Epoch 290, change: 0.00010160\n",
            "Epoch 293, change: 0.00013104\n",
            "Epoch 259, change: 0.00078543\n",
            "Epoch 257, change: 0.00047721\n",
            "Epoch 258, change: 0.00071595\n",
            "Epoch 292, change: 0.00010594\n",
            "Epoch 256, change: 0.00056707\n",
            "Epoch 288, change: 0.00011264\n",
            "Epoch 257, change: 0.00050042\n",
            "Epoch 260, change: 0.00040014\n",
            "Epoch 294, change: 0.00012921\n",
            "Epoch 291, change: 0.00010023\n",
            "Epoch 293, change: 0.00010454\n",
            "Epoch 259, change: 0.00071068\n",
            "Epoch 260, change: 0.00077639\n",
            "Epoch 258, change: 0.00047397\n",
            "Epoch 257, change: 0.00056208\n",
            "Epoch 289, change: 0.00011119\n",
            "Epoch 258, change: 0.00049694\n",
            "\n",
            "At iterate  200    f=  2.19293D-01    |proj g|=  2.07331D-04\n",
            "Epoch 261, change: 0.00039724\n",
            "Epoch 295, change: 0.00012726\n",
            "convergence after 292 epochs took 308 seconds\n",
            "Epoch 294, change: 0.00010316\n",
            "Epoch 260, change: 0.00070542\n",
            "Epoch 261, change: 0.00077134\n",
            "Epoch 259, change: 0.00047076\n",
            "Epoch 290, change: 0.00010977\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    236    244      1     0     0   8.997D-05   2.169D-01\n",
            "  F =  0.21691900493881494     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.40563D-02\n",
            "Epoch 258, change: 0.00055762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 259, change: 0.00049351\n",
            "Epoch 262, change: 0.00039434\n",
            "Epoch 296, change: 0.00012545\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.77256D-02\n",
            "Epoch 295, change: 0.00010176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 262, change: 0.00076297\n",
            "Epoch 291, change: 0.00010837\n",
            "Epoch 261, change: 0.00070018\n",
            "Epoch 260, change: 0.00046756\n",
            "Epoch 259, change: 0.00055188\n",
            "Epoch 260, change: 0.00048980\n",
            "Epoch 263, change: 0.00039149\n",
            "Epoch 297, change: 0.00012350\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    225    240      1     0     0   9.598D-05   2.189D-01\n",
            "  F =  0.21886837990007435     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "Epoch 296, change: 0.00010039\n",
            "Epoch 292, change: 0.00010698\n",
            "Epoch 262, change: 0.00069516\n",
            "Epoch 263, change: 0.00075462\n",
            "Epoch 261, change: 0.00046433\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.75006D-02\n",
            "Epoch 260, change: 0.00054745\n",
            "Epoch 298, change: 0.00012178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 261, change: 0.00048573\n",
            "Epoch 264, change: 0.00038859\n",
            "convergence after 297 epochs took 311 seconds\n",
            "Epoch 263, change: 0.00068942\n",
            "Epoch 262, change: 0.00046118\n",
            "Epoch 293, change: 0.00010562\n",
            "Epoch 264, change: 0.00074972\n",
            "Epoch 299, change: 0.00011998\n",
            "Epoch 261, change: 0.00054245\n",
            "Epoch 262, change: 0.00048279\n",
            "Epoch 265, change: 0.00038578\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.74506D-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 264, change: 0.00068495\n",
            "Epoch 263, change: 0.00045806\n",
            "Epoch 294, change: 0.00010426\n",
            "\n",
            "At iterate   50    f=  2.57646D-01    |proj g|=  2.05869D-03\n",
            "Epoch 265, change: 0.00074191\n",
            "Epoch 300, change: 0.00011830\n",
            "Epoch 266, change: 0.00038298\n",
            "Epoch 262, change: 0.00053816\n",
            "Epoch 263, change: 0.00047945\n",
            "Epoch 265, change: 0.00068019\n",
            "Epoch 295, change: 0.00010293\n",
            "Epoch 264, change: 0.00045492\n",
            "\n",
            "At iterate   50    f=  2.51174D-01    |proj g|=  8.43499D-04\n",
            "Epoch 266, change: 0.00073668\n",
            "Epoch 301, change: 0.00011652\n",
            "Epoch 267, change: 0.00038020\n",
            "Epoch 263, change: 0.00053326\n",
            "Epoch 264, change: 0.00047629\n",
            "Epoch 266, change: 0.00067449\n",
            "Epoch 296, change: 0.00010161\n",
            "Epoch 268, change: 0.00037744\n",
            "Epoch 265, change: 0.00045183\n",
            "Epoch 302, change: 0.00011480\n",
            "Epoch 267, change: 0.00072672\n",
            "Epoch 264, change: 0.00052877\n",
            "Epoch 265, change: 0.00047218\n",
            "\n",
            "At iterate   50    f=  2.51098D-01    |proj g|=  1.17335D-03\n",
            "Epoch 269, change: 0.00037471\n",
            "Epoch 267, change: 0.00066911\n",
            "Epoch 297, change: 0.00010031\n",
            "Epoch 266, change: 0.00044876\n",
            "Epoch 303, change: 0.00011321\n",
            "Epoch 268, change: 0.00072144\n",
            "Epoch 265, change: 0.00052377\n",
            "Epoch 266, change: 0.00046785\n",
            "Epoch 270, change: 0.00037199\n",
            "\n",
            "At iterate  100    f=  2.34153D-01    |proj g|=  5.74130D-04\n",
            "convergence after 298 epochs took 317 seconds\n",
            "Epoch 268, change: 0.00066416\n",
            "Epoch 304, change: 0.00011150\n",
            "\n",
            "At iterate   50    f=  2.59041D-01    |proj g|=  1.61150D-03\n",
            "Epoch 267, change: 0.00044571\n",
            "Epoch 269, change: 0.00071463\n",
            "Epoch 266, change: 0.00051921\n",
            "Epoch 271, change: 0.00036927\n",
            "Epoch 267, change: 0.00046505\n",
            "Epoch 269, change: 0.00065909\n",
            "Epoch 305, change: 0.00010992\n",
            "Epoch 268, change: 0.00044269\n",
            "Epoch 270, change: 0.00070700\n",
            "Epoch 267, change: 0.00051460\n",
            "Epoch 272, change: 0.00036659\n",
            "Epoch 268, change: 0.00046188\n",
            "\n",
            "At iterate  100    f=  2.30368D-01    |proj g|=  3.75305D-04\n",
            "Epoch 270, change: 0.00065400\n",
            "Epoch 306, change: 0.00010841\n",
            "Epoch 269, change: 0.00043967\n",
            "Epoch 271, change: 0.00069996\n",
            "Epoch 268, change: 0.00051022\n",
            "Epoch 269, change: 0.00045812\n",
            "Epoch 273, change: 0.00036395\n",
            "Epoch 271, change: 0.00064924\n",
            "Epoch 307, change: 0.00010678\n",
            "Epoch 272, change: 0.00069494\n",
            "Epoch 270, change: 0.00043669\n",
            "\n",
            "At iterate  100    f=  2.30823D-01    |proj g|=  4.62179D-04\n",
            "Epoch 269, change: 0.00050571\n",
            "Epoch 270, change: 0.00045493\n",
            "Epoch 274, change: 0.00036130\n",
            "Epoch 272, change: 0.00064466\n",
            "Epoch 308, change: 0.00010527\n",
            "Epoch 273, change: 0.00068911\n",
            "Epoch 271, change: 0.00043371\n",
            "Epoch 270, change: 0.00050147\n",
            "\n",
            "At iterate  150    f=  2.27741D-01    |proj g|=  8.60072D-04\n",
            "Epoch 271, change: 0.00045133\n",
            "Epoch 275, change: 0.00035868\n",
            "\n",
            "At iterate  100    f=  2.36663D-01    |proj g|=  4.59939D-04\n",
            "Epoch 273, change: 0.00063952\n",
            "Epoch 309, change: 0.00010374\n",
            "Epoch 272, change: 0.00043076\n",
            "Epoch 274, change: 0.00068163\n",
            "Epoch 271, change: 0.00049696\n",
            "Epoch 276, change: 0.00035608\n",
            "Epoch 272, change: 0.00044786\n",
            "Epoch 274, change: 0.00063461\n",
            "Epoch 310, change: 0.00010222\n",
            "\n",
            "At iterate  150    f=  2.24908D-01    |proj g|=  2.55051D-04\n",
            "Epoch 275, change: 0.00067464\n",
            "Epoch 273, change: 0.00042785\n",
            "Epoch 272, change: 0.00049290\n",
            "Epoch 273, change: 0.00044500\n",
            "Epoch 277, change: 0.00035350\n",
            "Epoch 275, change: 0.00063035\n",
            "Epoch 311, change: 0.00010072\n",
            "Epoch 276, change: 0.00066971\n",
            "Epoch 274, change: 0.00042494\n",
            "Epoch 273, change: 0.00048835\n",
            "Epoch 274, change: 0.00044155\n",
            "Epoch 278, change: 0.00035094\n",
            "Epoch 276, change: 0.00062534\n",
            "convergence after 312 epochs took 325 seconds\n",
            "Epoch 277, change: 0.00066392\n",
            "Epoch 275, change: 0.00042207\n",
            "\n",
            "At iterate  150    f=  2.25270D-01    |proj g|=  2.46029D-04\n",
            "Epoch 279, change: 0.00034841\n",
            "Epoch 275, change: 0.00043835\n",
            "Epoch 274, change: 0.00048417\n",
            "Epoch 277, change: 0.00062059\n",
            "\n",
            "At iterate  200    f=  2.25512D-01    |proj g|=  5.93379D-04\n",
            "Epoch 278, change: 0.00065735\n",
            "Epoch 276, change: 0.00041918\n",
            "\n",
            "At iterate  150    f=  2.30723D-01    |proj g|=  3.15636D-04\n",
            "Epoch 280, change: 0.00034589\n",
            "Epoch 276, change: 0.00043485\n",
            "Epoch 275, change: 0.00048013\n",
            "Epoch 278, change: 0.00061604\n",
            "Epoch 279, change: 0.00065064\n",
            "Epoch 277, change: 0.00041634\n",
            "Epoch 277, change: 0.00043172\n",
            "Epoch 281, change: 0.00034339\n",
            "Epoch 276, change: 0.00047621\n",
            "Epoch 279, change: 0.00061119\n",
            "\n",
            "At iterate  200    f=  2.23098D-01    |proj g|=  7.30354D-04\n",
            "Epoch 280, change: 0.00064473\n",
            "Epoch 278, change: 0.00041351\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    226    236      1     0     0   9.580D-05   2.250D-01\n",
            "  F =  0.22501516174437450     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "Epoch 278, change: 0.00042863\n",
            "Epoch 282, change: 0.00034088\n",
            "Epoch 277, change: 0.00047136\n",
            "Epoch 280, change: 0.00060696\n",
            "Epoch 281, change: 0.00063778\n",
            "Epoch 279, change: 0.00041071\n",
            "Epoch 278, change: 0.00046785\n",
            "Epoch 279, change: 0.00042571\n",
            "Epoch 283, change: 0.00033842\n",
            "Epoch 281, change: 0.00060184\n",
            "\n",
            "At iterate  200    f=  2.23443D-01    |proj g|=  1.24995D-04\n",
            "Epoch 282, change: 0.00063242\n",
            "Epoch 280, change: 0.00040795\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    231    240      1     0     0   8.468D-05   2.226D-01\n",
            "  F =  0.22261627156838107     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "Epoch 284, change: 0.00033598\n",
            "Epoch 280, change: 0.00042219\n",
            "Epoch 279, change: 0.00046316\n",
            "Epoch 282, change: 0.00059757\n",
            "\n",
            "At iterate  200    f=  2.28983D-01    |proj g|=  1.57403D-04\n",
            "Epoch 283, change: 0.00062760\n",
            "Epoch 281, change: 0.00040518\n",
            "Epoch 285, change: 0.00033355\n",
            "Epoch 281, change: 0.00041901\n",
            "Epoch 280, change: 0.00045994\n",
            "Epoch 283, change: 0.00059346\n",
            "Epoch 284, change: 0.00062225\n",
            "Epoch 282, change: 0.00040245\n",
            "Epoch 286, change: 0.00033114\n",
            "Epoch 282, change: 0.00041581\n",
            "Epoch 281, change: 0.00045574\n",
            "Epoch 284, change: 0.00058902\n",
            "Epoch 285, change: 0.00061437\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    237    255      1     0     0   9.772D-05   2.229D-01\n",
            "  F =  0.22288823377694297     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "Epoch 283, change: 0.00039973\n",
            "Epoch 287, change: 0.00032875\n",
            "Epoch 283, change: 0.00041321\n",
            "Epoch 282, change: 0.00045088\n",
            "Epoch 285, change: 0.00058409\n",
            "Epoch 286, change: 0.00060944\n",
            "Epoch 284, change: 0.00039703\n",
            "Epoch 288, change: 0.00032637\n",
            "Epoch 284, change: 0.00040978\n",
            "Epoch 283, change: 0.00044799\n",
            "Epoch 286, change: 0.00058037\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    246    261      1     0     0   9.073D-05   2.284D-01\n",
            "  F =  0.22837426555392010     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "Epoch 287, change: 0.00060383\n",
            "Epoch 285, change: 0.00039435\n",
            "Epoch 289, change: 0.00032402\n",
            "Epoch 285, change: 0.00040706\n",
            "Epoch 284, change: 0.00044426\n",
            "Epoch 287, change: 0.00057597\n",
            "Epoch 288, change: 0.00059816\n",
            "Epoch 286, change: 0.00039158\n",
            "Epoch 290, change: 0.00032167\n",
            "Epoch 286, change: 0.00040410\n",
            "Epoch 285, change: 0.00043961\n",
            "Epoch 288, change: 0.00057107\n",
            "Epoch 289, change: 0.00059326\n",
            "Epoch 287, change: 0.00038897\n",
            "Epoch 291, change: 0.00031936\n",
            "Epoch 287, change: 0.00040130\n",
            "Epoch 286, change: 0.00043598\n",
            "Epoch 289, change: 0.00056687\n",
            "Epoch 290, change: 0.00058831\n",
            "Epoch 288, change: 0.00038635\n",
            "Epoch 292, change: 0.00031705\n",
            "Epoch 288, change: 0.00039778\n",
            "Epoch 287, change: 0.00043251\n",
            "Epoch 290, change: 0.00056314\n",
            "Epoch 291, change: 0.00058199\n",
            "Epoch 289, change: 0.00038369\n",
            "Epoch 289, change: 0.00039491\n",
            "Epoch 293, change: 0.00031475\n",
            "Epoch 288, change: 0.00042820\n",
            "Epoch 291, change: 0.00055832\n",
            "Epoch 292, change: 0.00057729\n",
            "Epoch 290, change: 0.00038112\n",
            "Epoch 290, change: 0.00039224\n",
            "Epoch 294, change: 0.00031248\n",
            "Epoch 292, change: 0.00055434\n",
            "Epoch 289, change: 0.00042466\n",
            "Epoch 293, change: 0.00057180\n",
            "Epoch 291, change: 0.00037853\n",
            "Epoch 291, change: 0.00038928\n",
            "Epoch 295, change: 0.00031024\n",
            "Epoch 293, change: 0.00055070\n",
            "Epoch 290, change: 0.00042088\n",
            "Epoch 294, change: 0.00056697\n",
            "Epoch 292, change: 0.00037598\n",
            "Epoch 296, change: 0.00030799\n",
            "Epoch 292, change: 0.00038650\n",
            "Epoch 294, change: 0.00054655\n",
            "Epoch 291, change: 0.00041728\n",
            "Epoch 295, change: 0.00056071\n",
            "Epoch 293, change: 0.00037345\n",
            "Epoch 297, change: 0.00030578\n",
            "Epoch 293, change: 0.00038369\n",
            "Epoch 295, change: 0.00054193\n",
            "Epoch 292, change: 0.00041387\n",
            "Epoch 296, change: 0.00055554\n",
            "Epoch 294, change: 0.00037089\n",
            "Epoch 298, change: 0.00030357\n",
            "Epoch 294, change: 0.00038074\n",
            "Epoch 296, change: 0.00053810\n",
            "Epoch 293, change: 0.00041045\n",
            "Epoch 297, change: 0.00055175\n",
            "Epoch 295, change: 0.00036839\n",
            "Epoch 295, change: 0.00037807\n",
            "Epoch 299, change: 0.00030139\n",
            "Epoch 297, change: 0.00053449\n",
            "Epoch 294, change: 0.00040630\n",
            "Epoch 298, change: 0.00054506\n",
            "Epoch 296, change: 0.00036591\n",
            "Epoch 296, change: 0.00037520\n",
            "Epoch 300, change: 0.00029923\n",
            "Epoch 298, change: 0.00052971\n",
            "Epoch 295, change: 0.00040351\n",
            "Epoch 299, change: 0.00054209\n",
            "Epoch 297, change: 0.00036344\n",
            "Epoch 297, change: 0.00037270\n",
            "Epoch 301, change: 0.00029706\n",
            "Epoch 299, change: 0.00052632\n",
            "Epoch 296, change: 0.00039914\n",
            "Epoch 300, change: 0.00053694\n",
            "Epoch 298, change: 0.00036096\n",
            "Epoch 298, change: 0.00037019\n",
            "Epoch 302, change: 0.00029492\n",
            "Epoch 300, change: 0.00052213\n",
            "Epoch 301, change: 0.00053216\n",
            "Epoch 297, change: 0.00039618\n",
            "Epoch 299, change: 0.00035854\n",
            "Epoch 299, change: 0.00036721\n",
            "Epoch 303, change: 0.00029279\n",
            "Epoch 301, change: 0.00051858\n",
            "Epoch 302, change: 0.00052838\n",
            "Epoch 298, change: 0.00039253\n",
            "Epoch 300, change: 0.00035612\n",
            "Epoch 300, change: 0.00036458\n",
            "Epoch 304, change: 0.00029069\n",
            "Epoch 302, change: 0.00051442\n",
            "Epoch 303, change: 0.00052233\n",
            "Epoch 299, change: 0.00038920\n",
            "Epoch 301, change: 0.00035368\n",
            "Epoch 301, change: 0.00036200\n",
            "Epoch 303, change: 0.00051061\n",
            "Epoch 305, change: 0.00028859\n",
            "Epoch 304, change: 0.00051817\n",
            "Epoch 300, change: 0.00038618\n",
            "Epoch 302, change: 0.00035130\n",
            "Epoch 302, change: 0.00035843\n",
            "Epoch 305, change: 0.00051066\n",
            "Epoch 304, change: 0.00050712\n",
            "Epoch 306, change: 0.00028652\n",
            "Epoch 301, change: 0.00038248\n",
            "Epoch 303, change: 0.00034894\n",
            "Epoch 303, change: 0.00035622\n",
            "Epoch 306, change: 0.00050784\n",
            "Epoch 305, change: 0.00050352\n",
            "Epoch 307, change: 0.00028445\n",
            "Epoch 302, change: 0.00037940\n",
            "Epoch 304, change: 0.00034657\n",
            "Epoch 307, change: 0.00050202\n",
            "Epoch 304, change: 0.00035371\n",
            "Epoch 306, change: 0.00049961\n",
            "Epoch 308, change: 0.00028240\n",
            "Epoch 303, change: 0.00037602\n",
            "Epoch 305, change: 0.00034423\n",
            "Epoch 308, change: 0.00049779\n",
            "Epoch 305, change: 0.00035099\n",
            "Epoch 307, change: 0.00049605\n",
            "Epoch 309, change: 0.00028038\n",
            "Epoch 304, change: 0.00037272\n",
            "Epoch 306, change: 0.00034192\n",
            "Epoch 309, change: 0.00049387\n",
            "Epoch 306, change: 0.00034836\n",
            "Epoch 308, change: 0.00049236\n",
            "Epoch 310, change: 0.00027835\n",
            "Epoch 305, change: 0.00036984\n",
            "Epoch 307, change: 0.00033962\n",
            "Epoch 310, change: 0.00048901\n",
            "Epoch 307, change: 0.00034587\n",
            "Epoch 309, change: 0.00048846\n",
            "Epoch 311, change: 0.00027636\n",
            "Epoch 306, change: 0.00036699\n",
            "Epoch 308, change: 0.00033729\n",
            "Epoch 311, change: 0.00048479\n",
            "Epoch 308, change: 0.00034339\n",
            "Epoch 310, change: 0.00048460\n",
            "Epoch 312, change: 0.00027437\n",
            "Epoch 307, change: 0.00036394\n",
            "Epoch 309, change: 0.00033502\n",
            "Epoch 312, change: 0.00048141\n",
            "Epoch 309, change: 0.00034065\n",
            "Epoch 311, change: 0.00048137\n",
            "Epoch 313, change: 0.00027240\n",
            "Epoch 308, change: 0.00035962\n",
            "Epoch 310, change: 0.00033277\n",
            "Epoch 313, change: 0.00047565\n",
            "Epoch 310, change: 0.00033824\n",
            "Epoch 312, change: 0.00047769\n",
            "Epoch 314, change: 0.00027045\n",
            "Epoch 309, change: 0.00035695\n",
            "Epoch 311, change: 0.00033054\n",
            "Epoch 314, change: 0.00047193\n",
            "Epoch 311, change: 0.00033602\n",
            "Epoch 313, change: 0.00047413\n",
            "Epoch 315, change: 0.00026849\n",
            "Epoch 310, change: 0.00035396\n",
            "Epoch 312, change: 0.00032828\n",
            "Epoch 315, change: 0.00046763\n",
            "Epoch 312, change: 0.00033319\n",
            "Epoch 314, change: 0.00047072\n",
            "Epoch 316, change: 0.00026656\n",
            "Epoch 311, change: 0.00035100\n",
            "Epoch 313, change: 0.00032608\n",
            "Epoch 316, change: 0.00046282\n",
            "Epoch 315, change: 0.00046742\n",
            "Epoch 313, change: 0.00033107\n",
            "Epoch 317, change: 0.00026465\n",
            "Epoch 312, change: 0.00034829\n",
            "Epoch 314, change: 0.00032387\n",
            "Epoch 317, change: 0.00045962\n",
            "Epoch 316, change: 0.00046389\n",
            "Epoch 314, change: 0.00032832\n",
            "Epoch 318, change: 0.00026274\n",
            "Epoch 313, change: 0.00034451\n",
            "Epoch 315, change: 0.00032170\n",
            "Epoch 318, change: 0.00045484\n",
            "Epoch 317, change: 0.00046046\n",
            "Epoch 315, change: 0.00032638\n",
            "Epoch 319, change: 0.00026086\n",
            "Epoch 314, change: 0.00034212\n",
            "Epoch 316, change: 0.00031952\n",
            "Epoch 319, change: 0.00045211\n",
            "Epoch 318, change: 0.00045700\n",
            "Epoch 316, change: 0.00032427\n",
            "Epoch 320, change: 0.00025898\n",
            "Epoch 315, change: 0.00033929\n",
            "Epoch 317, change: 0.00031737\n",
            "Epoch 320, change: 0.00044695\n",
            "Epoch 319, change: 0.00045384\n",
            "Epoch 317, change: 0.00032092\n",
            "Epoch 321, change: 0.00025712\n",
            "Epoch 316, change: 0.00033593\n",
            "Epoch 318, change: 0.00031522\n",
            "Epoch 321, change: 0.00044187\n",
            "Epoch 320, change: 0.00045032\n",
            "Epoch 318, change: 0.00031875\n",
            "Epoch 322, change: 0.00025528\n",
            "Epoch 317, change: 0.00033315\n",
            "Epoch 319, change: 0.00031310\n",
            "Epoch 322, change: 0.00043872\n",
            "Epoch 321, change: 0.00044677\n",
            "Epoch 319, change: 0.00031651\n",
            "Epoch 323, change: 0.00025346\n",
            "Epoch 318, change: 0.00033043\n",
            "Epoch 320, change: 0.00031098\n",
            "Epoch 323, change: 0.00043467\n",
            "Epoch 322, change: 0.00044356\n",
            "Epoch 320, change: 0.00031439\n",
            "Epoch 324, change: 0.00025163\n",
            "Epoch 319, change: 0.00032745\n",
            "Epoch 321, change: 0.00030889\n",
            "Epoch 324, change: 0.00043112\n",
            "Epoch 323, change: 0.00044032\n",
            "Epoch 321, change: 0.00031192\n",
            "Epoch 325, change: 0.00024983\n",
            "Epoch 320, change: 0.00032501\n",
            "Epoch 322, change: 0.00030680\n",
            "Epoch 325, change: 0.00042723\n",
            "Epoch 324, change: 0.00043730\n",
            "Epoch 322, change: 0.00030957\n",
            "Epoch 326, change: 0.00024802\n",
            "Epoch 321, change: 0.00032215\n",
            "Epoch 323, change: 0.00030475\n",
            "Epoch 326, change: 0.00042420\n",
            "Epoch 325, change: 0.00043420\n",
            "Epoch 323, change: 0.00030724\n",
            "Epoch 327, change: 0.00024625\n",
            "Epoch 322, change: 0.00031959\n",
            "Epoch 327, change: 0.00041832\n",
            "Epoch 324, change: 0.00030269\n",
            "Epoch 326, change: 0.00043104\n",
            "Epoch 324, change: 0.00030508\n",
            "Epoch 328, change: 0.00024449\n",
            "Epoch 323, change: 0.00031706\n",
            "Epoch 328, change: 0.00041626\n",
            "Epoch 325, change: 0.00030066\n",
            "Epoch 327, change: 0.00042695\n",
            "Epoch 325, change: 0.00030298\n",
            "Epoch 329, change: 0.00024275\n",
            "Epoch 324, change: 0.00031311\n",
            "Epoch 329, change: 0.00041087\n",
            "Epoch 326, change: 0.00029861\n",
            "Epoch 328, change: 0.00042454\n",
            "Epoch 326, change: 0.00030045\n",
            "Epoch 330, change: 0.00024098\n",
            "Epoch 325, change: 0.00031097\n",
            "Epoch 330, change: 0.00040790\n",
            "Epoch 327, change: 0.00029662\n",
            "Epoch 329, change: 0.00042108\n",
            "Epoch 327, change: 0.00029840\n",
            "Epoch 331, change: 0.00023927\n",
            "Epoch 326, change: 0.00030859\n",
            "Epoch 331, change: 0.00040499\n",
            "Epoch 328, change: 0.00029463\n",
            "Epoch 330, change: 0.00041812\n",
            "Epoch 328, change: 0.00029604\n",
            "Epoch 332, change: 0.00023755\n",
            "Epoch 327, change: 0.00030621\n",
            "Epoch 332, change: 0.00040075\n",
            "Epoch 329, change: 0.00029262\n",
            "Epoch 331, change: 0.00041501\n",
            "Epoch 329, change: 0.00029414\n",
            "Epoch 333, change: 0.00023584\n",
            "Epoch 328, change: 0.00030353\n",
            "Epoch 333, change: 0.00039716\n",
            "Epoch 330, change: 0.00029066\n",
            "Epoch 332, change: 0.00041223\n",
            "Epoch 330, change: 0.00029200\n",
            "Epoch 334, change: 0.00023416\n",
            "Epoch 329, change: 0.00030118\n",
            "Epoch 334, change: 0.00039342\n",
            "Epoch 331, change: 0.00028871\n",
            "Epoch 333, change: 0.00040937\n",
            "Epoch 331, change: 0.00029011\n",
            "Epoch 335, change: 0.00023247\n",
            "Epoch 330, change: 0.00029888\n",
            "Epoch 335, change: 0.00039072\n",
            "Epoch 332, change: 0.00028677\n",
            "Epoch 334, change: 0.00040615\n",
            "Epoch 332, change: 0.00028782\n",
            "Epoch 336, change: 0.00023081\n",
            "Epoch 331, change: 0.00029622\n",
            "Epoch 336, change: 0.00038693\n",
            "Epoch 333, change: 0.00028485\n",
            "Epoch 335, change: 0.00040324\n",
            "Epoch 333, change: 0.00028572\n",
            "Epoch 337, change: 0.00022917\n",
            "Epoch 332, change: 0.00029263\n",
            "Epoch 337, change: 0.00038315\n",
            "Epoch 334, change: 0.00028289\n",
            "Epoch 336, change: 0.00040049\n",
            "Epoch 334, change: 0.00028308\n",
            "Epoch 338, change: 0.00022753\n",
            "Epoch 333, change: 0.00029048\n",
            "Epoch 338, change: 0.00038045\n",
            "Epoch 335, change: 0.00028100\n",
            "Epoch 337, change: 0.00039670\n",
            "Epoch 335, change: 0.00028146\n",
            "Epoch 339, change: 0.00022587\n",
            "Epoch 334, change: 0.00028819\n",
            "Epoch 339, change: 0.00037684\n",
            "Epoch 336, change: 0.00027912\n",
            "Epoch 338, change: 0.00039418\n",
            "Epoch 336, change: 0.00027932\n",
            "Epoch 340, change: 0.00022427\n",
            "Epoch 335, change: 0.00028583\n",
            "Epoch 340, change: 0.00037355\n",
            "Epoch 337, change: 0.00027723\n",
            "Epoch 339, change: 0.00039129\n",
            "Epoch 337, change: 0.00027687\n",
            "Epoch 341, change: 0.00022265\n",
            "Epoch 336, change: 0.00028361\n",
            "Epoch 341, change: 0.00036890\n",
            "Epoch 338, change: 0.00027537\n",
            "Epoch 340, change: 0.00038848\n",
            "Epoch 338, change: 0.00027525\n",
            "Epoch 342, change: 0.00022106\n",
            "Epoch 342, change: 0.00036658\n",
            "Epoch 337, change: 0.00028109\n",
            "Epoch 339, change: 0.00027351\n",
            "Epoch 341, change: 0.00038536\n",
            "Epoch 339, change: 0.00027278\n",
            "Epoch 343, change: 0.00021949\n",
            "Epoch 343, change: 0.00036310\n",
            "Epoch 338, change: 0.00027896\n",
            "Epoch 340, change: 0.00027167\n",
            "Epoch 342, change: 0.00038260\n",
            "Epoch 340, change: 0.00027121\n",
            "Epoch 344, change: 0.00021790\n",
            "Epoch 344, change: 0.00035984\n",
            "Epoch 339, change: 0.00027537\n",
            "Epoch 341, change: 0.00026984\n",
            "Epoch 343, change: 0.00037994\n",
            "Epoch 341, change: 0.00026896\n",
            "Epoch 345, change: 0.00021635\n",
            "Epoch 345, change: 0.00035715\n",
            "Epoch 340, change: 0.00027328\n",
            "Epoch 342, change: 0.00026804\n",
            "Epoch 344, change: 0.00037703\n",
            "Epoch 342, change: 0.00026704\n",
            "Epoch 346, change: 0.00021480\n",
            "Epoch 346, change: 0.00035352\n",
            "Epoch 341, change: 0.00027114\n",
            "Epoch 343, change: 0.00026622\n",
            "Epoch 345, change: 0.00037458\n",
            "Epoch 343, change: 0.00026536\n",
            "Epoch 347, change: 0.00021327\n",
            "Epoch 347, change: 0.00035017\n",
            "Epoch 342, change: 0.00026900\n",
            "Epoch 344, change: 0.00026443\n",
            "Epoch 346, change: 0.00037198\n",
            "Epoch 344, change: 0.00026363\n",
            "Epoch 348, change: 0.00021173\n",
            "Epoch 348, change: 0.00034794\n",
            "Epoch 343, change: 0.00026637\n",
            "Epoch 345, change: 0.00026266\n",
            "Epoch 347, change: 0.00036859\n",
            "Epoch 345, change: 0.00026129\n",
            "Epoch 349, change: 0.00021023\n",
            "Epoch 349, change: 0.00034412\n",
            "Epoch 344, change: 0.00026411\n",
            "Epoch 346, change: 0.00026090\n",
            "Epoch 348, change: 0.00036598\n",
            "Epoch 346, change: 0.00025892\n",
            "Epoch 350, change: 0.00020870\n",
            "Epoch 350, change: 0.00034160\n",
            "Epoch 345, change: 0.00026183\n",
            "Epoch 347, change: 0.00025914\n",
            "Epoch 349, change: 0.00036346\n",
            "Epoch 347, change: 0.00025746\n",
            "Epoch 351, change: 0.00020722\n",
            "Epoch 351, change: 0.00033860\n",
            "Epoch 346, change: 0.00025990\n",
            "Epoch 348, change: 0.00025740\n",
            "Epoch 350, change: 0.00036072\n",
            "Epoch 348, change: 0.00025560\n",
            "Epoch 352, change: 0.00020573\n",
            "Epoch 352, change: 0.00033479\n",
            "Epoch 347, change: 0.00025748\n",
            "Epoch 349, change: 0.00025566\n",
            "Epoch 351, change: 0.00035813\n",
            "Epoch 349, change: 0.00025345\n",
            "Epoch 353, change: 0.00020427\n",
            "Epoch 353, change: 0.00033221\n",
            "Epoch 348, change: 0.00025541\n",
            "Epoch 350, change: 0.00025395\n",
            "Epoch 352, change: 0.00035552\n",
            "Epoch 350, change: 0.00025181\n",
            "Epoch 354, change: 0.00032930\n",
            "Epoch 354, change: 0.00020280\n",
            "Epoch 349, change: 0.00025312\n",
            "Epoch 351, change: 0.00025223\n",
            "Epoch 353, change: 0.00035296\n",
            "Epoch 351, change: 0.00024981\n",
            "Epoch 355, change: 0.00032667\n",
            "Epoch 355, change: 0.00020136\n",
            "Epoch 350, change: 0.00025113\n",
            "Epoch 352, change: 0.00025054\n",
            "Epoch 354, change: 0.00035038\n",
            "Epoch 352, change: 0.00024813\n",
            "Epoch 356, change: 0.00032432\n",
            "Epoch 356, change: 0.00019991\n",
            "Epoch 351, change: 0.00024877\n",
            "Epoch 353, change: 0.00024886\n",
            "Epoch 355, change: 0.00034772\n",
            "Epoch 353, change: 0.00024610\n",
            "Epoch 357, change: 0.00031990\n",
            "Epoch 357, change: 0.00019848\n",
            "Epoch 352, change: 0.00024686\n",
            "Epoch 354, change: 0.00024719\n",
            "Epoch 356, change: 0.00034522\n",
            "Epoch 358, change: 0.00031777\n",
            "Epoch 354, change: 0.00024423\n",
            "Epoch 358, change: 0.00019706\n",
            "Epoch 353, change: 0.00024456\n",
            "Epoch 355, change: 0.00024554\n",
            "Epoch 357, change: 0.00034278\n",
            "Epoch 359, change: 0.00031491\n",
            "Epoch 355, change: 0.00024284\n",
            "Epoch 359, change: 0.00019566\n",
            "Epoch 354, change: 0.00024256\n",
            "Epoch 356, change: 0.00024389\n",
            "Epoch 358, change: 0.00034043\n",
            "Epoch 360, change: 0.00031279\n",
            "Epoch 356, change: 0.00024082\n",
            "Epoch 360, change: 0.00019426\n",
            "Epoch 355, change: 0.00024066\n",
            "Epoch 357, change: 0.00024222\n",
            "Epoch 359, change: 0.00033757\n",
            "Epoch 361, change: 0.00030927\n",
            "Epoch 357, change: 0.00023896\n",
            "Epoch 361, change: 0.00019286\n",
            "Epoch 356, change: 0.00023863\n",
            "Epoch 358, change: 0.00024062\n",
            "Epoch 360, change: 0.00033536\n",
            "Epoch 362, change: 0.00030693\n",
            "Epoch 358, change: 0.00023709\n",
            "Epoch 362, change: 0.00019149\n",
            "Epoch 357, change: 0.00023621\n",
            "Epoch 359, change: 0.00023898\n",
            "Epoch 361, change: 0.00033273\n",
            "Epoch 363, change: 0.00030395\n",
            "Epoch 359, change: 0.00023564\n",
            "Epoch 363, change: 0.00019012\n",
            "Epoch 358, change: 0.00023444\n",
            "Epoch 360, change: 0.00023738\n",
            "Epoch 362, change: 0.00033029\n",
            "Epoch 364, change: 0.00030187\n",
            "Epoch 360, change: 0.00023398\n",
            "Epoch 364, change: 0.00018875\n",
            "Epoch 359, change: 0.00023255\n",
            "Epoch 361, change: 0.00023580\n",
            "Epoch 363, change: 0.00032809\n",
            "Epoch 365, change: 0.00029828\n",
            "Epoch 361, change: 0.00023214\n",
            "Epoch 365, change: 0.00018741\n",
            "Epoch 360, change: 0.00023048\n",
            "Epoch 362, change: 0.00023420\n",
            "Epoch 366, change: 0.00029659\n",
            "Epoch 364, change: 0.00032549\n",
            "Epoch 362, change: 0.00023052\n",
            "Epoch 366, change: 0.00018607\n",
            "Epoch 361, change: 0.00022844\n",
            "Epoch 363, change: 0.00023264\n",
            "Epoch 367, change: 0.00029309\n",
            "Epoch 365, change: 0.00032334\n",
            "Epoch 363, change: 0.00022902\n",
            "Epoch 367, change: 0.00018475\n",
            "Epoch 362, change: 0.00022659\n",
            "Epoch 364, change: 0.00023107\n",
            "Epoch 368, change: 0.00029091\n",
            "Epoch 366, change: 0.00032098\n",
            "Epoch 364, change: 0.00022692\n",
            "Epoch 368, change: 0.00018342\n",
            "Epoch 363, change: 0.00022456\n",
            "Epoch 365, change: 0.00022952\n",
            "Epoch 369, change: 0.00028897\n",
            "Epoch 367, change: 0.00031834\n",
            "Epoch 365, change: 0.00022528\n",
            "Epoch 369, change: 0.00018211\n",
            "Epoch 364, change: 0.00022295\n",
            "Epoch 366, change: 0.00022799\n",
            "Epoch 370, change: 0.00028545\n",
            "Epoch 368, change: 0.00031624\n",
            "Epoch 366, change: 0.00022367\n",
            "Epoch 370, change: 0.00018081\n",
            "Epoch 365, change: 0.00022076\n",
            "Epoch 367, change: 0.00022645\n",
            "Epoch 371, change: 0.00028315\n",
            "Epoch 369, change: 0.00031385\n",
            "Epoch 367, change: 0.00022214\n",
            "Epoch 371, change: 0.00017952\n",
            "Epoch 366, change: 0.00021902\n",
            "Epoch 368, change: 0.00022493\n",
            "Epoch 372, change: 0.00028101\n",
            "Epoch 370, change: 0.00031145\n",
            "Epoch 368, change: 0.00022028\n",
            "Epoch 372, change: 0.00017823\n",
            "Epoch 367, change: 0.00021738\n",
            "Epoch 369, change: 0.00022342\n",
            "Epoch 373, change: 0.00027795\n",
            "Epoch 371, change: 0.00030921\n",
            "Epoch 369, change: 0.00021887\n",
            "Epoch 373, change: 0.00017696\n",
            "Epoch 368, change: 0.00021529\n",
            "Epoch 370, change: 0.00022192\n",
            "Epoch 374, change: 0.00027614\n",
            "Epoch 372, change: 0.00030706\n",
            "Epoch 370, change: 0.00021745\n",
            "Epoch 374, change: 0.00017570\n",
            "Epoch 369, change: 0.00021360\n",
            "Epoch 371, change: 0.00022044\n",
            "Epoch 375, change: 0.00027360\n",
            "Epoch 373, change: 0.00030473\n",
            "Epoch 371, change: 0.00021606\n",
            "Epoch 375, change: 0.00017444\n",
            "Epoch 370, change: 0.00021164\n",
            "Epoch 372, change: 0.00021895\n",
            "Epoch 376, change: 0.00027066\n",
            "Epoch 374, change: 0.00030273\n",
            "Epoch 372, change: 0.00021467\n",
            "Epoch 376, change: 0.00017320\n",
            "Epoch 371, change: 0.00020992\n",
            "Epoch 377, change: 0.00026908\n",
            "Epoch 373, change: 0.00021749\n",
            "Epoch 375, change: 0.00030042\n",
            "Epoch 373, change: 0.00021330\n",
            "Epoch 377, change: 0.00017195\n",
            "Epoch 372, change: 0.00020815\n",
            "Epoch 378, change: 0.00026618\n",
            "Epoch 374, change: 0.00021602\n",
            "Epoch 376, change: 0.00029799\n",
            "Epoch 374, change: 0.00021192\n",
            "Epoch 378, change: 0.00017073\n",
            "Epoch 373, change: 0.00020635\n",
            "Epoch 379, change: 0.00026369\n",
            "Epoch 375, change: 0.00021457\n",
            "Epoch 377, change: 0.00029596\n",
            "Epoch 375, change: 0.00021056\n",
            "Epoch 379, change: 0.00016951\n",
            "Epoch 374, change: 0.00020467\n",
            "Epoch 380, change: 0.00026162\n",
            "Epoch 376, change: 0.00021314\n",
            "Epoch 378, change: 0.00029380\n",
            "Epoch 376, change: 0.00020920\n",
            "Epoch 380, change: 0.00016831\n",
            "Epoch 375, change: 0.00020283\n",
            "Epoch 381, change: 0.00025936\n",
            "Epoch 377, change: 0.00021172\n",
            "Epoch 379, change: 0.00029173\n",
            "Epoch 377, change: 0.00020787\n",
            "Epoch 381, change: 0.00016710\n",
            "Epoch 376, change: 0.00020126\n",
            "Epoch 382, change: 0.00025709\n",
            "Epoch 378, change: 0.00021030\n",
            "Epoch 380, change: 0.00028966\n",
            "Epoch 378, change: 0.00020653\n",
            "Epoch 382, change: 0.00016591\n",
            "Epoch 377, change: 0.00019950\n",
            "Epoch 383, change: 0.00025478\n",
            "Epoch 379, change: 0.00020886\n",
            "Epoch 381, change: 0.00028744\n",
            "Epoch 379, change: 0.00020522\n",
            "Epoch 383, change: 0.00016472\n",
            "Epoch 378, change: 0.00019780\n",
            "Epoch 384, change: 0.00025252\n",
            "Epoch 380, change: 0.00020748\n",
            "Epoch 382, change: 0.00028539\n",
            "Epoch 380, change: 0.00020390\n",
            "Epoch 384, change: 0.00016355\n",
            "Epoch 385, change: 0.00025034\n",
            "Epoch 379, change: 0.00019608\n",
            "Epoch 381, change: 0.00020608\n",
            "Epoch 383, change: 0.00028327\n",
            "Epoch 381, change: 0.00020260\n",
            "Epoch 385, change: 0.00016237\n",
            "Epoch 386, change: 0.00024854\n",
            "Epoch 380, change: 0.00019463\n",
            "Epoch 382, change: 0.00020470\n",
            "Epoch 384, change: 0.00028127\n",
            "Epoch 382, change: 0.00020131\n",
            "Epoch 386, change: 0.00016122\n",
            "Epoch 387, change: 0.00024690\n",
            "Epoch 381, change: 0.00019276\n",
            "Epoch 383, change: 0.00020333\n",
            "Epoch 385, change: 0.00027918\n",
            "Epoch 383, change: 0.00020002\n",
            "Epoch 387, change: 0.00016007\n",
            "Epoch 388, change: 0.00024325\n",
            "Epoch 382, change: 0.00019136\n",
            "Epoch 384, change: 0.00020197\n",
            "Epoch 386, change: 0.00027708\n",
            "Epoch 384, change: 0.00019875\n",
            "Epoch 388, change: 0.00015893\n",
            "Epoch 389, change: 0.00024187\n",
            "Epoch 383, change: 0.00018976\n",
            "Epoch 385, change: 0.00020060\n",
            "Epoch 387, change: 0.00027525\n",
            "Epoch 385, change: 0.00019747\n",
            "Epoch 389, change: 0.00015780\n",
            "Epoch 390, change: 0.00023966\n",
            "Epoch 384, change: 0.00018783\n",
            "Epoch 386, change: 0.00019927\n",
            "Epoch 388, change: 0.00027305\n",
            "Epoch 386, change: 0.00019622\n",
            "Epoch 390, change: 0.00015666\n",
            "Epoch 391, change: 0.00023827\n",
            "Epoch 385, change: 0.00018650\n",
            "Epoch 387, change: 0.00019794\n",
            "Epoch 389, change: 0.00027121\n",
            "Epoch 387, change: 0.00019497\n",
            "Epoch 391, change: 0.00015554\n",
            "Epoch 392, change: 0.00023521\n",
            "Epoch 386, change: 0.00018473\n",
            "Epoch 388, change: 0.00019659\n",
            "Epoch 390, change: 0.00026910\n",
            "Epoch 388, change: 0.00019373\n",
            "Epoch 392, change: 0.00015444\n",
            "Epoch 393, change: 0.00023342\n",
            "Epoch 387, change: 0.00018326\n",
            "Epoch 389, change: 0.00019528\n",
            "Epoch 391, change: 0.00026725\n",
            "Epoch 389, change: 0.00019249\n",
            "Epoch 393, change: 0.00015333\n",
            "Epoch 394, change: 0.00023118\n",
            "Epoch 388, change: 0.00018162\n",
            "Epoch 390, change: 0.00019397\n",
            "Epoch 392, change: 0.00026547\n",
            "Epoch 390, change: 0.00019126\n",
            "Epoch 394, change: 0.00015224\n",
            "Epoch 395, change: 0.00022970\n",
            "Epoch 389, change: 0.00018009\n",
            "Epoch 391, change: 0.00019267\n",
            "Epoch 393, change: 0.00026338\n",
            "Epoch 391, change: 0.00019004\n",
            "Epoch 395, change: 0.00015115\n",
            "Epoch 396, change: 0.00022667\n",
            "Epoch 390, change: 0.00017872\n",
            "Epoch 392, change: 0.00019139\n",
            "Epoch 394, change: 0.00026155\n",
            "Epoch 392, change: 0.00018883\n",
            "Epoch 396, change: 0.00015008\n",
            "Epoch 397, change: 0.00022544\n",
            "Epoch 391, change: 0.00017711\n",
            "Epoch 393, change: 0.00019009\n",
            "Epoch 395, change: 0.00025950\n",
            "Epoch 393, change: 0.00018763\n",
            "Epoch 397, change: 0.00014900\n",
            "Epoch 398, change: 0.00022314\n",
            "Epoch 392, change: 0.00017567\n",
            "Epoch 394, change: 0.00018882\n",
            "Epoch 396, change: 0.00025779\n",
            "Epoch 394, change: 0.00018642\n",
            "Epoch 398, change: 0.00014795\n",
            "Epoch 399, change: 0.00022138\n",
            "Epoch 393, change: 0.00017433\n",
            "Epoch 395, change: 0.00018756\n",
            "Epoch 397, change: 0.00025585\n",
            "Epoch 395, change: 0.00018524\n",
            "Epoch 399, change: 0.00014688\n",
            "Epoch 400, change: 0.00021953\n",
            "Epoch 394, change: 0.00017275\n",
            "Epoch 396, change: 0.00018630\n",
            "Epoch 398, change: 0.00025388\n",
            "Epoch 396, change: 0.00018407\n",
            "Epoch 400, change: 0.00014584\n",
            "Epoch 401, change: 0.00021731\n",
            "Epoch 395, change: 0.00017128\n",
            "Epoch 397, change: 0.00018505\n",
            "Epoch 399, change: 0.00025217\n",
            "Epoch 397, change: 0.00018288\n",
            "Epoch 402, change: 0.00021587\n",
            "Epoch 401, change: 0.00014480\n",
            "Epoch 396, change: 0.00016991\n",
            "Epoch 398, change: 0.00018382\n",
            "Epoch 400, change: 0.00025020\n",
            "Epoch 398, change: 0.00018173\n",
            "Epoch 403, change: 0.00021396\n",
            "Epoch 402, change: 0.00014377\n",
            "Epoch 397, change: 0.00016862\n",
            "Epoch 399, change: 0.00018257\n",
            "Epoch 401, change: 0.00024850\n",
            "Epoch 399, change: 0.00018056\n",
            "Epoch 404, change: 0.00021223\n",
            "Epoch 403, change: 0.00014275\n",
            "Epoch 398, change: 0.00016720\n",
            "Epoch 400, change: 0.00018135\n",
            "Epoch 402, change: 0.00024660\n",
            "Epoch 400, change: 0.00017942\n",
            "Epoch 405, change: 0.00020953\n",
            "Epoch 404, change: 0.00014172\n",
            "Epoch 399, change: 0.00016535\n",
            "Epoch 401, change: 0.00018014\n",
            "Epoch 403, change: 0.00024493\n",
            "Epoch 401, change: 0.00017827\n",
            "Epoch 406, change: 0.00020827\n",
            "Epoch 405, change: 0.00014071\n",
            "Epoch 400, change: 0.00016429\n",
            "Epoch 402, change: 0.00017893\n",
            "Epoch 404, change: 0.00024325\n",
            "Epoch 402, change: 0.00017714\n",
            "Epoch 407, change: 0.00020647\n",
            "Epoch 406, change: 0.00013971\n",
            "Epoch 401, change: 0.00016279\n",
            "Epoch 403, change: 0.00017773\n",
            "Epoch 405, change: 0.00024126\n",
            "Epoch 403, change: 0.00017601\n",
            "Epoch 408, change: 0.00020423\n",
            "Epoch 407, change: 0.00013871\n",
            "Epoch 402, change: 0.00016132\n",
            "Epoch 404, change: 0.00017654\n",
            "Epoch 406, change: 0.00023966\n",
            "Epoch 404, change: 0.00017489\n",
            "Epoch 409, change: 0.00020309\n",
            "Epoch 408, change: 0.00013773\n",
            "Epoch 403, change: 0.00016003\n",
            "Epoch 405, change: 0.00017537\n",
            "Epoch 407, change: 0.00023789\n",
            "Epoch 405, change: 0.00017377\n",
            "Epoch 410, change: 0.00020138\n",
            "Epoch 409, change: 0.00013675\n",
            "Epoch 404, change: 0.00015878\n",
            "Epoch 406, change: 0.00017418\n",
            "Epoch 408, change: 0.00023629\n",
            "Epoch 411, change: 0.00019944\n",
            "Epoch 406, change: 0.00017267\n",
            "Epoch 410, change: 0.00013578\n",
            "Epoch 405, change: 0.00015732\n",
            "Epoch 407, change: 0.00017303\n",
            "Epoch 409, change: 0.00023435\n",
            "Epoch 412, change: 0.00019776\n",
            "Epoch 407, change: 0.00017157\n",
            "Epoch 411, change: 0.00013478\n",
            "Epoch 408, change: 0.00017186\n",
            "Epoch 406, change: 0.00015611\n",
            "Epoch 410, change: 0.00023267\n",
            "Epoch 413, change: 0.00019567\n",
            "Epoch 408, change: 0.00017048\n",
            "Epoch 412, change: 0.00013384\n",
            "Epoch 409, change: 0.00017071\n",
            "Epoch 407, change: 0.00015491\n",
            "Epoch 411, change: 0.00023112\n",
            "Epoch 414, change: 0.00019448\n",
            "Epoch 409, change: 0.00016939\n",
            "Epoch 413, change: 0.00013288\n",
            "Epoch 410, change: 0.00016957\n",
            "Epoch 408, change: 0.00015348\n",
            "Epoch 412, change: 0.00022951\n",
            "Epoch 415, change: 0.00019228\n",
            "Epoch 410, change: 0.00016831\n",
            "Epoch 414, change: 0.00013194\n",
            "Epoch 411, change: 0.00016843\n",
            "Epoch 409, change: 0.00015241\n",
            "Epoch 413, change: 0.00022755\n",
            "Epoch 416, change: 0.00019077\n",
            "Epoch 411, change: 0.00016724\n",
            "Epoch 415, change: 0.00013100\n",
            "Epoch 412, change: 0.00016731\n",
            "Epoch 410, change: 0.00015081\n",
            "Epoch 414, change: 0.00022598\n",
            "Epoch 417, change: 0.00018924\n",
            "Epoch 412, change: 0.00016618\n",
            "Epoch 416, change: 0.00013006\n",
            "Epoch 413, change: 0.00016619\n",
            "Epoch 411, change: 0.00014964\n",
            "Epoch 415, change: 0.00022442\n",
            "Epoch 418, change: 0.00018766\n",
            "Epoch 413, change: 0.00016512\n",
            "Epoch 417, change: 0.00012913\n",
            "Epoch 414, change: 0.00016508\n",
            "Epoch 412, change: 0.00014835\n",
            "Epoch 416, change: 0.00022273\n",
            "Epoch 419, change: 0.00018628\n",
            "Epoch 414, change: 0.00016407\n",
            "Epoch 418, change: 0.00012821\n",
            "Epoch 415, change: 0.00016396\n",
            "Epoch 417, change: 0.00022123\n",
            "Epoch 413, change: 0.00014724\n",
            "Epoch 420, change: 0.00018474\n",
            "Epoch 415, change: 0.00016303\n",
            "Epoch 419, change: 0.00012730\n",
            "Epoch 416, change: 0.00016287\n",
            "Epoch 418, change: 0.00021956\n",
            "Epoch 414, change: 0.00014597\n",
            "Epoch 421, change: 0.00018258\n",
            "Epoch 416, change: 0.00016199\n",
            "Epoch 420, change: 0.00012640\n",
            "Epoch 417, change: 0.00016178\n",
            "Epoch 419, change: 0.00021801\n",
            "Epoch 415, change: 0.00014456\n",
            "Epoch 422, change: 0.00018164\n",
            "Epoch 417, change: 0.00016096\n",
            "Epoch 421, change: 0.00012548\n",
            "Epoch 420, change: 0.00021643\n",
            "Epoch 418, change: 0.00016070\n",
            "Epoch 416, change: 0.00014342\n",
            "Epoch 423, change: 0.00017930\n",
            "Epoch 418, change: 0.00015993\n",
            "Epoch 422, change: 0.00012459\n",
            "Epoch 421, change: 0.00021478\n",
            "Epoch 419, change: 0.00015963\n",
            "Epoch 417, change: 0.00014234\n",
            "Epoch 424, change: 0.00017823\n",
            "Epoch 419, change: 0.00015892\n",
            "Epoch 423, change: 0.00012371\n",
            "Epoch 422, change: 0.00021322\n",
            "Epoch 420, change: 0.00015853\n",
            "Epoch 418, change: 0.00014120\n",
            "Epoch 425, change: 0.00017655\n",
            "Epoch 420, change: 0.00015791\n",
            "Epoch 424, change: 0.00012283\n",
            "Epoch 423, change: 0.00021172\n",
            "Epoch 421, change: 0.00015749\n",
            "Epoch 419, change: 0.00013983\n",
            "Epoch 426, change: 0.00017522\n",
            "Epoch 421, change: 0.00015690\n",
            "Epoch 425, change: 0.00012194\n",
            "Epoch 424, change: 0.00021015\n",
            "Epoch 422, change: 0.00015644\n",
            "Epoch 420, change: 0.00013870\n",
            "Epoch 427, change: 0.00017408\n",
            "Epoch 422, change: 0.00015591\n",
            "Epoch 426, change: 0.00012108\n",
            "Epoch 425, change: 0.00020868\n",
            "Epoch 423, change: 0.00015538\n",
            "Epoch 428, change: 0.00017194\n",
            "Epoch 421, change: 0.00013766\n",
            "Epoch 423, change: 0.00015492\n",
            "Epoch 427, change: 0.00012021\n",
            "Epoch 426, change: 0.00020726\n",
            "Epoch 424, change: 0.00015434\n",
            "Epoch 429, change: 0.00017009\n",
            "Epoch 422, change: 0.00013635\n",
            "Epoch 424, change: 0.00015393\n",
            "Epoch 428, change: 0.00011935\n",
            "Epoch 427, change: 0.00020556\n",
            "Epoch 430, change: 0.00016904\n",
            "Epoch 425, change: 0.00015332\n",
            "Epoch 423, change: 0.00013537\n",
            "Epoch 425, change: 0.00015295\n",
            "Epoch 429, change: 0.00011851\n",
            "Epoch 428, change: 0.00020423\n",
            "Epoch 431, change: 0.00016715\n",
            "Epoch 426, change: 0.00015228\n",
            "Epoch 424, change: 0.00013400\n",
            "Epoch 426, change: 0.00015198\n",
            "Epoch 430, change: 0.00011767\n",
            "Epoch 429, change: 0.00020267\n",
            "Epoch 432, change: 0.00016618\n",
            "Epoch 427, change: 0.00015126\n",
            "Epoch 425, change: 0.00013304\n",
            "Epoch 427, change: 0.00015101\n",
            "Epoch 431, change: 0.00011682\n",
            "Epoch 430, change: 0.00020128\n",
            "Epoch 433, change: 0.00016466\n",
            "Epoch 428, change: 0.00015025\n",
            "Epoch 426, change: 0.00013186\n",
            "Epoch 428, change: 0.00015005\n",
            "Epoch 432, change: 0.00011600\n",
            "Epoch 431, change: 0.00019994\n",
            "Epoch 434, change: 0.00016288\n",
            "Epoch 429, change: 0.00014924\n",
            "Epoch 427, change: 0.00013069\n",
            "Epoch 429, change: 0.00014910\n",
            "Epoch 433, change: 0.00011516\n",
            "Epoch 435, change: 0.00016192\n",
            "Epoch 432, change: 0.00019847\n",
            "Epoch 430, change: 0.00014824\n",
            "Epoch 428, change: 0.00012963\n",
            "Epoch 430, change: 0.00014815\n",
            "Epoch 434, change: 0.00011435\n",
            "Epoch 436, change: 0.00016042\n",
            "Epoch 433, change: 0.00019706\n",
            "Epoch 431, change: 0.00014725\n",
            "Epoch 429, change: 0.00012857\n",
            "Epoch 431, change: 0.00014721\n",
            "Epoch 435, change: 0.00011354\n",
            "Epoch 437, change: 0.00015894\n",
            "Epoch 434, change: 0.00019528\n",
            "Epoch 432, change: 0.00014627\n",
            "Epoch 430, change: 0.00012754\n",
            "Epoch 432, change: 0.00014627\n",
            "Epoch 436, change: 0.00011272\n",
            "Epoch 438, change: 0.00015803\n",
            "Epoch 435, change: 0.00019407\n",
            "Epoch 433, change: 0.00014529\n",
            "Epoch 431, change: 0.00012651\n",
            "Epoch 433, change: 0.00014535\n",
            "Epoch 437, change: 0.00011192\n",
            "Epoch 439, change: 0.00015619\n",
            "Epoch 436, change: 0.00019263\n",
            "Epoch 434, change: 0.00014432\n",
            "Epoch 432, change: 0.00012528\n",
            "Epoch 434, change: 0.00014442\n",
            "Epoch 438, change: 0.00011112\n",
            "Epoch 440, change: 0.00015522\n",
            "Epoch 437, change: 0.00019120\n",
            "Epoch 435, change: 0.00014335\n",
            "Epoch 433, change: 0.00012441\n",
            "Epoch 435, change: 0.00014350\n",
            "Epoch 439, change: 0.00011033\n",
            "Epoch 441, change: 0.00015333\n",
            "Epoch 438, change: 0.00018991\n",
            "Epoch 436, change: 0.00014239\n",
            "Epoch 434, change: 0.00012319\n",
            "Epoch 436, change: 0.00014259\n",
            "Epoch 440, change: 0.00010955\n",
            "Epoch 442, change: 0.00015204\n",
            "Epoch 439, change: 0.00018854\n",
            "Epoch 437, change: 0.00014144\n",
            "Epoch 435, change: 0.00012225\n",
            "Epoch 437, change: 0.00014169\n",
            "Epoch 441, change: 0.00010877\n",
            "Epoch 443, change: 0.00015101\n",
            "Epoch 440, change: 0.00018722\n",
            "Epoch 438, change: 0.00014050\n",
            "Epoch 436, change: 0.00012128\n",
            "Epoch 438, change: 0.00014079\n",
            "Epoch 442, change: 0.00010798\n",
            "Epoch 444, change: 0.00014947\n",
            "Epoch 441, change: 0.00018580\n",
            "Epoch 439, change: 0.00013955\n",
            "Epoch 437, change: 0.00012029\n",
            "Epoch 439, change: 0.00013989\n",
            "Epoch 443, change: 0.00010722\n",
            "Epoch 445, change: 0.00014830\n",
            "Epoch 442, change: 0.00018443\n",
            "Epoch 440, change: 0.00013862\n",
            "Epoch 438, change: 0.00011918\n",
            "Epoch 440, change: 0.00013900\n",
            "Epoch 444, change: 0.00010645\n",
            "Epoch 446, change: 0.00014734\n",
            "Epoch 443, change: 0.00018317\n",
            "Epoch 441, change: 0.00013770\n",
            "Epoch 439, change: 0.00011825\n",
            "Epoch 441, change: 0.00013812\n",
            "Epoch 445, change: 0.00010569\n",
            "Epoch 447, change: 0.00014568\n",
            "Epoch 444, change: 0.00018187\n",
            "Epoch 442, change: 0.00013677\n",
            "Epoch 440, change: 0.00011723\n",
            "Epoch 442, change: 0.00013725\n",
            "Epoch 446, change: 0.00010494\n",
            "Epoch 448, change: 0.00014462\n",
            "Epoch 445, change: 0.00018052\n",
            "Epoch 443, change: 0.00013586\n",
            "Epoch 441, change: 0.00011628\n",
            "Epoch 443, change: 0.00013637\n",
            "Epoch 447, change: 0.00010419\n",
            "Epoch 449, change: 0.00014342\n",
            "Epoch 446, change: 0.00017907\n",
            "Epoch 444, change: 0.00013495\n",
            "Epoch 442, change: 0.00011521\n",
            "Epoch 444, change: 0.00013551\n",
            "Epoch 448, change: 0.00010345\n",
            "Epoch 450, change: 0.00014178\n",
            "Epoch 447, change: 0.00017791\n",
            "Epoch 445, change: 0.00013405\n",
            "Epoch 443, change: 0.00011437\n",
            "Epoch 445, change: 0.00013465\n",
            "Epoch 449, change: 0.00010272\n",
            "Epoch 451, change: 0.00014088\n",
            "Epoch 448, change: 0.00017672\n",
            "Epoch 446, change: 0.00013315\n",
            "Epoch 444, change: 0.00011333\n",
            "Epoch 446, change: 0.00013379\n",
            "Epoch 452, change: 0.00013946\n",
            "Epoch 450, change: 0.00010199\n",
            "Epoch 449, change: 0.00017540\n",
            "Epoch 447, change: 0.00013226\n",
            "Epoch 445, change: 0.00011236\n",
            "Epoch 447, change: 0.00013294\n",
            "Epoch 453, change: 0.00013857\n",
            "Epoch 451, change: 0.00010125\n",
            "Epoch 450, change: 0.00017409\n",
            "Epoch 448, change: 0.00013137\n",
            "Epoch 446, change: 0.00011148\n",
            "Epoch 448, change: 0.00013210\n",
            "Epoch 454, change: 0.00013712\n",
            "Epoch 452, change: 0.00010053\n",
            "Epoch 451, change: 0.00017286\n",
            "Epoch 449, change: 0.00013050\n",
            "Epoch 447, change: 0.00011049\n",
            "Epoch 449, change: 0.00013126\n",
            "Epoch 455, change: 0.00013598\n",
            "convergence after 453 epochs took 446 seconds\n",
            "Epoch 452, change: 0.00017149\n",
            "Epoch 450, change: 0.00012962\n",
            "Epoch 448, change: 0.00010962\n",
            "Epoch 450, change: 0.00013043\n",
            "Epoch 456, change: 0.00013486\n",
            "Epoch 453, change: 0.00017033\n",
            "Epoch 451, change: 0.00012875\n",
            "Epoch 449, change: 0.00010871\n",
            "Epoch 451, change: 0.00012960\n",
            "Epoch 457, change: 0.00013401\n",
            "Epoch 454, change: 0.00016909\n",
            "Epoch 452, change: 0.00012789\n",
            "Epoch 450, change: 0.00010775\n",
            "Epoch 452, change: 0.00012877\n",
            "Epoch 458, change: 0.00013246\n",
            "Epoch 455, change: 0.00016783\n",
            "Epoch 453, change: 0.00012704\n",
            "Epoch 451, change: 0.00010686\n",
            "Epoch 453, change: 0.00012796\n",
            "Epoch 459, change: 0.00013140\n",
            "Epoch 456, change: 0.00016663\n",
            "Epoch 454, change: 0.00012620\n",
            "Epoch 452, change: 0.00010600\n",
            "Epoch 454, change: 0.00012715\n",
            "Epoch 460, change: 0.00013027\n",
            "Epoch 457, change: 0.00016551\n",
            "Epoch 455, change: 0.00012534\n",
            "Epoch 453, change: 0.00010505\n",
            "Epoch 455, change: 0.00012634\n",
            "Epoch 461, change: 0.00012927\n",
            "Epoch 458, change: 0.00016429\n",
            "Epoch 456, change: 0.00012451\n",
            "Epoch 454, change: 0.00010430\n",
            "Epoch 456, change: 0.00012554\n",
            "Epoch 462, change: 0.00012833\n",
            "Epoch 459, change: 0.00016308\n",
            "Epoch 457, change: 0.00012368\n",
            "Epoch 455, change: 0.00010350\n",
            "Epoch 457, change: 0.00012474\n",
            "Epoch 463, change: 0.00012678\n",
            "Epoch 460, change: 0.00016189\n",
            "Epoch 458, change: 0.00012285\n",
            "Epoch 456, change: 0.00010262\n",
            "Epoch 458, change: 0.00012395\n",
            "Epoch 464, change: 0.00012578\n",
            "Epoch 461, change: 0.00016070\n",
            "Epoch 459, change: 0.00012203\n",
            "Epoch 457, change: 0.00010154\n",
            "Epoch 459, change: 0.00012316\n",
            "Epoch 465, change: 0.00012495\n",
            "Epoch 462, change: 0.00015961\n",
            "Epoch 460, change: 0.00012121\n",
            "Epoch 458, change: 0.00010079\n",
            "Epoch 466, change: 0.00012381\n",
            "Epoch 460, change: 0.00012238\n",
            "Epoch 463, change: 0.00015849\n",
            "Epoch 461, change: 0.00012040\n",
            "convergence after 459 epochs took 458 seconds\n",
            "Epoch 467, change: 0.00012259\n",
            "Epoch 461, change: 0.00012160\n",
            "Epoch 464, change: 0.00015744\n",
            "Epoch 462, change: 0.00011960\n",
            "Epoch 468, change: 0.00012190\n",
            "Epoch 462, change: 0.00012084\n",
            "Epoch 465, change: 0.00015607\n",
            "Epoch 463, change: 0.00011879\n",
            "Epoch 469, change: 0.00012043\n",
            "Epoch 463, change: 0.00012007\n",
            "Epoch 466, change: 0.00015503\n",
            "Epoch 464, change: 0.00011800\n",
            "Epoch 470, change: 0.00011972\n",
            "Epoch 464, change: 0.00011930\n",
            "Epoch 467, change: 0.00015398\n",
            "Epoch 465, change: 0.00011721\n",
            "Epoch 471, change: 0.00011879\n",
            "Epoch 465, change: 0.00011855\n",
            "Epoch 468, change: 0.00015272\n",
            "Epoch 466, change: 0.00011643\n",
            "Epoch 472, change: 0.00011793\n",
            "Epoch 466, change: 0.00011780\n",
            "Epoch 469, change: 0.00015172\n",
            "Epoch 467, change: 0.00011565\n",
            "Epoch 473, change: 0.00011643\n",
            "Epoch 467, change: 0.00011705\n",
            "Epoch 470, change: 0.00015058\n",
            "Epoch 468, change: 0.00011487\n",
            "Epoch 474, change: 0.00011564\n",
            "Epoch 468, change: 0.00011631\n",
            "Epoch 471, change: 0.00014956\n",
            "Epoch 469, change: 0.00011411\n",
            "Epoch 475, change: 0.00011446\n",
            "Epoch 469, change: 0.00011557\n",
            "Epoch 472, change: 0.00014845\n",
            "Epoch 470, change: 0.00011335\n",
            "Epoch 476, change: 0.00011354\n",
            "Epoch 470, change: 0.00011483\n",
            "Epoch 473, change: 0.00014745\n",
            "Epoch 471, change: 0.00011259\n",
            "Epoch 477, change: 0.00011243\n",
            "Epoch 471, change: 0.00011411\n",
            "Epoch 474, change: 0.00014638\n",
            "Epoch 472, change: 0.00011184\n",
            "Epoch 478, change: 0.00011162\n",
            "Epoch 472, change: 0.00011338\n",
            "Epoch 475, change: 0.00014516\n",
            "Epoch 473, change: 0.00011109\n",
            "Epoch 479, change: 0.00011072\n",
            "Epoch 473, change: 0.00011267\n",
            "Epoch 476, change: 0.00014421\n",
            "Epoch 474, change: 0.00011035\n",
            "Epoch 480, change: 0.00010971\n",
            "Epoch 474, change: 0.00011195\n",
            "Epoch 477, change: 0.00014317\n",
            "Epoch 475, change: 0.00010961\n",
            "Epoch 481, change: 0.00010879\n",
            "Epoch 475, change: 0.00011124\n",
            "Epoch 478, change: 0.00014219\n",
            "Epoch 476, change: 0.00010887\n",
            "Epoch 482, change: 0.00010780\n",
            "Epoch 476, change: 0.00011054\n",
            "Epoch 479, change: 0.00014107\n",
            "Epoch 483, change: 0.00010689\n",
            "Epoch 477, change: 0.00010815\n",
            "Epoch 477, change: 0.00010983\n",
            "Epoch 480, change: 0.00014012\n",
            "Epoch 484, change: 0.00010596\n",
            "Epoch 478, change: 0.00010743\n",
            "Epoch 478, change: 0.00010914\n",
            "Epoch 481, change: 0.00013910\n",
            "Epoch 485, change: 0.00010517\n",
            "Epoch 479, change: 0.00010671\n",
            "Epoch 479, change: 0.00010845\n",
            "Epoch 482, change: 0.00013818\n",
            "Epoch 486, change: 0.00010417\n",
            "Epoch 480, change: 0.00010600\n",
            "Epoch 483, change: 0.00013705\n",
            "Epoch 480, change: 0.00010776\n",
            "Epoch 487, change: 0.00010321\n",
            "Epoch 481, change: 0.00010528\n",
            "Epoch 484, change: 0.00013617\n",
            "Epoch 481, change: 0.00010707\n",
            "Epoch 488, change: 0.00010236\n",
            "Epoch 482, change: 0.00010458\n",
            "Epoch 485, change: 0.00013519\n",
            "Epoch 482, change: 0.00010640\n",
            "Epoch 489, change: 0.00010166\n",
            "Epoch 483, change: 0.00010388\n",
            "Epoch 486, change: 0.00013408\n",
            "Epoch 483, change: 0.00010572\n",
            "Epoch 490, change: 0.00010062\n",
            "Epoch 484, change: 0.00010319\n",
            "Epoch 487, change: 0.00013319\n",
            "Epoch 484, change: 0.00010505\n",
            "Epoch 491, change: 0.00010001\n",
            "Epoch 485, change: 0.00010250\n",
            "Epoch 488, change: 0.00013229\n",
            "Epoch 485, change: 0.00010439\n",
            "convergence after 492 epochs took 477 seconds\n",
            "Epoch 486, change: 0.00010182\n",
            "Epoch 489, change: 0.00013137\n",
            "Epoch 486, change: 0.00010373\n",
            "Epoch 487, change: 0.00010114\n",
            "Epoch 490, change: 0.00013031\n",
            "Epoch 487, change: 0.00010307\n",
            "Epoch 488, change: 0.00010045\n",
            "Epoch 491, change: 0.00012942\n",
            "Epoch 488, change: 0.00010241\n",
            "convergence after 489 epochs took 481 seconds\n",
            "Epoch 492, change: 0.00012848\n",
            "Epoch 489, change: 0.00010176\n",
            "Epoch 493, change: 0.00012753\n",
            "Epoch 490, change: 0.00010112\n",
            "Epoch 494, change: 0.00012665\n",
            "Epoch 491, change: 0.00010048\n",
            "Epoch 495, change: 0.00012578\n",
            "convergence after 492 epochs took 483 seconds\n",
            "Epoch 496, change: 0.00012491\n",
            "Epoch 497, change: 0.00012403\n",
            "Epoch 498, change: 0.00012320\n",
            "Epoch 499, change: 0.00012230\n",
            "Epoch 500, change: 0.00012113\n",
            "Epoch 501, change: 0.00012043\n",
            "Epoch 502, change: 0.00011963\n",
            "Epoch 503, change: 0.00011860\n",
            "Epoch 504, change: 0.00011784\n",
            "Epoch 505, change: 0.00011695\n",
            "Epoch 506, change: 0.00011614\n",
            "Epoch 507, change: 0.00011535\n",
            "Epoch 508, change: 0.00011449\n",
            "Epoch 509, change: 0.00011363\n",
            "Epoch 510, change: 0.00011282\n",
            "Epoch 511, change: 0.00011207\n",
            "Epoch 512, change: 0.00011122\n",
            "Epoch 513, change: 0.00011041\n",
            "Epoch 514, change: 0.00010961\n",
            "Epoch 515, change: 0.00010891\n",
            "Epoch 516, change: 0.00010813\n",
            "Epoch 517, change: 0.00010727\n",
            "Epoch 518, change: 0.00010651\n",
            "Epoch 519, change: 0.00010581\n",
            "Epoch 520, change: 0.00010502\n",
            "Epoch 521, change: 0.00010432\n",
            "Epoch 522, change: 0.00010353\n",
            "Epoch 523, change: 0.00010283\n",
            "Epoch 524, change: 0.00010197\n",
            "Epoch 525, change: 0.00010130\n",
            "Epoch 526, change: 0.00010051\n",
            "convergence after 527 epochs took 511 seconds\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0640843487394958 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05586882738346957 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024163738524936095 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014203334757401398 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007269835993149527 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031297712732813784 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007903334018712538 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000450670209458163 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002578222437458051 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 9.420290843371138e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.22978964893988219.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                                        FunctionTransformer(func=&lt;function preprocess_data at 0x17b9eeb60&gt;,\n",
              "                                                            kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                                       (&#x27;logisticregression&#x27;,\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;logisticregression__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;sag&#x27;,\n",
              "                                                        &#x27;saga&#x27;, &#x27;lbfgs&#x27;],\n",
              "                         &#x27;preprocessing__kw_args&#x27;: [{&#x27;method&#x27;: &#x27;normalize&#x27;},\n",
              "                                                    {&#x27;method&#x27;: &#x27;binarize&#x27;}]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                                        FunctionTransformer(func=&lt;function preprocess_data at 0x17b9eeb60&gt;,\n",
              "                                                            kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                                       (&#x27;logisticregression&#x27;,\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;logisticregression__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;sag&#x27;,\n",
              "                                                        &#x27;saga&#x27;, &#x27;lbfgs&#x27;],\n",
              "                         &#x27;preprocessing__kw_args&#x27;: [{&#x27;method&#x27;: &#x27;normalize&#x27;},\n",
              "                                                    {&#x27;method&#x27;: &#x27;binarize&#x27;}]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function preprocess_data at 0x17b9eeb60&gt;,\n",
              "                                     kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                (&#x27;logisticregression&#x27;,\n",
              "                 LogisticRegression(max_iter=10000, solver=&#x27;newton-cg&#x27;,\n",
              "                                    verbose=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function preprocess_data at 0x17b9eeb60&gt;,\n",
              "                    kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;newton-cg&#x27;, verbose=1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('preprocessing',\n",
              "                                        FunctionTransformer(func=<function preprocess_data at 0x17b9eeb60>,\n",
              "                                                            kw_args={'method': 'normalize'})),\n",
              "                                       ('logisticregression',\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'logisticregression__solver': ['newton-cg', 'sag',\n",
              "                                                        'saga', 'lbfgs'],\n",
              "                         'preprocessing__kw_args': [{'method': 'normalize'},\n",
              "                                                    {'method': 'binarize'}]},\n",
              "             scoring='f1_weighted', verbose=1)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Grid search with your pipeline\n",
        "## commenting these lines to avoid running fit again as it is time consuming.\n",
        "## uncomment the below lines to fit model again.\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring=\"f1_weighted\", n_jobs=-1, verbose=1)\n",
        "grid_search.fit(train_X, train_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oj0VCOudrpB"
      },
      "source": [
        "##### Finding Best Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpeEqwJFS1jz",
        "outputId": "6326203d-4c91-4b5c-ddbb-e4a2d2e57752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'logisticregression__solver': 'newton-cg', 'preprocessing__kw_args': {'method': 'normalize'}}\n",
            "Best F1 Score: 0.9204433376055948\n"
          ]
        }
      ],
      "source": [
        "# Best params and score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best F1 Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWp1NVE68Gqx"
      },
      "source": [
        "##### Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "MLjOhWEV5GIJ"
      },
      "outputs": [],
      "source": [
        "## dump the model to google drive\n",
        "# filename = joblib.dump(grid_search.best_estimator_, f\"{shared_folder_path}/logistic_regression_best_model.joblib\")\n",
        "save_model(grid_search.best_estimator_, \"logistic_regression_v1.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwqsnB8d9hmr",
        "outputId": "38b1a7c8-c411-4ebf-8af5-b1157838af7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([ 31.05841525,  30.13615719, 310.48314349, 309.49962203,\n",
              "        484.42176263, 469.32051833,  22.46318944,  22.77225169]),\n",
              " 'std_fit_time': array([ 0.86419307,  1.39344265, 16.56746721, 13.51729919, 22.0485784 ,\n",
              "        16.29538788,  0.92769462,  0.19044785]),\n",
              " 'mean_score_time': array([0.30697346, 0.36249169, 0.09810193, 0.21375561, 0.08239134,\n",
              "        0.14151772, 0.14397232, 0.16827496]),\n",
              " 'std_score_time': array([0.02313248, 0.02377644, 0.00765689, 0.0051399 , 0.00369511,\n",
              "        0.00493533, 0.00988258, 0.01972425]),\n",
              " 'param_logisticregression__solver': masked_array(data=['newton-cg', 'newton-cg', 'sag', 'sag', 'saga', 'saga',\n",
              "                    'lbfgs', 'lbfgs'],\n",
              "              mask=[False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_preprocessing__kw_args': masked_array(data=[{'method': 'normalize'}, {'method': 'binarize'},\n",
              "                    {'method': 'normalize'}, {'method': 'binarize'},\n",
              "                    {'method': 'normalize'}, {'method': 'binarize'},\n",
              "                    {'method': 'normalize'}, {'method': 'binarize'}],\n",
              "              mask=[False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'logisticregression__solver': 'newton-cg',\n",
              "   'preprocessing__kw_args': {'method': 'normalize'}},\n",
              "  {'logisticregression__solver': 'newton-cg',\n",
              "   'preprocessing__kw_args': {'method': 'binarize'}},\n",
              "  {'logisticregression__solver': 'sag',\n",
              "   'preprocessing__kw_args': {'method': 'normalize'}},\n",
              "  {'logisticregression__solver': 'sag',\n",
              "   'preprocessing__kw_args': {'method': 'binarize'}},\n",
              "  {'logisticregression__solver': 'saga',\n",
              "   'preprocessing__kw_args': {'method': 'normalize'}},\n",
              "  {'logisticregression__solver': 'saga',\n",
              "   'preprocessing__kw_args': {'method': 'binarize'}},\n",
              "  {'logisticregression__solver': 'lbfgs',\n",
              "   'preprocessing__kw_args': {'method': 'normalize'}},\n",
              "  {'logisticregression__solver': 'lbfgs',\n",
              "   'preprocessing__kw_args': {'method': 'binarize'}}],\n",
              " 'split0_test_score': array([0.91906499, 0.90864351, 0.91896009, 0.90913417, 0.91890747,\n",
              "        0.90908187, 0.91901975, 0.90850093]),\n",
              " 'split1_test_score': array([0.91970242, 0.9074639 , 0.9194354 , 0.90767346, 0.9194354 ,\n",
              "        0.90762015, 0.9191696 , 0.90751268]),\n",
              " 'split2_test_score': array([0.9225626 , 0.90962854, 0.92142711, 0.90908886, 0.92142711,\n",
              "        0.90914343, 0.92089949, 0.90904651]),\n",
              " 'mean_test_score': array([0.92044334, 0.90857865, 0.91994087, 0.90863217, 0.91992333,\n",
              "        0.90861515, 0.91969628, 0.90835337]),\n",
              " 'std_test_score': array([0.00152097, 0.0008849 , 0.0010687 , 0.00067816, 0.00108496,\n",
              "        0.00070402, 0.00085299, 0.00063481]),\n",
              " 'rank_test_score': array([1, 7, 2, 5, 3, 6, 4, 8], dtype=int32)}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "8eWhKAcI8aAl"
      },
      "outputs": [],
      "source": [
        "# Save cross-validation results as JSON\n",
        "## commenting these lines to avoid overwriting the model in google drive.\n",
        "## uncomment them to update the model in google drive.\n",
        "\n",
        "# filename = joblib.dump(grid_search.cv_results_, f\"{shared_folder_path}/logistic_regression_v1_cv_results.joblib\")\n",
        "save_model(grid_search.cv_results_, \"logistic_regression_v1_cv_results.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545aexfaLVeh"
      },
      "source": [
        "##### Performance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99OqaCN4w1KV"
      },
      "source": [
        "* To calculate the performance metrics, we'll first get the best params from grid search and do cross val with the same params."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "hpsk1VMIyikc"
      },
      "outputs": [],
      "source": [
        "best_params = grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "X-ZVEi0fyoIH"
      },
      "outputs": [],
      "source": [
        "## create new pipeline\n",
        "## defaulting to newton-cg solver if not found in best_params, because that was the best solver in iteration 1 of grid search.\n",
        "logistic_regression = LogisticRegression(max_iter=10000, verbose=1, solver=best_params.get(\"logisticregression__solver\", \"newton-cg\"))\n",
        "## create pipeline\n",
        "preprocessing_method = best_params.get(\"preprocessing__kw_args\", {\"method\": \"normalize\"})[\"method\"]\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessing\", FunctionTransformer(preprocess_data, kw_args={\"method\": preprocessing_method})),\n",
        "    (\"training\", logistic_regression)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNEvRLeyzM8X",
        "outputId": "4285b609-d799-4652-82c8-6bd1a257d0b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05595957070928089 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0556326571727961 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596280984522609 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024388942315533235 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.023023988305067158 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025091128394095222 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013596754560941109 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014506205604912571 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.01453673896669188 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007593654728518624 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007283441377992933 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005054019827049796 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031146963465692153 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032522697034441383 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023202958093750045 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007994908562239658 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000913237919852819 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000836455371295198 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005088976609375899 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005773570836641845 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005284668717374731 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002756891144761195 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00032831161461654914 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003457691373532914 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00022188555862540438 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010949043378872298 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010587022746062941 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 9.829169845516656e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2261625773537494.\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.9769157620122838e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.21649195609951896.\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.8331698858140754e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2182472068133294.\n"
          ]
        }
      ],
      "source": [
        "probabilities = cross_val_predict(pipeline, train_X, train_Y, cv=3, method=\"predict_proba\", n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "dvk9G4gW3_DF",
        "outputId": "bc769070-48cf-4390-e685-d80b0e941207"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Method</th>\n",
              "      <th>File Name</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1 Score</th>\n",
              "      <th>ROC AUC Score</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression V0</td>\n",
              "      <td>Default Estimator</td>\n",
              "      <td>logistic_regression_v0.joblib</td>\n",
              "      <td>0.919839</td>\n",
              "      <td>0.919697</td>\n",
              "      <td>0.992891</td>\n",
              "      <td>0.96094</td>\n",
              "      <td>0.964241</td>\n",
              "      <td>0.904483</td>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.926959</td>\n",
              "      <td>0.879824</td>\n",
              "      <td>0.944259</td>\n",
              "      <td>0.929785</td>\n",
              "      <td>0.880834</td>\n",
              "      <td>0.897883</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Algorithm             Method                      File Name  \\\n",
              "0  Logistic Regression V0  Default Estimator  logistic_regression_v0.joblib   \n",
              "\n",
              "   Accuracy  Weighted F1 Score  ROC AUC Score  Class_0   Class_1   Class_2  \\\n",
              "0  0.919839           0.919697       0.992891  0.96094  0.964241  0.904483   \n",
              "\n",
              "    Class_3   Class_4   Class_5   Class_6   Class_7   Class_8   Class_9  \n",
              "0  0.898339  0.926959  0.879824  0.944259  0.929785  0.880834  0.897883  "
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "-igPDimqNoxK"
      },
      "outputs": [],
      "source": [
        "comparison_df = update_model_comparison(probabilities, train_Y, \"Logistic Regression V1\", \"GridSearchCV\",\"logistic_regression_v1.joblib\",comparison_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "RUc1nO52Yhjf",
        "outputId": "01084b93-1015-460c-dc52-b277a9090150"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Method</th>\n",
              "      <th>File Name</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1 Score</th>\n",
              "      <th>ROC AUC Score</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression V0</td>\n",
              "      <td>Default Estimator</td>\n",
              "      <td>logistic_regression_v0.joblib</td>\n",
              "      <td>0.919839</td>\n",
              "      <td>0.919697</td>\n",
              "      <td>0.992891</td>\n",
              "      <td>0.960940</td>\n",
              "      <td>0.964241</td>\n",
              "      <td>0.904483</td>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.926959</td>\n",
              "      <td>0.879824</td>\n",
              "      <td>0.944259</td>\n",
              "      <td>0.929785</td>\n",
              "      <td>0.880834</td>\n",
              "      <td>0.897883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression V1</td>\n",
              "      <td>GridSearchCV</td>\n",
              "      <td>logistic_regression_v1.joblib</td>\n",
              "      <td>0.920589</td>\n",
              "      <td>0.920444</td>\n",
              "      <td>0.992934</td>\n",
              "      <td>0.960701</td>\n",
              "      <td>0.964468</td>\n",
              "      <td>0.905045</td>\n",
              "      <td>0.899217</td>\n",
              "      <td>0.927801</td>\n",
              "      <td>0.881860</td>\n",
              "      <td>0.944334</td>\n",
              "      <td>0.930612</td>\n",
              "      <td>0.882478</td>\n",
              "      <td>0.898686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Algorithm             Method                      File Name  \\\n",
              "0  Logistic Regression V0  Default Estimator  logistic_regression_v0.joblib   \n",
              "1  Logistic Regression V1       GridSearchCV  logistic_regression_v1.joblib   \n",
              "\n",
              "   Accuracy  Weighted F1 Score  ROC AUC Score   Class_0   Class_1   Class_2  \\\n",
              "0  0.919839           0.919697       0.992891  0.960940  0.964241  0.904483   \n",
              "1  0.920589           0.920444       0.992934  0.960701  0.964468  0.905045   \n",
              "\n",
              "    Class_3   Class_4   Class_5   Class_6   Class_7   Class_8   Class_9  \n",
              "0  0.898339  0.926959  0.879824  0.944259  0.929785  0.880834  0.897883  \n",
              "1  0.899217  0.927801  0.881860  0.944334  0.930612  0.882478  0.898686  "
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6e1OafAOJbb"
      },
      "source": [
        "Observations:\n",
        "* We see slight improvement in hyper tuned model, but nothing significant. Lets try second iteration of GridSearchCV while keeping `solver` and `arguments` as it is and finding best penalty and C value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4CzhGROBZwi"
      },
      "source": [
        "#### Iteration 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "9AfVrdctAuoc"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"logisticregression__penalty\": [\"l2\", \"none\"],\n",
        "    \"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "}\n",
        "\n",
        "## initialize LogisticRegression\n",
        "logistic_regression = LogisticRegression(max_iter=10000, verbose=1, solver=\"newton-cg\")\n",
        "\n",
        "## create pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessing\", FunctionTransformer(preprocess_data, kw_args={\"method\": \"normalize\"})),\n",
        "    (\"logisticregression\", logistic_regression)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "0cQZ1gb2ySdT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055926431956904214 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0555970450825691 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05165096503827657 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025083798155239107 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02301896702628503 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02278163146395315 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05524060914005245 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05190199271115941 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014488922114073073 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013557421162128927 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02461197375918775 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02297238233791094 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.010097110507840568 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013171309205769336 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.010484076639706318 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055923640488595217 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007594867746964214 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005065541125684582 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.008468079166671876 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0519472609388737 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024383172341876317 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.008812577434644997 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055562390638798476 <= 0.0001 False\n",
            "    max |gradient| <= tol: 0.055564065752412115 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0069789120499681835 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024059743389368227 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.01446318016887404 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02432906067101161 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.003152071846735626 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025014333511724714 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023467551513162944 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.010779454332901544 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0035259918693891596 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014040146519874818 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014019285137091685 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596280984522609 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05595957070928089 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0556326571727961 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0072830810223857454 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025091128394095222 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.002001317946866174 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00177694349634275 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.009105121824390364 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024388942315533235 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.023023988305067158 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007482663900920433 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007296904610291197 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.01453673896669188 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.001194956471441318 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014506205604912571 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013596754560941109 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0012935603181583645 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032894088761413567 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007773652777184898 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007434279210330187 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0012272624991858572 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00354037435355282 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007593654728518624 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.003674936919392082 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007283441377992933 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005054019827049796 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0019295779746140449 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0006890222878775543 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0011877976903233863 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00019014547133748235 <= 0.0001 False\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031146963465692153 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032522697034441383 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007153852880897589 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0006321152470001904 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0004634213649588231 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023202958093750045 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003050509630877706 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0012760345490456305 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0012479302758733844 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00013833894184318193 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0006788917850443394 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 7.4990556137787e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.7153146804790197.\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007994908562239658 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007209542399616343 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000399436840947619 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0006039273987990154 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001208048815349592 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000913237919852819 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00016669901705916037 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000836455371295198 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.8396786325280944e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.7175774431327271.\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001416408159326003 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 6.872045625559582e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.7191290423133508.\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00020543133104297627 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05563621806067901 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596644736547852 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00015856244172271142 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001556761111711034 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.023024494162193966 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02509186536159745 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 3.989536177090954e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.3905888224697264.\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005088976609375899 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013600695021156416 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005773570836641845 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014541529058781628 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.94044164517556e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2701159656201794.\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005284668717374731 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596316345273406 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 4.1545474253220635e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2716568327265989.\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024389523001331098 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005052831607139531 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0075934943391692 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014510515247939748 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 3.1034347203771106e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.39630679219687004.\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002756891144761195 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 6.354098463447835e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2770602111181727.\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.9673681311368662e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.39218200647310375.\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007283493446101924 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596681111481183 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031109908789157398 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023176968174017207 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055636574146249486 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025091939097891546 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596352272428737 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02302454478530166 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003457691373532914 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024389581106896895 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014542008151932568 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032485937284625257 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00032831161461654914 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013601089138278472 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014510946283114055 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007593477957946967 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0008239526345900075 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0009121119228269432 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005052712422229324 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007283498812030823 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00311062070162115 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.001308438215077127 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023174374744748833 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032482265443146687 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000610422403980983 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00048245313363068766 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007069440354207921 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00022188555862540438 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0008262584713304899 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0008732234572114266 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010949043378872298 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.001247413298571283 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010587022746062941 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007085377607142712 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00055237818153694 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000440818198293241 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0006193429486532404 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00040091585957261454 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0004715864650232148 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00022502444831957362 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002115599631456347 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 9.829169845516656e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2261625773537494.\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005267285960200239 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0004705105448131787 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.8331698858140754e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2182472068133294.\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000418622105337116 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.9769157620122838e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.21649195609951896.\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001908730691454986 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003669091638481095 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00019720227200500242 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002740002497711003 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00040821285507904606 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00011632661148418438 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00019276923370367598 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00019284158008265286 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001783988707843964 <= 0.0001 False\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00016386247130532688 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001839036156015388 <= 0.0001 False\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00012533257529979887 <= 0.0001 False\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00011061155128695 <= 0.0001 False\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 9.531634888107158e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.1848306550431336.\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00017763344444246955 <= 0.0001 False\n",
            "Newton-CG iter = 12\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010600616162245349 <= 0.0001 False\n",
            "Newton-CG iter = 12\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00013781078806919506 <= 0.0001 False\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00016047087651088174 <= 0.0001 False\n",
            "Newton-CG iter = 12\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 6.58751413371422e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.18864427734725123.\n",
            "Newton-CG iter = 13\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 3.4848631122161004e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.18640638494626502.\n",
            "Newton-CG iter = 12\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00013379073104418477 <= 0.0001 False\n",
            "Newton-CG iter = 13\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.966660767480363e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.19476744649341077.\n",
            "Newton-CG iter = 12\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00024137880895179627 <= 0.0001 False\n",
            "Newton-CG iter = 13\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001490092063684326 <= 0.0001 False\n",
            "Newton-CG iter = 13\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 8.237156653134281e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.17495933559441748.\n",
            "Newton-CG iter = 14\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.660727933300787e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.1816967780288528.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "18 fits failed out of a total of 36.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "7 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "4 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "4 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.88715685        nan 0.91171344        nan 0.92119086        nan\n",
            " 0.92044334        nan 0.91256468        nan 0.910563          nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0640843487394958 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055844834961084146 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024159706273318312 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014174266275980962 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007271341865288091 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031551853574376997 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007129159485098198 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00041611691202089865 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00019037509431587743 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.83773662971508e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.26863483023546475.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                                        FunctionTransformer(func=&lt;function preprocess_data at 0x17b9eeb60&gt;,\n",
              "                                                            kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                                       (&#x27;logisticregression&#x27;,\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           solver=&#x27;newton-cg&#x27;,\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10,\n",
              "                                                   100],\n",
              "                         &#x27;logisticregression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                                        FunctionTransformer(func=&lt;function preprocess_data at 0x17b9eeb60&gt;,\n",
              "                                                            kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                                       (&#x27;logisticregression&#x27;,\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           solver=&#x27;newton-cg&#x27;,\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10,\n",
              "                                                   100],\n",
              "                         &#x27;logisticregression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function preprocess_data at 0x17b9eeb60&gt;,\n",
              "                                     kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                (&#x27;logisticregression&#x27;,\n",
              "                 LogisticRegression(C=0.1, max_iter=10000, solver=&#x27;newton-cg&#x27;,\n",
              "                                    verbose=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function preprocess_data at 0x17b9eeb60&gt;,\n",
              "                    kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, max_iter=10000, solver=&#x27;newton-cg&#x27;, verbose=1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('preprocessing',\n",
              "                                        FunctionTransformer(func=<function preprocess_data at 0x17b9eeb60>,\n",
              "                                                            kw_args={'method': 'normalize'})),\n",
              "                                       ('logisticregression',\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           solver='newton-cg',\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'logisticregression__C': [0.001, 0.01, 0.1, 1, 10,\n",
              "                                                   100],\n",
              "                         'logisticregression__penalty': ['l2', 'none']},\n",
              "             scoring='f1_weighted', verbose=1)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring=\"f1_weighted\", n_jobs=-1, verbose=1)\n",
        "grid_search.fit(train_X, train_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Finding Best Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}\n",
            "Best F1 Score: 0.9211908550922101\n"
          ]
        }
      ],
      "source": [
        "# Best params and score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best F1 Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "## dump the model to google drive\n",
        "# filename = joblib.dump(grid_search.best_estimator_, f\"{shared_folder_path}/logistic_regression_best_model.joblib\")\n",
        "save_model(grid_search.best_estimator_, \"logistic_regression_v2.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Performance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* To calculate the performance metrics, we'll first get the best params from grid search and do cross val with the same params."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_params = grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "## create new pipeline\n",
        "## defaulting to newton-cg solver if not found in best_params, because that was the best solver in iteration 1 of grid search.\n",
        "\n",
        "logistic_regression = LogisticRegression(max_iter=10000, verbose=1, solver=\"newton-cg\", penalty=best_params.get(\"logisticregression__penalty\", \"l2\"), C=best_params.get(\"logisticregression__C\", 0.1))\n",
        "## create pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessing\", FunctionTransformer(preprocess_data, kw_args={\"method\": \"normalize\"})),\n",
        "    (\"training\", logistic_regression)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055923640488595217 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055926431956904214 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0555970450825691 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025083798155239107 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024383172341876317 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02301896702628503 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014488922114073073 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.01446318016887404 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013557421162128927 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007594867746964214 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0072830810223857454 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005065541125684582 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.003152071846735626 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032894088761413567 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023467551513162944 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007434279210330187 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007773652777184898 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007153852880897589 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0004634213649588231 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003050509630877706 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000399436840947619 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00016669901705916037 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00020543133104297627 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001416408159326003 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 6.354098463447835e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2770602111181727.\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.94044164517556e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2701159656201794.\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 4.1545474253220635e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2716568327265989.\n"
          ]
        }
      ],
      "source": [
        "probabilities = cross_val_predict(pipeline, train_X, train_Y, cv=3, method=\"predict_proba\", n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Method</th>\n",
              "      <th>File Name</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1 Score</th>\n",
              "      <th>ROC AUC Score</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression V0</td>\n",
              "      <td>Default Estimator</td>\n",
              "      <td>logistic_regression_v0.joblib</td>\n",
              "      <td>0.919839</td>\n",
              "      <td>0.919697</td>\n",
              "      <td>0.992891</td>\n",
              "      <td>0.960940</td>\n",
              "      <td>0.964241</td>\n",
              "      <td>0.904483</td>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.926959</td>\n",
              "      <td>0.879824</td>\n",
              "      <td>0.944259</td>\n",
              "      <td>0.929785</td>\n",
              "      <td>0.880834</td>\n",
              "      <td>0.897883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression V1</td>\n",
              "      <td>GridSearchCV</td>\n",
              "      <td>logistic_regression_v1.joblib</td>\n",
              "      <td>0.920589</td>\n",
              "      <td>0.920444</td>\n",
              "      <td>0.992934</td>\n",
              "      <td>0.960701</td>\n",
              "      <td>0.964468</td>\n",
              "      <td>0.905045</td>\n",
              "      <td>0.899217</td>\n",
              "      <td>0.927801</td>\n",
              "      <td>0.881860</td>\n",
              "      <td>0.944334</td>\n",
              "      <td>0.930612</td>\n",
              "      <td>0.882478</td>\n",
              "      <td>0.898686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Algorithm             Method                      File Name  \\\n",
              "0  Logistic Regression V0  Default Estimator  logistic_regression_v0.joblib   \n",
              "1  Logistic Regression V1       GridSearchCV  logistic_regression_v1.joblib   \n",
              "\n",
              "   Accuracy  Weighted F1 Score  ROC AUC Score   Class_0   Class_1   Class_2  \\\n",
              "0  0.919839           0.919697       0.992891  0.960940  0.964241  0.904483   \n",
              "1  0.920589           0.920444       0.992934  0.960701  0.964468  0.905045   \n",
              "\n",
              "    Class_3   Class_4   Class_5   Class_6   Class_7   Class_8   Class_9  \n",
              "0  0.898339  0.926959  0.879824  0.944259  0.929785  0.880834  0.897883  \n",
              "1  0.899217  0.927801  0.881860  0.944334  0.930612  0.882478  0.898686  "
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "comparison_df = update_model_comparison(probabilities, train_Y, \"Logistic Regression V2\", \"GridSearchCV\", \"logistic_regression_v2.joblib\",comparison_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Method</th>\n",
              "      <th>File Name</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1 Score</th>\n",
              "      <th>ROC AUC Score</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression V0</td>\n",
              "      <td>Default Estimator</td>\n",
              "      <td>logistic_regression_v0.joblib</td>\n",
              "      <td>0.919839</td>\n",
              "      <td>0.919697</td>\n",
              "      <td>0.992891</td>\n",
              "      <td>0.960940</td>\n",
              "      <td>0.964241</td>\n",
              "      <td>0.904483</td>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.926959</td>\n",
              "      <td>0.879824</td>\n",
              "      <td>0.944259</td>\n",
              "      <td>0.929785</td>\n",
              "      <td>0.880834</td>\n",
              "      <td>0.897883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression V1</td>\n",
              "      <td>GridSearchCV</td>\n",
              "      <td>logistic_regression_v1.joblib</td>\n",
              "      <td>0.920589</td>\n",
              "      <td>0.920444</td>\n",
              "      <td>0.992934</td>\n",
              "      <td>0.960701</td>\n",
              "      <td>0.964468</td>\n",
              "      <td>0.905045</td>\n",
              "      <td>0.899217</td>\n",
              "      <td>0.927801</td>\n",
              "      <td>0.881860</td>\n",
              "      <td>0.944334</td>\n",
              "      <td>0.930612</td>\n",
              "      <td>0.882478</td>\n",
              "      <td>0.898686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic Regression V2</td>\n",
              "      <td>GridSearchCV</td>\n",
              "      <td>logistic_regression_v2.joblib</td>\n",
              "      <td>0.921375</td>\n",
              "      <td>0.921193</td>\n",
              "      <td>0.993371</td>\n",
              "      <td>0.961961</td>\n",
              "      <td>0.960945</td>\n",
              "      <td>0.908795</td>\n",
              "      <td>0.900696</td>\n",
              "      <td>0.927737</td>\n",
              "      <td>0.880727</td>\n",
              "      <td>0.948119</td>\n",
              "      <td>0.931754</td>\n",
              "      <td>0.884302</td>\n",
              "      <td>0.898043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Algorithm             Method                      File Name  \\\n",
              "0  Logistic Regression V0  Default Estimator  logistic_regression_v0.joblib   \n",
              "1  Logistic Regression V1       GridSearchCV  logistic_regression_v1.joblib   \n",
              "2  Logistic Regression V2       GridSearchCV  logistic_regression_v2.joblib   \n",
              "\n",
              "   Accuracy  Weighted F1 Score  ROC AUC Score   Class_0   Class_1   Class_2  \\\n",
              "0  0.919839           0.919697       0.992891  0.960940  0.964241  0.904483   \n",
              "1  0.920589           0.920444       0.992934  0.960701  0.964468  0.905045   \n",
              "2  0.921375           0.921193       0.993371  0.961961  0.960945  0.908795   \n",
              "\n",
              "    Class_3   Class_4   Class_5   Class_6   Class_7   Class_8   Class_9  \n",
              "0  0.898339  0.926959  0.879824  0.944259  0.929785  0.880834  0.897883  \n",
              "1  0.899217  0.927801  0.881860  0.944334  0.930612  0.882478  0.898686  \n",
              "2  0.900696  0.927737  0.880727  0.948119  0.931754  0.884302  0.898043  "
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observations:\n",
        "* So there is slight improvement in Accuracy and F1 Scores from previous version, and its definately better than default version. \n",
        "* We also see some improvements in per class f1 scores, specially class 3 which has f1 score of 0.9 as compared to .89 in baseline version. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "## saving the dataframe to csv file\n",
        "save_comparison_df(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Final Params\n",
        "* So for `Logistic Regresssion` following are the final params that gives us best estimator,\n",
        "    * Preprocessing: `normalize`\n",
        "    * Solver : `newton-cg`\n",
        "    * C : `0.1`\n",
        "    * Penalty : `l2`\n",
        "* These params will give us an classifier with F1 score of `0.92`, Accuracy of `0.92` and ROC AUC Score of `.99`\n",
        "* We still need to test this on test data, but we'll do that after exploring other algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Support Vector Classifier (SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Default Estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter Tuning"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
