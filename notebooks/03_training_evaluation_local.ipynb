{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZYKPYNu8eF1"
      },
      "source": [
        "# Model Training & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I5faNMt8hp5"
      },
      "source": [
        "* This note book is similar to `02_training_evaluation_colab` the only difference is we've created this to run locally instead of on `Google Colab`. The main reason for this is that the free version of `Google Colab` only has 2 cores, while our local machine has 12 cores giving us added advantage of almost 2X performance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9gYBPVV9jCK"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s9jYgk_x9k8O"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Binarizer, OneHotEncoder, MinMaxScaler, StandardScaler, FunctionTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict,GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import loguniform\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, f1_score, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import joblib\n",
        "import json\n",
        "import gdown\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz-Sy-KP91Wy"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "## function to download data from google drive\n",
        "def download_from_google_drive(file_id, file_name):\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    gdown.download(url, file_name, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "## check if mnist data is already downloaded\n",
        "mnist_train_set_path = Path(\"..\", \"data\", \"mnist_train_set.csv\")\n",
        "mnist_test_set_path = Path(\"..\", \"data\", \"mnist_test_set.csv\")\n",
        "\n",
        "if not mnist_train_set_path.exists():\n",
        "    ## download train set\n",
        "    file_id = \"1Rho1umzwBQTodR7sXVCdUZsJE7xq9EmM\"\n",
        "    # data_dir = str(Path(\"..\", \"data\", \"mnist_train_set.csv\"))\n",
        "    download_from_google_drive(file_id, str(mnist_train_set_path))\n",
        "\n",
        "if not mnist_test_set_path.exists():\n",
        "    ## download test set\n",
        "    file_id = \"1qxd-M96DJpYXHfO8xf_XKdDHr3o0xMUE\"\n",
        "    # data_dir = str(Path(\"..\", \"data\", \"mnist_test_set.csv\"))\n",
        "    download_from_google_drive(file_id, str(mnist_test_set_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NZpnRKS-J4s"
      },
      "source": [
        "### Access Train/Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oX0WLcHw-Ljl"
      },
      "outputs": [],
      "source": [
        "## access train data\n",
        "mnist_train_set = pd.read_csv(mnist_train_set_path)\n",
        "\n",
        "## access test data\n",
        "mnist_test_set = pd.read_csv(mnist_test_set_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "wR1vwxLN-dlT",
        "outputId": "45b49664-e313-40a4-bbf9-e48ea2aa5ae0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0       0       0   \n",
              "2       0       0       0       0       0       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       0       0   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  \\\n",
              "0        0  ...         0         0         0         0         0         0   \n",
              "1        0  ...         0         0         0         0         0         0   \n",
              "2        0  ...         0         0         0         0         0         0   \n",
              "3        0  ...         0         0         0         0         0         0   \n",
              "4        0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel782  pixel783  pixel784  class  \n",
              "0         0         0         0      0  \n",
              "1         0         0         0      7  \n",
              "2         0         0         0      0  \n",
              "3         0         0         0      9  \n",
              "4         0         0         0      1  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist_train_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "LhTJRHwG_OEL",
        "outputId": "004feeb7-0f48-4801-9576-64395cae93e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mnist_test_set"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-20497c61-14b8-45c1-8005-624ccf61770c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20497c61-14b8-45c1-8005-624ccf61770c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-20497c61-14b8-45c1-8005-624ccf61770c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-20497c61-14b8-45c1-8005-624ccf61770c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-759e9f23-cbee-4168-ab0e-a30d20924410\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-759e9f23-cbee-4168-ab0e-a30d20924410')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-759e9f23-cbee-4168-ab0e-a30d20924410 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0       0       0   \n",
              "2       0       0       0       0       0       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       0       0   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  \\\n",
              "0        0  ...         0         0         0         0         0         0   \n",
              "1        0  ...         0         0         0         0         0         0   \n",
              "2        0  ...         0         0         0         0         0         0   \n",
              "3        0  ...         0         0         0         0         0         0   \n",
              "4        0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel782  pixel783  pixel784  class  \n",
              "0         0         0         0      7  \n",
              "1         0         0         0      3  \n",
              "2         0         0         0      1  \n",
              "3         0         0         0      1  \n",
              "4         0         0         0      2  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist_test_set.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGW8p6Yu-glV"
      },
      "source": [
        "### Split Features/Target Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EppfbDFo-kFc"
      },
      "outputs": [],
      "source": [
        "## Split training features and target into separate dataset\n",
        "train_X = mnist_train_set.drop(\"class\", axis=1)\n",
        "train_Y = mnist_train_set[\"class\"]\n",
        "\n",
        "## split test features and target into separate dataset\n",
        "test_X = mnist_test_set.drop(\"class\", axis=1)\n",
        "test_Y = mnist_test_set[\"class\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "VWiQPLgA-2kP",
        "outputId": "1054e378-52a7-488a-b1ff-f087702abe74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0       0       0   \n",
              "2       0       0       0       0       0       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       0       0   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0        0  ...         0         0         0         0         0         0   \n",
              "1        0  ...         0         0         0         0         0         0   \n",
              "2        0  ...         0         0         0         0         0         0   \n",
              "3        0  ...         0         0         0         0         0         0   \n",
              "4        0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrI5yRUF_fPN",
        "outputId": "12a8a312-8aa5-4f9c-fe47-8a26bb716858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56000 entries, 0 to 55999\n",
            "Columns: 784 entries, pixel1 to pixel784\n",
            "dtypes: int64(784)\n",
            "memory usage: 335.0 MB\n"
          ]
        }
      ],
      "source": [
        "train_X.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "8c2h0SZn-6ZM",
        "outputId": "07f35d1f-caae-4f8a-8333-b7c42dc94553"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0\n",
              "1    7\n",
              "2    0\n",
              "3    9\n",
              "4    1\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AyGzY0V_kXC",
        "outputId": "9ec6bc20-e422-40b0-edd1-8041be3d8532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 56000 entries, 0 to 55999\n",
            "Series name: class\n",
            "Non-Null Count  Dtype\n",
            "--------------  -----\n",
            "56000 non-null  int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 437.6 KB\n"
          ]
        }
      ],
      "source": [
        "train_Y.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "7YJJ-Zp4_oBG",
        "outputId": "09dbbadf-7236-40e2-8533-a5c819d3f4c2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
              "0       0       0       0       0       0       0       0       0       0   \n",
              "1       0       0       0       0       0       0       0       0       0   \n",
              "2       0       0       0       0       0       0       0       0       0   \n",
              "3       0       0       0       0       0       0       0       0       0   \n",
              "4       0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0        0  ...         0         0         0         0         0         0   \n",
              "1        0  ...         0         0         0         0         0         0   \n",
              "2        0  ...         0         0         0         0         0         0   \n",
              "3        0  ...         0         0         0         0         0         0   \n",
              "4        0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2         0         0         0         0  \n",
              "3         0         0         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkIBCZ5H_qzw",
        "outputId": "488c6f7e-f0f2-414f-c6cf-79217b4eb0c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14000 entries, 0 to 13999\n",
            "Columns: 784 entries, pixel1 to pixel784\n",
            "dtypes: int64(784)\n",
            "memory usage: 83.7 MB\n"
          ]
        }
      ],
      "source": [
        "test_X.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "upNsfr8k_uTc",
        "outputId": "130b0f5c-b402-4c2a-ef9b-9c0dd1b791dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    7\n",
              "1    3\n",
              "2    1\n",
              "3    1\n",
              "4    2\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yDbB4Jt_v9m",
        "outputId": "f6e0e34d-75e9-4f45-f459-cbf379578720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 14000 entries, 0 to 13999\n",
            "Series name: class\n",
            "Non-Null Count  Dtype\n",
            "--------------  -----\n",
            "14000 non-null  int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 109.5 KB\n"
          ]
        }
      ],
      "source": [
        "test_Y.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8SbCvVE8vAK"
      },
      "source": [
        "## Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YniWK6x8wqZ"
      },
      "source": [
        "* Based on `Data Exploration` done in [01_explore_data.ipynb](https://github.com/gaurangdave/mnist_digits_recognition/blob/main/notebooks/01_explore_data.ipynb) below is the outline of the pipeline we are going to create,\n",
        "  * Pipeline Parameters\n",
        "    * `method` - To indicate whether we are going to `normalize`, `binarize` or leave the data as it is `none`.\n",
        "    * `threshold` - only applicable to `binarize` option to help set the threshold for binarization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HNMxsagAi2r"
      },
      "source": [
        "### Preprocessing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bxK8im4e_90L"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data, method=\"none\", threshold = 128):\n",
        "    \"\"\"\n",
        "    Preprocess MNIST data based on the specified method.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Input dataset with only features.\n",
        "        method (str): Preprocessing method - \"normalize\", \"binarize\", or \"none\".\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Preprocessed dataset.\n",
        "    \"\"\"\n",
        "    if method == \"normalize\":\n",
        "        scaler = MinMaxScaler()\n",
        "        transformed_data = scaler.fit_transform(data)\n",
        "        return pd.DataFrame(transformed_data)\n",
        "    elif method == \"binarize\":\n",
        "        binarizer = Binarizer(threshold=threshold)\n",
        "        transformed_data = binarizer.fit_transform(data)\n",
        "        return pd.DataFrame(transformed_data)\n",
        "    # else, keep features unchanged (no transformation)\n",
        "\n",
        "    # Combine processed features and labels\n",
        "    return pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7z3R3SAjlJT"
      },
      "source": [
        "* Lets create a `FunctionalTransformer` and test the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qE1_hInplZos"
      },
      "outputs": [],
      "source": [
        "## helper function to print aggregated descrition of features\n",
        "def print_aggregated_description(data):\n",
        "  # Check the range of normalized pixel values\n",
        "  print(f\"Min of mins in data is {data.iloc[:, :].min().min()} and max of mins in data is {data.iloc[:, :].min().max()}\")\n",
        "  print(f\"Min of max in data is {data.iloc[:, :].max().min()} and max of max in data is {data.iloc[:, :].max().max()}\")\n",
        "\n",
        "  # # Check the mean and standard deviation\n",
        "  print(f\"Aggregated mean of data is {data.iloc[:, :].mean().mean()}\")\n",
        "  print(f\"Aggregated standard deviation of data is {data.iloc[:, :].std().mean()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gWoKBHNBjj3a"
      },
      "outputs": [],
      "source": [
        "preprocess_transformer = FunctionTransformer(preprocess_data, feature_names_out=\"one-to-one\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3oRpt0-k0qa",
        "outputId": "51d0851f-e814-417c-d030-f1d820cfe5f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min of mins in data is 0 and max of mins in data is 0\n",
            "Min of max in data is 0 and max of max in data is 255\n",
            "Aggregated mean of data is 33.40283570973032\n",
            "Aggregated standard deviation of data is 49.25044784975305\n"
          ]
        }
      ],
      "source": [
        "## this should output the dataframe as it is without any changes.\n",
        "preprocessed_data = pd.DataFrame(preprocess_transformer.fit_transform(train_X, y=None), columns=preprocess_transformer.get_feature_names_out())\n",
        "print_aggregated_description(preprocessed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erAGLqzEl3g_"
      },
      "source": [
        "Observation:\n",
        "* Here aggregated min is 0 and max is 255 which matches the raw data as expected and aggreagated mean and standard deviation also matches the raw data as expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zplfk5TmjqE",
        "outputId": "6aae3bc2-07e9-40c3-e075-a93bebd302db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min of mins in data is 0.0 and max of mins in data is 0.0\n",
            "Min of max in data is 0.0 and max of max in data is 1.0\n",
            "Aggregated mean of data is 0.13099372795196987\n",
            "Aggregated standard deviation of data is 0.19343918583584427\n"
          ]
        }
      ],
      "source": [
        "## this should normalized the dataframe.\n",
        "preprocess_transformer = FunctionTransformer(preprocess_data, kw_args={\"method\": \"normalize\"}, feature_names_out=\"one-to-one\")\n",
        "preprocessed_data = pd.DataFrame(preprocess_transformer.fit_transform(train_X), columns=preprocess_transformer.get_feature_names_out())\n",
        "print_aggregated_description(preprocessed_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRPCTjj-puW6",
        "outputId": "de3cb1fa-6a6d-4254-f085-2e4f72a57b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min of mins in data is 0 and max of mins in data is 0\n",
            "Min of max in data is 0 and max of max in data is 1\n",
            "Aggregated mean of data is 0.13101193513119536\n",
            "Aggregated standard deviation of data is 0.21739390727945354\n"
          ]
        }
      ],
      "source": [
        "## this should binarize the dataframe.\n",
        "preprocess_transformer = FunctionTransformer(preprocess_data, kw_args={\"method\": \"binarize\", \"threshold\": 128}, feature_names_out=\"one-to-one\")\n",
        "preprocessed_data = pd.DataFrame(preprocess_transformer.fit_transform(train_X), columns=preprocess_transformer.get_feature_names_out())\n",
        "print_aggregated_description(preprocessed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPCzQjCWC6Is"
      },
      "source": [
        "## Plan\n",
        "\n",
        "* As a learning experience, we've decided to explore the following ML Algorithms to explore for classification,\n",
        "  1. Logistic Regression.\n",
        "  1. Support Vector Classifier (SVC).\n",
        "  1. K-Nearest Neighbour.\n",
        "  1. Random Forest Classifier.\n",
        "* We'll use the following metrics for each model,\n",
        "  * Accuracy\n",
        "  * Weighted F1 Score\n",
        "  * Per-class F1 Score\n",
        "* For `Logistic Regression` and `SVC` we'll focus on `hyperparameter tuning` and `threshold tuning` to get the best results.\n",
        "* For `KNN` and `Random Forest Classifier` we'll just focus on `hyperparameter tuning` to reduce the complexity and focus on getting handson experience with what we've learnt so far.\n",
        "* For all algorithms we'll do the following,\n",
        "  * Find a baseline model using cross validation\n",
        "  * Find hyper params using grid search cv\n",
        "    * Get the metrics for hypertuned model using cross validation for apples to apples comparison between baseline and hypertuned.\n",
        "* We need to do cross validation again for hypertuned model because once the hyper params are discovered, grid search cv trains a model on complete training data. And so when we calculate the performance metrics these numbers are inflated since model has already seen the data.\n",
        "  * To do the right comparison we either need to have a unseen validation set or use the hyper parameters in cross validation to get the right numbers.  For now we've decided to go with cross validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-yAhBe9FbSn"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfaWej-HGh6w"
      },
      "source": [
        "* Lets create models using `DummyClassifier` with stratified and most frequest strategies to create a baseline for comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj7r39b3GwZT"
      },
      "source": [
        "### Stratified Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB4Nr3smFgEW",
        "outputId": "ad50b7b6-2416-4342-d6a5-10ee6bf3128c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratified Prediction - Accuracy: 0.0988\n",
            "Weighted F1: 0.0988\n"
          ]
        }
      ],
      "source": [
        "# Create a dummy classifier that predicts randomly based on class distribution\n",
        "dummy_stratified = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
        "dummy_stratified.fit(train_X, train_Y)\n",
        "\n",
        "# Predict and evaluate\n",
        "stratified_predictions = dummy_stratified.predict(test_X)\n",
        "stratified_accuracy = accuracy_score(test_Y, stratified_predictions)\n",
        "stratified_f1 = f1_score(test_Y, stratified_predictions, average=\"weighted\")\n",
        "print(f\"Stratified Prediction - Accuracy: {stratified_accuracy:.4f}\")\n",
        "print(f\"Weighted F1: {stratified_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjsuDeV2HYRS"
      },
      "source": [
        "### Most Frequest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ga2H6OHHczq",
        "outputId": "3706cb82-2e07-4130-c0f5-0c65ff4cba00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most Frequent Class - Accuracy: 0.1125\n",
            "Weighted F1: 0.0228\n"
          ]
        }
      ],
      "source": [
        "# Create a dummy classifier that predicts the most frequent class\n",
        "dummy_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_most_frequent.fit(train_X, train_Y)\n",
        "\n",
        "# Predict and evaluate\n",
        "most_frequent_predictions = dummy_most_frequent.predict(test_X)\n",
        "most_frequent_accuracy = accuracy_score(test_Y, most_frequent_predictions)\n",
        "most_frequent_f1 = f1_score(test_Y, most_frequent_predictions, average=\"weighted\")\n",
        "print(f\"Most Frequent Class - Accuracy: {most_frequent_accuracy:.4f}\")\n",
        "print(f\"Weighted F1: {most_frequent_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y472_QuZHzmU"
      },
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "ByQVdH6kH1QU",
        "outputId": "49e1aa56-b91f-433f-d2b1-64d79aa00a1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Most Frequent</td>\n",
              "      <td>0.112500</td>\n",
              "      <td>0.022753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stratified</td>\n",
              "      <td>0.098786</td>\n",
              "      <td>0.098806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Model  Accuracy  Weighted F1\n",
              "0  Most Frequent  0.112500     0.022753\n",
              "1     Stratified  0.098786     0.098806"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline_results = pd.DataFrame({\n",
        "    \"Model\": [\"Most Frequent\", \"Stratified\"],\n",
        "    \"Accuracy\": [most_frequent_accuracy, stratified_accuracy],\n",
        "    \"Weighted F1\": [most_frequent_f1, stratified_f1]\n",
        "})\n",
        "\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju4Jf7fZIHaJ"
      },
      "source": [
        "### Observations\n",
        "* Both baseline models have very low `F1 Score` and `Accuracy` as expected.\n",
        "* Since the train and test set were stratified, the frequency of classes in both the sets are more or less similar which explains why the accuracy of `Frequent Dummy Classifier` is more than `Stratified`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPvHuOq4RUSR"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9fciyb7LRkAQ"
      },
      "outputs": [],
      "source": [
        "## helper function to calculate per class f1 scores\n",
        "def per_class_f1_score(actual_classes, prediction_classes):\n",
        "    # Compute F1 scores for each class directly\n",
        "    f1_scores = f1_score(actual_classes, prediction_classes, average=None)\n",
        "    # Create a list of dictionaries for output\n",
        "    per_class_f1_scores = [{\"class\": i, \"f1_score\": score} for i, score in enumerate(f1_scores)]\n",
        "\n",
        "    return per_class_f1_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Dey7q6cLRTRV"
      },
      "outputs": [],
      "source": [
        "def update_model_comparison(probabilities, true_labels, algorithm, method, comparison_df=None):\n",
        "    \"\"\"\n",
        "    Updates the model comparison DataFrame with metrics for a given model.\n",
        "\n",
        "    Args:\n",
        "        probabilities (ndarray): Probabilities or predicted values for the dataset.\n",
        "        true_labels (Series or ndarray): True labels for the dataset.\n",
        "        algorithm (str): Name of the algorithm (e.g., 'Logistic Regression').\n",
        "        method (str): Method used (e.g., 'Default Params', 'Grid Search').\n",
        "        comparison_df (DataFrame or None): Existing comparison DataFrame. If None, a new one is created.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Updated comparison DataFrame with metrics for the given model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get predicted classes (argmax for probabilities)\n",
        "    predicted_classes = probabilities.argmax(axis=1)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(true_labels, predicted_classes)\n",
        "    weighted_f1 = f1_score(true_labels, predicted_classes, average='weighted')\n",
        "    roc_score = roc_auc_score(train_Y, probabilities, multi_class=\"ovr\")\n",
        "    # Compute per-class F1 scores\n",
        "    per_class_f1_scores = f1_score(true_labels, predicted_classes, average=None)\n",
        "    per_class_f1_dict = {f\"Class_{i}\": score for i, score in enumerate(per_class_f1_scores)}\n",
        "\n",
        "    # Create a new row with metrics\n",
        "    new_row = {\n",
        "        \"Algorithm\": algorithm,\n",
        "        \"Method\": method,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Weighted F1 Score\": weighted_f1,\n",
        "        \"ROC AUC Score\": roc_score,\n",
        "        **per_class_f1_dict,  # Unpack per-class F1 scores\n",
        "    }\n",
        "\n",
        "    # Initialize or update the DataFrame\n",
        "    if comparison_df is None:\n",
        "      return pd.DataFrame([new_row])\n",
        "\n",
        "\n",
        "    # Append the new row\n",
        "    comparison_df = pd.concat([comparison_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "    return comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "406loEhhSdTq"
      },
      "outputs": [],
      "source": [
        "## helper function to save the model metrics to google drive\n",
        "models_path = Path(\"..\", \"models\")\n",
        "def save_comparison_df(comparison_df):\n",
        "  comparison_df.to_csv(f\"{str(models_path)}/mnist_models_metrics.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "CI3pe4YULN82"
      },
      "outputs": [],
      "source": [
        "## helper function to dump and save the model on google drive\n",
        "from joblib import dump\n",
        "def save_model(estimator, file_name):\n",
        "  ## model path\n",
        "  model_path = Path(\"..\", \"models\", file_name)\n",
        "  dump(estimator, str(model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKxYTxfRAkJO"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvZbJe2nxayj"
      },
      "source": [
        "* Lets start with default estimator in logistic regression, we'll analyze the performance, tune the threshold and get the final performance numbers\n",
        "* After that we'll experiment with hyperparameters using `GridSearchCV` and `RandomSearchCV` tune the threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fVOmadOySA8"
      },
      "source": [
        "### Default Estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2zFd01si0fi"
      },
      "source": [
        "#### Initialize Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "L65-bv9pAbri"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "## initialize LogisticRegression\n",
        "logistic_regression = LogisticRegression(max_iter=10000)\n",
        "\n",
        "## create pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessing\", FunctionTransformer(preprocess_data, kw_args={\"method\": \"normalize\"})),\n",
        "    (\"training\", logistic_regression)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmiAnaHc_9jD"
      },
      "source": [
        "#### Finding Probabilies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gSJZ14Bh8jgf"
      },
      "outputs": [],
      "source": [
        "probabilities = cross_val_predict(pipeline, train_X, train_Y, cv=3, method=\"predict_proba\", n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY8MOnPETCH5",
        "outputId": "639c971c-2c3d-4e81-eb0f-a35e1e35b205"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[9.98539849e-01, 1.72487179e-17, 3.04786440e-08, ...,\n",
              "        8.46459391e-11, 1.14099141e-09, 1.56510674e-11],\n",
              "       [2.17677175e-11, 8.05965604e-05, 2.73645806e-06, ...,\n",
              "        9.96868621e-01, 6.65571635e-04, 2.29046998e-03],\n",
              "       [9.99287289e-01, 3.93336806e-12, 2.53542609e-05, ...,\n",
              "        2.36146724e-06, 3.75609944e-05, 2.72536315e-04],\n",
              "       ...,\n",
              "       [1.34196753e-10, 9.94951280e-01, 6.46942453e-05, ...,\n",
              "        4.78412044e-06, 2.28747392e-03, 2.65979418e-04],\n",
              "       [2.62376595e-08, 1.57345691e-08, 4.04014881e-05, ...,\n",
              "        1.51480874e-03, 4.64608394e-03, 9.77021388e-01],\n",
              "       [1.07720256e-07, 2.95387863e-06, 5.60961756e-05, ...,\n",
              "        2.72198097e-01, 1.98544675e-03, 6.64139264e-02]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "B5tSibO-SOcZ"
      },
      "outputs": [],
      "source": [
        "## create/update comparison_df to compare metrics from all the models.\n",
        "comparison_df = update_model_comparison(probabilities, train_Y, \"Logistic Regression V0\", \"Default Estimator\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "cVEUbyFoTPgl",
        "outputId": "c0950f41-a26e-4da0-c19a-3d6cbacb2fbe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Method</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1 Score</th>\n",
              "      <th>ROC AUC Score</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>Default Estimator</td>\n",
              "      <td>0.919839</td>\n",
              "      <td>0.919697</td>\n",
              "      <td>0.992891</td>\n",
              "      <td>0.96094</td>\n",
              "      <td>0.964241</td>\n",
              "      <td>0.904483</td>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.926959</td>\n",
              "      <td>0.879824</td>\n",
              "      <td>0.944259</td>\n",
              "      <td>0.929785</td>\n",
              "      <td>0.880834</td>\n",
              "      <td>0.897883</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Algorithm             Method  Accuracy  Weighted F1 Score  \\\n",
              "0  Logistic Regression  Default Estimator  0.919839           0.919697   \n",
              "\n",
              "   ROC AUC Score  Class_0   Class_1   Class_2   Class_3   Class_4   Class_5  \\\n",
              "0       0.992891  0.96094  0.964241  0.904483  0.898339  0.926959  0.879824   \n",
              "\n",
              "    Class_6   Class_7   Class_8   Class_9  \n",
              "0  0.944259  0.929785  0.880834  0.897883  "
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RB2djq1cX4dt"
      },
      "outputs": [],
      "source": [
        "save_comparison_df(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yrkCW1qbfB8"
      },
      "source": [
        "#### Save Probabilites\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ymA_vsE2besn"
      },
      "outputs": [],
      "source": [
        "probabilities_df = pd.DataFrame(probabilities, columns=[f\"Class_{i}\" for i in range(probabilities.shape[1])])\n",
        "probabilities_df.to_csv(f\"{str(models_path)}/default_logistic_regression_probabilites.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU-fGCHzjrew"
      },
      "source": [
        "Observations:\n",
        "* `ROC AUC Score` of ~.99 means our estimator has high `True Positive Rate (TPR)` and a very low `False Positive Rate (FPR)`\n",
        "  * i.e. The model has very accurate discrimination rate between different classes\n",
        "* `F1 Score` of ~0.92 is a descent score, but this also tells us that our model has a low `Recall` i.e it has a higher `False Negative` rate.\n",
        "* Per class f1 score tells us that f1 score of class instance of 3, 5 8 and 9 is significantly lower than rest of classes and these might have an impact of overall f1 score.\n",
        "* Lets take a look at confusion matrix before threshold tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi84nT-QCjB8"
      },
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsN_OWbsBpiU"
      },
      "source": [
        "* Lets look at normalized data in percentage to get more useful insight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3HH3m7o3OnIh"
      },
      "outputs": [],
      "source": [
        "predictions = np.argmax(probabilities, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "nctXheonBcvg",
        "outputId": "72cd9357-3ce9-4a05-afa0-fcce1436f636"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1754f4ec0>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(train_Y, predictions, normalize=\"true\", values_format=\".0%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U40FMUIvCI83"
      },
      "source": [
        "Observations:\n",
        "* So the percent of predictions for `3`, `5` and `8` are significantly less than rest of the classes as expected\n",
        "* Which is interesting because when it comes to hand written digits, `3`, `5` and `8` are similar and can be confusing depending on the handwriting.\n",
        "* Lets focus more on errors by putting 0 weight on correct predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "8m0DNiq36cSj",
        "outputId": "2ad14d21-74ee-46d7-a44f-e05e80456c7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x307ade720>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample_weight = (predictions != train_Y)\n",
        "ConfusionMatrixDisplay.from_predictions(train_Y, predictions, normalize=\"true\", values_format=\".0%\", sample_weight=sample_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCDC3FyB0jFx"
      },
      "source": [
        "Observations:\n",
        "* This is interesting, this confusion matrix highlights some interesting chunks of errors,\n",
        "  * `47%` of errors of 4 (False Negatives) and `48%` of errors of 7 were classified as 9. This kind of makes sense, cause when we write 4 or 7 its kind of similar to 9. The straight line of 7 or angle of 4 can be mis represented as curve of 9.\n",
        "  * Also majoriy of misclassified 3s are classified as 2, 5 and 8.\n",
        "  * Similarly majority of misclassified 5s are classified as 3 and 8 and majority of 8s are misclassified as 3 and 5.\n",
        "  * This makes sense cause hand written 2,3,5 and 8 share similar patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrYkVZKu3XBm"
      },
      "source": [
        "#### Threshold Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss2mdS_y3Zha"
      },
      "source": [
        "* Lets see if we can find a better threshold and improve the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJyhYj-x5fY1"
      },
      "source": [
        "##### Per Class Threshold Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "QWUGXAUgz_GM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "def calculate_per_class_threshold(actual_classes, prediction_probabilities):\n",
        "    thresholds = []\n",
        "    for class_label in range(10):  # Loop through all classes\n",
        "        # Convert actual_classes to binary labels for the current class\n",
        "        binary_labels = (actual_classes == class_label).astype(int)\n",
        "        # Extract probabilities for the current class\n",
        "        class_probabilities = prediction_probabilities[:, class_label]\n",
        "\n",
        "        # Calculate ROC curve\n",
        "        fpr, tpr, threshold = roc_curve(binary_labels, class_probabilities)\n",
        "\n",
        "        # Calculate F1 scores for each threshold\n",
        "        f1_scores = (2 * tpr * (1 - fpr)) / (tpr + (1 - fpr))\n",
        "\n",
        "        # Handle any division by zero or invalid values in F1 scores\n",
        "        f1_scores = np.nan_to_num(f1_scores)\n",
        "\n",
        "        # Find the threshold with the highest F1 score\n",
        "        optimal_idx = f1_scores.argmax()\n",
        "        optimal_threshold = threshold[optimal_idx]\n",
        "\n",
        "        # Store the threshold for this class\n",
        "        thresholds.append({ \"class\": class_label, \"optimal_threshold\" : optimal_threshold})\n",
        "\n",
        "    return thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "-DeNMSM25sPJ"
      },
      "outputs": [],
      "source": [
        "# Assuming `train_Y` contains actual class labels and `probabilities` contains class probabilities\n",
        "thresholds = calculate_per_class_threshold(train_Y, probabilities)\n",
        "threshold_df = pd.DataFrame(thresholds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6dxb7WcEO1c"
      },
      "source": [
        "##### Predictions With Thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "8MnIXgms9wQo"
      },
      "outputs": [],
      "source": [
        "## helper functions to predict using optimized thresholds\n",
        "def predict_with_thresholds(prediction_probabilities, thresholds):\n",
        "    predictions = []\n",
        "    for i in range(prediction_probabilities.shape[0]):  # Iterate over each sample\n",
        "        # Check if probabilities exceed their respective thresholds\n",
        "        class_probs = [(cls, prob) for cls, prob in enumerate(prediction_probabilities[i]) if prob >= thresholds[thresholds[\"class\"] == cls][\"optimal_threshold\"].values[0]]\n",
        "\n",
        "        if class_probs:\n",
        "            # Choose the class with the highest probability among those exceeding thresholds\n",
        "            predictions.append(max(class_probs, key=lambda x: x[1])[0])\n",
        "        else:\n",
        "            # If no class exceeds threshold, default to the one with the highest probability\n",
        "            predictions.append(prediction_probabilities[i].argmax())\n",
        "\n",
        "    return np.array(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "0JenNxGVE8Tm"
      },
      "outputs": [],
      "source": [
        "optimized_predictions = predict_with_thresholds(probabilities, thresholds=threshold_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybdatWwyFZpI",
        "outputId": "392a8e94-0094-401a-9b1d-97e5beda8cd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9196967787148708"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(train_Y, optimized_predictions, average=\"weighted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgLDMuZZHVVN"
      },
      "source": [
        "* Original `f1 score` was `0.9197076517400227` so no change there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qiMZfDOLTVh"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9Y2t2o8PkBY"
      },
      "source": [
        "* For `Hyperparameter Tuning` we'll use the following strategy\n",
        "  * Iteration 1 : First we'll experiment with different solvers [‘newton-cg’, ‘sag’, ‘saga’, ‘lbfgs’] and different transformation techniqune ['normalization', 'binarization']\n",
        "  * Iteration 2 : Next along with above params we'll add penalty ['l2', 'None'] since `l2` works with all solvers we'll experiment with and without penalty, along with C [0.01, 0.1, 1, 10, 100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayan9m5NSH3E"
      },
      "source": [
        "#### Iteration 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "GkCXLl7oLYvH"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"logisticregression__solver\": [\"newton-cg\", \"sag\", \"saga\", \"lbfgs\"],\n",
        "    \"preprocessing__kw_args\": [{\"method\": \"normalize\"}, {\"method\": \"binarize\"}],\n",
        "}\n",
        "\n",
        "## initialize LogisticRegression\n",
        "logistic_regression = LogisticRegression(max_iter=10000, verbose=1)\n",
        "\n",
        "## create pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessing\", FunctionTransformer(preprocess_data, kw_args={\"method\": \"normalize\"})),\n",
        "    (\"logisticregression\", logistic_regression)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "1DqwUwy0SyWy",
        "outputId": "c8b825a2-1407-4052-db19-d8b64a8677b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06772560469289908 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06745058123962074 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06750060268395257 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05424221012737024 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596280984522609 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.054371692338912696 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05446629223870036 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05595957070928089 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0556326571727961 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.023210490038465433 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025091128394095222 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0245430528305145 <= 0.0001 False\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 1, change: 1.00000000\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02525569404177914 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024388942315533235 <= 0.0001 False\n",
            "Epoch 1, change: 1.00000000\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.023023988305067158 <= 0.0001 False\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 1, change: 1.00000000\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013746480066164886 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014559964695867489 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.01453673896669188 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014599888853006008 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014506205604912571 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013596754560941109 <= 0.0001 False\n",
            "Epoch 2, change: 0.24865864\n",
            "Epoch 2, change: 0.36647678\n",
            "Epoch 2, change: 0.29386721\n",
            "Epoch 2, change: 0.32148413\n",
            "Epoch 2, change: 0.25812319\n",
            "Epoch 2, change: 0.28986238\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00494944865053879 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007107543699753866 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007593654728518624 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007506879794766388 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007283441377992933 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005054019827049796 <= 0.0001 False\n",
            "Epoch 3, change: 0.22171622\n",
            "Epoch 3, change: 0.20613473\n",
            "Epoch 3, change: 0.21621281\n",
            "Epoch 3, change: 0.19832113\n",
            "Epoch 3, change: 0.19328530\n",
            "Epoch 3, change: 0.16775909\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.002563370178058731 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031146963465692153 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0033611405003100485 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031707711255545726 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032522697034441383 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023202958093750045 <= 0.0001 False\n",
            "Epoch 4, change: 0.12729397\n",
            "Epoch 4, change: 0.12755039\n",
            "Epoch 4, change: 0.13491624\n",
            "Epoch 4, change: 0.19121028\n",
            "Epoch 4, change: 0.12511857\n",
            "Epoch 4, change: 0.14503491\n",
            "Epoch 5, change: 0.13133022\n",
            "Epoch 5, change: 0.09371020\n",
            "Epoch 5, change: 0.11439235\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007994908562239658 <= 0.0001 False\n",
            "Epoch 5, change: 0.10503200\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000887177890845067 <= 0.0001 False\n",
            "Epoch 5, change: 0.08146338\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0008578870970225558 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0012795083476968949 <= 0.0001 False\n",
            "Epoch 5, change: 0.08841249\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000913237919852819 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000836455371295198 <= 0.0001 False\n",
            "Epoch 6, change: 0.08035769\n",
            "Epoch 6, change: 0.07654656\n",
            "Epoch 6, change: 0.08977503\n",
            "Epoch 6, change: 0.08294649\n",
            "Epoch 6, change: 0.07422547\n",
            "Epoch 6, change: 0.06143041\n",
            "Epoch 7, change: 0.06028040\n",
            "Epoch 7, change: 0.07136131\n",
            "Epoch 7, change: 0.05548686\n",
            "Epoch 7, change: 0.05278947\n",
            "Epoch 7, change: 0.06460077\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0004552780825930107 <= 0.0001 False\n",
            "Epoch 7, change: 0.04885093\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005685017146812178 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005845979579338345 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005773570836641845 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005088976609375899 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005284668717374731 <= 0.0001 False\n",
            "Epoch 8, change: 0.04717712\n",
            "Epoch 8, change: 0.04359227\n",
            "Epoch 8, change: 0.05375643\n",
            "Epoch 8, change: 0.04589179\n",
            "Epoch 8, change: 0.05247699\n",
            "Epoch 8, change: 0.03883345\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002756891144761195 <= 0.0001 False\n",
            "Epoch 9, change: 0.03433386\n",
            "Epoch 9, change: 0.03846445\n",
            "Epoch 9, change: 0.04173839\n",
            "Epoch 9, change: 0.03900072\n",
            "Epoch 9, change: 0.04398572\n",
            "Epoch 9, change: 0.03383991\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00035367276188885525 <= 0.0001 False\n",
            "Epoch 10, change: 0.03072347\n",
            "Epoch 10, change: 0.03492023\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002830050563447772 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00034405090618695744 <= 0.0001 False\n",
            "Epoch 10, change: 0.03778305\n",
            "Epoch 10, change: 0.03524338\n",
            "Epoch 10, change: 0.03823454\n",
            "Epoch 10, change: 0.03163448\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00032831161461654914 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003457691373532914 <= 0.0001 False\n",
            "Epoch 11, change: 0.02780696\n",
            "Epoch 11, change: 0.03067384\n",
            "Epoch 11, change: 0.03431223\n",
            "Epoch 11, change: 0.03140496\n",
            "Epoch 11, change: 0.03324576\n",
            "Epoch 11, change: 0.02931569\n",
            "Epoch 12, change: 0.02688595\n",
            "Epoch 12, change: 0.02852438\n",
            "Epoch 12, change: 0.03178672\n",
            "Epoch 12, change: 0.02856877\n",
            "Epoch 12, change: 0.03169308\n",
            "Epoch 12, change: 0.02754888\n",
            "Epoch 13, change: 0.02683920\n",
            "Epoch 13, change: 0.02639175\n",
            "Epoch 13, change: 0.02969605\n",
            "Epoch 13, change: 0.02858239\n",
            "Epoch 13, change: 0.02878084\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000150611754857631 <= 0.0001 False\n",
            "Epoch 13, change: 0.02419729\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00013874705645879417 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00022188555862540438 <= 0.0001 False\n",
            "Epoch 14, change: 0.02460968\n",
            "Epoch 14, change: 0.02552885\n",
            "Epoch 14, change: 0.02797707\n",
            "Epoch 14, change: 0.02657147\n",
            "Epoch 14, change: 0.02747142\n",
            "Epoch 14, change: 0.02230165\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010949043378872298 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00014093211515910775 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010587022746062941 <= 0.0001 False\n",
            "Epoch 15, change: 0.02309984\n",
            "Epoch 15, change: 0.02304878\n",
            "Epoch 15, change: 0.02661938\n",
            "Epoch 15, change: 0.02496275\n",
            "Epoch 15, change: 0.02609325\n",
            "Epoch 15, change: 0.02174656\n",
            "Epoch 16, change: 0.02148375\n",
            "Epoch 16, change: 0.02226008\n",
            "Epoch 16, change: 0.02468815\n",
            "Epoch 16, change: 0.02394754\n",
            "Epoch 16, change: 0.02451492\n",
            "Epoch 16, change: 0.02028875\n",
            "Epoch 17, change: 0.02061280\n",
            "Epoch 17, change: 0.02192285\n",
            "Epoch 17, change: 0.02315878\n",
            "Epoch 17, change: 0.02220360\n",
            "Epoch 17, change: 0.02232042\n",
            "Epoch 17, change: 0.01933583\n",
            "Epoch 18, change: 0.01974310\n",
            "Epoch 18, change: 0.02089160\n",
            "Epoch 18, change: 0.02115210\n",
            "Epoch 18, change: 0.02159306\n",
            "Epoch 18, change: 0.02168671\n",
            "Epoch 18, change: 0.01855754\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.3043549648403533e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2281260307051291.\n",
            "Epoch 19, change: 0.01861085\n",
            "Epoch 19, change: 0.01973659\n",
            "Epoch 19, change: 0.01987521\n",
            "Epoch 19, change: 0.02015558\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 4.115658599819953e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.22256316337129556.\n",
            "Epoch 19, change: 0.01947375\n",
            "Epoch 19, change: 0.01710411\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 9.829169845516656e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2261625773537494.\n",
            "Epoch 20, change: 0.01726284\n",
            "Epoch 20, change: 0.01890221\n",
            "Epoch 20, change: 0.01894933\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 3.4261423127887806e-05 <= 0.0001 True\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "  Solver did converge at loss = 0.22214318537060465.\n",
            "    max |gradient| <= tol: 2.9769157620122838e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.21649195609951896.\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 20, change: 0.01906566\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.8331698858140754e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2182472068133294.\n",
            "Epoch 20, change: 0.01905724\n",
            "Epoch 20, change: 0.01647431\n",
            "Epoch 21, change: 0.01637887\n",
            "Epoch 21, change: 0.01821368\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 21, change: 0.01820656\n",
            "Epoch 21, change: 0.01827512\n",
            "Epoch 2, change: 0.23846947\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 21, change: 0.01583097\n",
            "Epoch 21, change: 0.01845793\n",
            "Epoch 22, change: 0.01556850\n",
            "Epoch 22, change: 0.01746287\n",
            "Epoch 22, change: 0.01726702\n",
            "Epoch 2, change: 0.23832414\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 22, change: 0.01752915\n",
            "Epoch 1, change: 1.00000000\n",
            "Epoch 3, change: 0.12129111\n",
            "Epoch 22, change: 0.01492869\n",
            "Epoch 22, change: 0.01782925\n",
            "Epoch 2, change: 0.24715690\n",
            "Epoch 23, change: 0.01477858\n",
            "Epoch 23, change: 0.01671368\n",
            "Epoch 23, change: 0.01601824\n",
            "Epoch 3, change: 0.13287272\n",
            "Epoch 2, change: 0.27809118\n",
            "Epoch 2, change: 0.23547118\n",
            "Epoch 23, change: 0.01666498\n",
            "Epoch 23, change: 0.01406333\n",
            "Epoch 4, change: 0.08849722\n",
            "Epoch 2, change: 0.28198249\n",
            "Epoch 23, change: 0.01692312\n",
            "Epoch 3, change: 0.15070680\n",
            "Epoch 24, change: 0.01425029\n",
            "Epoch 24, change: 0.01614498\n",
            "Epoch 24, change: 0.01520769\n",
            "Epoch 4, change: 0.09209502\n",
            "Epoch 3, change: 0.17217681\n",
            "Epoch 3, change: 0.12885538\n",
            "Epoch 24, change: 0.01581176\n",
            "Epoch 5, change: 0.07147157\n",
            "Epoch 24, change: 0.01329199\n",
            "Epoch 24, change: 0.01606916\n",
            "Epoch 3, change: 0.14031430\n",
            "Epoch 4, change: 0.11282583\n",
            "Epoch 25, change: 0.01338346\n",
            "Epoch 25, change: 0.01564450\n",
            "Epoch 25, change: 0.01465080\n",
            "Epoch 5, change: 0.08559916\n",
            "Epoch 4, change: 0.11781652\n",
            "Epoch 25, change: 0.01512503\n",
            "Epoch 4, change: 0.09247120\n",
            "Epoch 6, change: 0.06174257\n",
            "Epoch 25, change: 0.01280303\n",
            "Epoch 25, change: 0.01532570\n",
            "Epoch 4, change: 0.12297094\n",
            "Epoch 5, change: 0.08528442\n",
            "Epoch 26, change: 0.01486106\n",
            "Epoch 26, change: 0.01278532\n",
            "Epoch 26, change: 0.01397013\n",
            "Epoch 6, change: 0.06998558\n",
            "Epoch 5, change: 0.10704520\n",
            "Epoch 26, change: 0.01427104\n",
            "Epoch 5, change: 0.08019301\n",
            "Epoch 7, change: 0.05401301\n",
            "Epoch 26, change: 0.01471974\n",
            "Epoch 26, change: 0.01232878\n",
            "Epoch 5, change: 0.08906696\n",
            "Epoch 6, change: 0.06969197\n",
            "Epoch 27, change: 0.01415744\n",
            "Epoch 27, change: 0.01230465\n",
            "Epoch 27, change: 0.01312617\n",
            "Epoch 7, change: 0.06029309\n",
            "Epoch 6, change: 0.08263802\n",
            "Epoch 27, change: 0.01368990\n",
            "Epoch 6, change: 0.06601762\n",
            "Epoch 8, change: 0.04685463\n",
            "Epoch 27, change: 0.01412477\n",
            "Epoch 27, change: 0.01191904\n",
            "Epoch 6, change: 0.07266876\n",
            "Epoch 7, change: 0.05904008\n",
            "Epoch 28, change: 0.01356002\n",
            "Epoch 28, change: 0.01176936\n",
            "Epoch 28, change: 0.01249427\n",
            "Epoch 8, change: 0.05039937\n",
            "Epoch 9, change: 0.04271278\n",
            "Epoch 7, change: 0.07287180\n",
            "Epoch 7, change: 0.05463184\n",
            "Epoch 28, change: 0.01303503\n",
            "Epoch 28, change: 0.01350634\n",
            "Epoch 28, change: 0.01140690\n",
            "Epoch 7, change: 0.06010947\n",
            "Epoch 8, change: 0.04972024\n",
            "Epoch 29, change: 0.01300420\n",
            "Epoch 29, change: 0.01127307\n",
            "Epoch 29, change: 0.01209372\n",
            "Epoch 9, change: 0.04499377\n",
            "Epoch 8, change: 0.06037513\n",
            "Epoch 29, change: 0.01269885\n",
            "Epoch 29, change: 0.01275617\n",
            "Epoch 10, change: 0.03678948\n",
            "Epoch 29, change: 0.01092223\n",
            "Epoch 8, change: 0.04962802\n",
            "Epoch 8, change: 0.04980655\n",
            "Epoch 9, change: 0.04270273\n",
            "Epoch 30, change: 0.01246678\n",
            "Epoch 30, change: 0.01080393\n",
            "Epoch 30, change: 0.01165271\n",
            "Epoch 10, change: 0.04032218\n",
            "Epoch 9, change: 0.04969348\n",
            "Epoch 30, change: 0.01217327\n",
            "Epoch 30, change: 0.01210074\n",
            "Epoch 11, change: 0.03507642\n",
            "Epoch 30, change: 0.01050875\n",
            "Epoch 9, change: 0.04458334\n",
            "Epoch 10, change: 0.03688272\n",
            "Epoch 9, change: 0.04608711\n",
            "Epoch 31, change: 0.01204435\n",
            "Epoch 31, change: 0.01040406\n",
            "Epoch 31, change: 0.01133012\n",
            "Epoch 11, change: 0.03587497\n",
            "Epoch 31, change: 0.01149298\n",
            "Epoch 31, change: 0.01167757\n",
            "Epoch 10, change: 0.04443486\n",
            "Epoch 31, change: 0.01015506\n",
            "Epoch 12, change: 0.03049590\n",
            "Epoch 32, change: 0.01165843\n",
            "Epoch 11, change: 0.03236285\n",
            "Epoch 10, change: 0.03780383\n",
            "Epoch 32, change: 0.01004329\n",
            "Epoch 10, change: 0.04248282\n",
            "Epoch 32, change: 0.01065609\n",
            "Epoch 32, change: 0.01091260\n",
            "Epoch 12, change: 0.03175371\n",
            "Epoch 32, change: 0.01124937\n",
            "Epoch 32, change: 0.00974478\n",
            "Epoch 11, change: 0.03714123\n",
            "Epoch 13, change: 0.03002910\n",
            "Epoch 33, change: 0.01111016\n",
            "Epoch 33, change: 0.00989954\n",
            "Epoch 12, change: 0.02945751\n",
            "Epoch 11, change: 0.03943204\n",
            "Epoch 11, change: 0.03283385\n",
            "Epoch 33, change: 0.01030417\n",
            "Epoch 33, change: 0.01038638\n",
            "Epoch 13, change: 0.02856045\n",
            "Epoch 33, change: 0.00932371\n",
            "Epoch 33, change: 0.01088615\n",
            "Epoch 14, change: 0.02801961\n",
            "Epoch 12, change: 0.03437036\n",
            "Epoch 34, change: 0.01057859\n",
            "Epoch 34, change: 0.00964368\n",
            "Epoch 13, change: 0.02606897\n",
            "Epoch 12, change: 0.03663786\n",
            "Epoch 12, change: 0.03025437\n",
            "Epoch 34, change: 0.01002873\n",
            "Epoch 34, change: 0.00979329\n",
            "Epoch 34, change: 0.01048995\n",
            "Epoch 34, change: 0.00899642\n",
            "Epoch 15, change: 0.02638616\n",
            "Epoch 14, change: 0.02527927\n",
            "Epoch 13, change: 0.03099035\n",
            "Epoch 35, change: 0.01031787\n",
            "Epoch 35, change: 0.00945760\n",
            "Epoch 14, change: 0.02329739\n",
            "Epoch 13, change: 0.02850423\n",
            "Epoch 35, change: 0.00974345\n",
            "Epoch 13, change: 0.03400488\n",
            "Epoch 35, change: 0.00936069\n",
            "Epoch 35, change: 0.01012354\n",
            "Epoch 35, change: 0.00873060\n",
            "Epoch 16, change: 0.02511393\n",
            "Epoch 15, change: 0.02341497\n",
            "Epoch 36, change: 0.00994870\n",
            "Epoch 14, change: 0.02841009\n",
            "Epoch 36, change: 0.00912107\n",
            "Epoch 15, change: 0.02187359\n",
            "Epoch 14, change: 0.02646943\n",
            "Epoch 36, change: 0.00945496\n",
            "Epoch 14, change: 0.03095267\n",
            "Epoch 36, change: 0.00891532\n",
            "Epoch 36, change: 0.00974707\n",
            "Epoch 36, change: 0.00842132\n",
            "Epoch 17, change: 0.02388485\n",
            "Epoch 16, change: 0.02153960\n",
            "Epoch 37, change: 0.00951294\n",
            "Epoch 37, change: 0.00876032\n",
            "Epoch 15, change: 0.02684281\n",
            "Epoch 15, change: 0.02495392\n",
            "Epoch 37, change: 0.00918552\n",
            "Epoch 16, change: 0.02058987\n",
            "Epoch 15, change: 0.02955944\n",
            "Epoch 37, change: 0.00846656\n",
            "Epoch 37, change: 0.00938013\n",
            "Epoch 37, change: 0.00810212\n",
            "Epoch 18, change: 0.02272881\n",
            "Epoch 17, change: 0.01950229\n",
            "Epoch 38, change: 0.00922140\n",
            "Epoch 38, change: 0.00852310\n",
            "Epoch 16, change: 0.02438279\n",
            "Epoch 16, change: 0.02394120\n",
            "Epoch 38, change: 0.00899294\n",
            "Epoch 17, change: 0.01984766\n",
            "Epoch 16, change: 0.02674072\n",
            "Epoch 38, change: 0.00817020\n",
            "Epoch 38, change: 0.00906904\n",
            "Epoch 38, change: 0.00782013\n",
            "Epoch 39, change: 0.00887734\n",
            "Epoch 19, change: 0.02159630\n",
            "Epoch 18, change: 0.01787539\n",
            "Epoch 39, change: 0.00827707\n",
            "Epoch 17, change: 0.02332331\n",
            "Epoch 17, change: 0.02247211\n",
            "Epoch 39, change: 0.00876447\n",
            "Epoch 18, change: 0.01831390\n",
            "Epoch 17, change: 0.02570014\n",
            "Epoch 39, change: 0.00786491\n",
            "Epoch 39, change: 0.00875044\n",
            "Epoch 39, change: 0.00756941\n",
            "Epoch 40, change: 0.00815163\n",
            "Epoch 19, change: 0.01647713\n",
            "Epoch 40, change: 0.00860234\n",
            "Epoch 18, change: 0.02151938\n",
            "Epoch 20, change: 0.02078543\n",
            "Epoch 40, change: 0.00858525\n",
            "Epoch 18, change: 0.02097547\n",
            "Epoch 18, change: 0.02393964\n",
            "Epoch 19, change: 0.01781452\n",
            "Epoch 40, change: 0.00753670\n",
            "Epoch 40, change: 0.00843164\n",
            "Epoch 40, change: 0.00734174\n",
            "Epoch 41, change: 0.00791978\n",
            "Epoch 20, change: 0.01592977\n",
            "Epoch 41, change: 0.00827830\n",
            "Epoch 19, change: 0.01993305\n",
            "Epoch 21, change: 0.02009896\n",
            "Epoch 41, change: 0.00837564\n",
            "Epoch 19, change: 0.02287251\n",
            "Epoch 19, change: 0.02028816\n",
            "Epoch 20, change: 0.01711068\n",
            "Epoch 41, change: 0.00716032\n",
            "Epoch 41, change: 0.00816799\n",
            "Epoch 41, change: 0.00706156\n",
            "Epoch 42, change: 0.00774856\n",
            "Epoch 21, change: 0.01512316\n",
            "Epoch 42, change: 0.00798299\n",
            "Epoch 20, change: 0.01915967\n",
            "Epoch 42, change: 0.00810312\n",
            "Epoch 22, change: 0.01913668\n",
            "Epoch 20, change: 0.01932412\n",
            "Epoch 20, change: 0.02163115\n",
            "Epoch 21, change: 0.01628452\n",
            "Epoch 42, change: 0.00683657\n",
            "Epoch 42, change: 0.00792710\n",
            "Epoch 42, change: 0.00686571\n",
            "Epoch 43, change: 0.00764383\n",
            "Epoch 22, change: 0.01472146\n",
            "Epoch 43, change: 0.00771572\n",
            "Epoch 21, change: 0.01803191\n",
            "Epoch 43, change: 0.00792765\n",
            "Epoch 23, change: 0.01834143\n",
            "Epoch 21, change: 0.02047262\n",
            "Epoch 22, change: 0.01576355\n",
            "Epoch 21, change: 0.01866810\n",
            "Epoch 43, change: 0.00654579\n",
            "Epoch 43, change: 0.00771878\n",
            "Epoch 43, change: 0.00657238\n",
            "Epoch 44, change: 0.00741625\n",
            "Epoch 44, change: 0.00746322\n",
            "Epoch 22, change: 0.01719748\n",
            "Epoch 23, change: 0.01418677\n",
            "Epoch 44, change: 0.00778146\n",
            "Epoch 22, change: 0.01854715\n",
            "Epoch 24, change: 0.01775231\n",
            "Epoch 23, change: 0.01496970\n",
            "Epoch 22, change: 0.01785872\n",
            "Epoch 44, change: 0.00622374\n",
            "Epoch 44, change: 0.00747347\n",
            "Epoch 44, change: 0.00637252\n",
            "Epoch 45, change: 0.00721455\n",
            "Epoch 45, change: 0.00718685\n",
            "Epoch 45, change: 0.00756527\n",
            "Epoch 23, change: 0.01591910\n",
            "Epoch 24, change: 0.01367927\n",
            "Epoch 23, change: 0.01759762\n",
            "Epoch 25, change: 0.01703185\n",
            "Epoch 45, change: 0.00598865\n",
            "Epoch 23, change: 0.01706928\n",
            "Epoch 24, change: 0.01445385\n",
            "Epoch 45, change: 0.00720031\n",
            "Epoch 45, change: 0.00623479\n",
            "Epoch 46, change: 0.00690915\n",
            "Epoch 46, change: 0.00696644\n",
            "Epoch 46, change: 0.00739413\n",
            "Epoch 24, change: 0.01557052\n",
            "Epoch 25, change: 0.01294154\n",
            "Epoch 24, change: 0.01711977\n",
            "Epoch 46, change: 0.00575849\n",
            "Epoch 26, change: 0.01641796\n",
            "Epoch 24, change: 0.01625629\n",
            "Epoch 46, change: 0.00593982\n",
            "Epoch 25, change: 0.01370499\n",
            "Epoch 46, change: 0.00701433\n",
            "Epoch 47, change: 0.00675685\n",
            "Epoch 47, change: 0.00668723\n",
            "Epoch 47, change: 0.00723001\n",
            "Epoch 25, change: 0.01475717\n",
            "Epoch 26, change: 0.01250458\n",
            "Epoch 25, change: 0.01639652\n",
            "Epoch 47, change: 0.00553637\n",
            "Epoch 25, change: 0.01598854\n",
            "Epoch 27, change: 0.01564771\n",
            "Epoch 47, change: 0.00581124\n",
            "Epoch 47, change: 0.00674960\n",
            "Epoch 26, change: 0.01348764\n",
            "Epoch 48, change: 0.00661655\n",
            "Epoch 48, change: 0.00643393\n",
            "Epoch 48, change: 0.00709313\n",
            "Epoch 26, change: 0.01423579\n",
            "Epoch 48, change: 0.00531060\n",
            "Epoch 27, change: 0.01215257\n",
            "Epoch 48, change: 0.00564161\n",
            "Epoch 26, change: 0.01541477\n",
            "Epoch 26, change: 0.01572328\n",
            "Epoch 28, change: 0.01544540\n",
            "Epoch 48, change: 0.00656017\n",
            "Epoch 27, change: 0.01288507\n",
            "Epoch 49, change: 0.00640337\n",
            "Epoch 49, change: 0.00620774\n",
            "Epoch 49, change: 0.00696831\n",
            "Epoch 27, change: 0.01381672\n",
            "Epoch 49, change: 0.00513538\n",
            "Epoch 49, change: 0.00540568\n",
            "Epoch 28, change: 0.01191200\n",
            "Epoch 27, change: 0.01517793\n",
            "Epoch 27, change: 0.01469601\n",
            "Epoch 49, change: 0.00636647\n",
            "Epoch 29, change: 0.01467861\n",
            "Epoch 28, change: 0.01254252\n",
            "Epoch 50, change: 0.00626051\n",
            "Epoch 50, change: 0.00600819\n",
            "Epoch 50, change: 0.00679543\n",
            "Epoch 28, change: 0.01349102\n",
            "Epoch 50, change: 0.00488715\n",
            "Epoch 50, change: 0.00527226\n",
            "Epoch 28, change: 0.01466972\n",
            "Epoch 28, change: 0.01445326\n",
            "Epoch 50, change: 0.00623194\n",
            "Epoch 29, change: 0.01149261\n",
            "Epoch 30, change: 0.01428315\n",
            "Epoch 29, change: 0.01193196\n",
            "Epoch 51, change: 0.00610116\n",
            "Epoch 51, change: 0.00579882\n",
            "Epoch 51, change: 0.00662845\n",
            "Epoch 51, change: 0.00469725\n",
            "Epoch 29, change: 0.01296395\n",
            "Epoch 51, change: 0.00507063\n",
            "Epoch 29, change: 0.01357509\n",
            "Epoch 51, change: 0.00603542\n",
            "Epoch 29, change: 0.01432645\n",
            "Epoch 30, change: 0.01114909\n",
            "Epoch 31, change: 0.01387496\n",
            "Epoch 52, change: 0.00599942\n",
            "Epoch 30, change: 0.01188514\n",
            "Epoch 52, change: 0.00557973\n",
            "Epoch 52, change: 0.00651242\n",
            "Epoch 52, change: 0.00452905\n",
            "Epoch 30, change: 0.01268331\n",
            "Epoch 52, change: 0.00494089\n",
            "Epoch 52, change: 0.00588127\n",
            "Epoch 30, change: 0.01332568\n",
            "Epoch 30, change: 0.01386404\n",
            "Epoch 31, change: 0.01077818\n",
            "Epoch 32, change: 0.01322951\n",
            "Epoch 53, change: 0.00587523\n",
            "Epoch 31, change: 0.01139227\n",
            "Epoch 53, change: 0.00540279\n",
            "Epoch 53, change: 0.00638595\n",
            "Epoch 53, change: 0.00438080\n",
            "Epoch 31, change: 0.01232127\n",
            "Epoch 53, change: 0.00482150\n",
            "Epoch 53, change: 0.00568953\n",
            "Epoch 31, change: 0.01297023\n",
            "Epoch 31, change: 0.01338951\n",
            "Epoch 32, change: 0.01045195\n",
            "Epoch 54, change: 0.00565534\n",
            "Epoch 32, change: 0.01091987\n",
            "Epoch 33, change: 0.01291799\n",
            "Epoch 54, change: 0.00522729\n",
            "Epoch 54, change: 0.00624290\n",
            "Epoch 54, change: 0.00420924\n",
            "Epoch 54, change: 0.00471029\n",
            "Epoch 32, change: 0.01193874\n",
            "Epoch 54, change: 0.00553615\n",
            "Epoch 32, change: 0.01248409\n",
            "Epoch 32, change: 0.01259655\n",
            "Epoch 33, change: 0.01026465\n",
            "Epoch 55, change: 0.00553326\n",
            "Epoch 33, change: 0.01063321\n",
            "Epoch 55, change: 0.00505693\n",
            "Epoch 34, change: 0.01255494\n",
            "Epoch 55, change: 0.00609659\n",
            "Epoch 55, change: 0.00454379\n",
            "Epoch 55, change: 0.00410948\n",
            "Epoch 33, change: 0.01154598\n",
            "Epoch 55, change: 0.00539349\n",
            "Epoch 33, change: 0.01224189\n",
            "Epoch 56, change: 0.00540534\n",
            "Epoch 33, change: 0.01250049\n",
            "Epoch 34, change: 0.00991047\n",
            "Epoch 56, change: 0.00490607\n",
            "Epoch 34, change: 0.01032180\n",
            "Epoch 35, change: 0.01209819\n",
            "Epoch 56, change: 0.00596660\n",
            "Epoch 56, change: 0.00442567\n",
            "Epoch 56, change: 0.00399210\n",
            "Epoch 56, change: 0.00522750\n",
            "Epoch 34, change: 0.01133075\n",
            "Epoch 34, change: 0.01179529\n",
            "Epoch 34, change: 0.01210509\n",
            "Epoch 57, change: 0.00523780\n",
            "Epoch 35, change: 0.00961061\n",
            "Epoch 57, change: 0.00476371\n",
            "Epoch 35, change: 0.00994635\n",
            "Epoch 57, change: 0.00585989\n",
            "Epoch 36, change: 0.01176345\n",
            "Epoch 57, change: 0.00386177\n",
            "Epoch 57, change: 0.00509177\n",
            "Epoch 57, change: 0.00430786\n",
            "Epoch 35, change: 0.01094622\n",
            "Epoch 35, change: 0.01145926\n",
            "Epoch 58, change: 0.00510970\n",
            "Epoch 36, change: 0.00939586\n",
            "Epoch 35, change: 0.01133391\n",
            "Epoch 58, change: 0.00461514\n",
            "Epoch 36, change: 0.00976329\n",
            "Epoch 58, change: 0.00573702\n",
            "Epoch 37, change: 0.01146997\n",
            "Epoch 58, change: 0.00376440\n",
            "Epoch 58, change: 0.00497518\n",
            "Epoch 58, change: 0.00414813\n",
            "Epoch 36, change: 0.01061299\n",
            "Epoch 36, change: 0.01108637\n",
            "Epoch 59, change: 0.00496540\n",
            "Epoch 37, change: 0.00919275\n",
            "Epoch 36, change: 0.01100175\n",
            "Epoch 59, change: 0.00447173\n",
            "Epoch 37, change: 0.00942789\n",
            "Epoch 59, change: 0.00562836\n",
            "Epoch 38, change: 0.01121158\n",
            "Epoch 59, change: 0.00366655\n",
            "Epoch 59, change: 0.00485938\n",
            "Epoch 59, change: 0.00400630\n",
            "Epoch 37, change: 0.01048508\n",
            "Epoch 37, change: 0.01094662\n",
            "Epoch 38, change: 0.00888888\n",
            "Epoch 60, change: 0.00482410\n",
            "Epoch 60, change: 0.00434940\n",
            "Epoch 37, change: 0.01059579\n",
            "Epoch 38, change: 0.00925136\n",
            "Epoch 60, change: 0.00551448\n",
            "Epoch 60, change: 0.00473508\n",
            "Epoch 39, change: 0.01079177\n",
            "Epoch 60, change: 0.00357007\n",
            "Epoch 60, change: 0.00390092\n",
            "Epoch 38, change: 0.01019966\n",
            "Epoch 38, change: 0.01063967\n",
            "Epoch 61, change: 0.00472900\n",
            "Epoch 61, change: 0.00420127\n",
            "Epoch 38, change: 0.01033290\n",
            "Epoch 39, change: 0.00863221\n",
            "Epoch 39, change: 0.00901244\n",
            "Epoch 61, change: 0.00542111\n",
            "Epoch 40, change: 0.01059518\n",
            "Epoch 61, change: 0.00379442\n",
            "Epoch 61, change: 0.00348128\n",
            "Epoch 61, change: 0.00457494\n",
            "Epoch 39, change: 0.00997005\n",
            "Epoch 39, change: 0.01021130\n",
            "Epoch 62, change: 0.00404201\n",
            "Epoch 62, change: 0.00460998\n",
            "Epoch 40, change: 0.00848191\n",
            "Epoch 40, change: 0.00884825\n",
            "Epoch 39, change: 0.00990639\n",
            "Epoch 62, change: 0.00531214\n",
            "Epoch 62, change: 0.00368765\n",
            "Epoch 62, change: 0.00341615\n",
            "Epoch 41, change: 0.01029547\n",
            "Epoch 62, change: 0.00439759\n",
            "Epoch 40, change: 0.00969700\n",
            "Epoch 63, change: 0.00393692\n",
            "Epoch 40, change: 0.01001921\n",
            "Epoch 63, change: 0.00448050\n",
            "Epoch 41, change: 0.00823784\n",
            "Epoch 40, change: 0.00957037\n",
            "Epoch 41, change: 0.00846480\n",
            "Epoch 63, change: 0.00521276\n",
            "Epoch 63, change: 0.00330508\n",
            "Epoch 63, change: 0.00356860\n",
            "Epoch 42, change: 0.00993950\n",
            "Epoch 63, change: 0.00433315\n",
            "Epoch 41, change: 0.00950211\n",
            "Epoch 64, change: 0.00384642\n",
            "Epoch 41, change: 0.00976051\n",
            "Epoch 64, change: 0.00432335\n",
            "Epoch 42, change: 0.00803582\n",
            "Epoch 41, change: 0.00924913\n",
            "Epoch 42, change: 0.00824248\n",
            "Epoch 64, change: 0.00512301\n",
            "Epoch 64, change: 0.00319264\n",
            "Epoch 64, change: 0.00422151\n",
            "Epoch 64, change: 0.00348485\n",
            "Epoch 43, change: 0.00972005\n",
            "Epoch 42, change: 0.00933882\n",
            "Epoch 65, change: 0.00369887\n",
            "Epoch 65, change: 0.00423759\n",
            "Epoch 42, change: 0.00945811\n",
            "Epoch 43, change: 0.00786763\n",
            "Epoch 42, change: 0.00898426\n",
            "Epoch 65, change: 0.00502155\n",
            "Epoch 43, change: 0.00807360\n",
            "Epoch 65, change: 0.00312045\n",
            "Epoch 65, change: 0.00411545\n",
            "Epoch 65, change: 0.00337404\n",
            "Epoch 44, change: 0.00947718\n",
            "Epoch 43, change: 0.00898031\n",
            "Epoch 66, change: 0.00411663\n",
            "Epoch 43, change: 0.00921664\n",
            "Epoch 66, change: 0.00360553\n",
            "Epoch 44, change: 0.00756279\n",
            "Epoch 66, change: 0.00494009\n",
            "Epoch 44, change: 0.00785936\n",
            "Epoch 43, change: 0.00873726\n",
            "Epoch 66, change: 0.00398609\n",
            "Epoch 66, change: 0.00328108\n",
            "Epoch 66, change: 0.00305362\n",
            "Epoch 45, change: 0.00925841\n",
            "Epoch 44, change: 0.00888255\n",
            "Epoch 67, change: 0.00401597\n",
            "Epoch 67, change: 0.00352961\n",
            "Epoch 44, change: 0.00903770\n",
            "Epoch 45, change: 0.00752360\n",
            "Epoch 67, change: 0.00479085\n",
            "Epoch 45, change: 0.00766209\n",
            "Epoch 44, change: 0.00857767\n",
            "Epoch 67, change: 0.00319579\n",
            "Epoch 67, change: 0.00389027\n",
            "Epoch 67, change: 0.00297113\n",
            "Epoch 46, change: 0.00901943\n",
            "Epoch 68, change: 0.00391055\n",
            "Epoch 45, change: 0.00862434\n",
            "Epoch 68, change: 0.00345036\n",
            "Epoch 45, change: 0.00883971\n",
            "Epoch 46, change: 0.00724729\n",
            "Epoch 68, change: 0.00470418\n",
            "Epoch 46, change: 0.00746976\n",
            "Epoch 68, change: 0.00311530\n",
            "Epoch 45, change: 0.00845647\n",
            "Epoch 68, change: 0.00380214\n",
            "Epoch 68, change: 0.00288948\n",
            "Epoch 47, change: 0.00880238\n",
            "Epoch 69, change: 0.00381700\n",
            "Epoch 46, change: 0.00849336\n",
            "Epoch 69, change: 0.00338487\n",
            "Epoch 46, change: 0.00860649\n",
            "Epoch 47, change: 0.00698840\n",
            "Epoch 69, change: 0.00462581\n",
            "Epoch 47, change: 0.00729123\n",
            "Epoch 69, change: 0.00303630\n",
            "Epoch 69, change: 0.00373178\n",
            "Epoch 46, change: 0.00821918\n",
            "Epoch 69, change: 0.00280719\n",
            "Epoch 48, change: 0.00851714\n",
            "Epoch 70, change: 0.00329308\n",
            "Epoch 70, change: 0.00371918\n",
            "Epoch 47, change: 0.00836011\n",
            "Epoch 48, change: 0.00693404\n",
            "Epoch 47, change: 0.00846620\n",
            "Epoch 70, change: 0.00455013\n",
            "Epoch 70, change: 0.00366700\n",
            "Epoch 70, change: 0.00292248\n",
            "Epoch 48, change: 0.00719680\n",
            "Epoch 70, change: 0.00273665\n",
            "Epoch 47, change: 0.00795188\n",
            "Epoch 49, change: 0.00832128\n",
            "Epoch 71, change: 0.00320940\n",
            "Epoch 71, change: 0.00361342\n",
            "Epoch 48, change: 0.00817465\n",
            "Epoch 49, change: 0.00676697\n",
            "Epoch 71, change: 0.00446996\n",
            "Epoch 48, change: 0.00831105\n",
            "Epoch 71, change: 0.00360201\n",
            "Epoch 71, change: 0.00285923\n",
            "Epoch 49, change: 0.00699906\n",
            "Epoch 71, change: 0.00266375\n",
            "Epoch 48, change: 0.00781761\n",
            "Epoch 50, change: 0.00806285\n",
            "Epoch 72, change: 0.00314692\n",
            "Epoch 72, change: 0.00349156\n",
            "Epoch 49, change: 0.00798629\n",
            "Epoch 72, change: 0.00436840\n",
            "Epoch 49, change: 0.00806720\n",
            "Epoch 50, change: 0.00660957\n",
            "Epoch 72, change: 0.00353923\n",
            "Epoch 72, change: 0.00279401\n",
            "Epoch 50, change: 0.00681453\n",
            "Epoch 72, change: 0.00259820\n",
            "Epoch 73, change: 0.00306917\n",
            "Epoch 49, change: 0.00760362\n",
            "Epoch 51, change: 0.00778279\n",
            "Epoch 73, change: 0.00341463\n",
            "Epoch 73, change: 0.00428405\n",
            "Epoch 50, change: 0.00788817\n",
            "Epoch 50, change: 0.00785704\n",
            "Epoch 51, change: 0.00649888\n",
            "Epoch 73, change: 0.00347630\n",
            "Epoch 51, change: 0.00667501\n",
            "Epoch 73, change: 0.00270349\n",
            "Epoch 73, change: 0.00252081\n",
            "Epoch 74, change: 0.00300357\n",
            "Epoch 74, change: 0.00335371\n",
            "Epoch 50, change: 0.00744054\n",
            "Epoch 52, change: 0.00753677\n",
            "Epoch 74, change: 0.00421337\n",
            "Epoch 51, change: 0.00763680\n",
            "Epoch 52, change: 0.00634154\n",
            "Epoch 74, change: 0.00341730\n",
            "Epoch 74, change: 0.00264953\n",
            "Epoch 51, change: 0.00763781\n",
            "Epoch 52, change: 0.00652078\n",
            "Epoch 74, change: 0.00247864\n",
            "Epoch 75, change: 0.00294936\n",
            "Epoch 75, change: 0.00325638\n",
            "Epoch 51, change: 0.00729140\n",
            "Epoch 53, change: 0.00735167\n",
            "Epoch 75, change: 0.00412662\n",
            "Epoch 52, change: 0.00746276\n",
            "Epoch 75, change: 0.00336062\n",
            "Epoch 53, change: 0.00624334\n",
            "Epoch 75, change: 0.00256541\n",
            "Epoch 52, change: 0.00754442\n",
            "Epoch 53, change: 0.00639445\n",
            "Epoch 75, change: 0.00240449\n",
            "Epoch 76, change: 0.00286180\n",
            "Epoch 76, change: 0.00315275\n",
            "Epoch 54, change: 0.00716743\n",
            "Epoch 52, change: 0.00691417\n",
            "Epoch 76, change: 0.00404860\n",
            "Epoch 53, change: 0.00734032\n",
            "Epoch 76, change: 0.00329815\n",
            "Epoch 76, change: 0.00249989\n",
            "Epoch 54, change: 0.00609976\n",
            "Epoch 53, change: 0.00737288\n",
            "Epoch 76, change: 0.00233334\n",
            "Epoch 54, change: 0.00628048\n",
            "Epoch 77, change: 0.00280147\n",
            "Epoch 77, change: 0.00307905\n",
            "Epoch 53, change: 0.00689526\n",
            "Epoch 55, change: 0.00693055\n",
            "Epoch 77, change: 0.00397902\n",
            "Epoch 77, change: 0.00324181\n",
            "Epoch 77, change: 0.00241830\n",
            "Epoch 54, change: 0.00723643\n",
            "Epoch 54, change: 0.00723310\n",
            "Epoch 77, change: 0.00227697\n",
            "Epoch 55, change: 0.00587218\n",
            "Epoch 55, change: 0.00606151\n",
            "Epoch 78, change: 0.00274100\n",
            "Epoch 78, change: 0.00303261\n",
            "Epoch 54, change: 0.00665074\n",
            "Epoch 78, change: 0.00391796\n",
            "Epoch 56, change: 0.00672359\n",
            "Epoch 78, change: 0.00318915\n",
            "Epoch 78, change: 0.00236910\n",
            "Epoch 55, change: 0.00706480\n",
            "Epoch 55, change: 0.00710393\n",
            "Epoch 78, change: 0.00222603\n",
            "Epoch 56, change: 0.00582400\n",
            "Epoch 56, change: 0.00599692\n",
            "Epoch 79, change: 0.00267357\n",
            "Epoch 79, change: 0.00296307\n",
            "Epoch 55, change: 0.00658345\n",
            "Epoch 79, change: 0.00383389\n",
            "Epoch 57, change: 0.00660355\n",
            "Epoch 79, change: 0.00313423\n",
            "Epoch 79, change: 0.00230982\n",
            "Epoch 56, change: 0.00694721\n",
            "Epoch 79, change: 0.00217241\n",
            "Epoch 56, change: 0.00688486\n",
            "Epoch 57, change: 0.00573971\n",
            "Epoch 57, change: 0.00581747\n",
            "Epoch 80, change: 0.00261429\n",
            "Epoch 80, change: 0.00288421\n",
            "Epoch 56, change: 0.00643859\n",
            "Epoch 80, change: 0.00376350\n",
            "Epoch 58, change: 0.00643896\n",
            "Epoch 80, change: 0.00308243\n",
            "Epoch 80, change: 0.00223424\n",
            "Epoch 57, change: 0.00672042\n",
            "Epoch 57, change: 0.00683368\n",
            "Epoch 80, change: 0.00212743\n",
            "Epoch 58, change: 0.00564132\n",
            "Epoch 58, change: 0.00573779\n",
            "Epoch 81, change: 0.00256335\n",
            "Epoch 81, change: 0.00283868\n",
            "Epoch 81, change: 0.00369008\n",
            "Epoch 57, change: 0.00628814\n",
            "Epoch 81, change: 0.00302611\n",
            "Epoch 59, change: 0.00623766\n",
            "Epoch 81, change: 0.00218873\n",
            "Epoch 58, change: 0.00653100\n",
            "Epoch 81, change: 0.00207242\n",
            "Epoch 58, change: 0.00667381\n",
            "Epoch 59, change: 0.00545494\n",
            "Epoch 82, change: 0.00250737\n",
            "Epoch 82, change: 0.00275241\n",
            "Epoch 59, change: 0.00559046\n",
            "Epoch 58, change: 0.00617034\n",
            "Epoch 82, change: 0.00363152\n",
            "Epoch 82, change: 0.00297797\n",
            "Epoch 60, change: 0.00610881\n",
            "Epoch 82, change: 0.00212074\n",
            "Epoch 82, change: 0.00202863\n",
            "Epoch 59, change: 0.00631206\n",
            "Epoch 59, change: 0.00653565\n",
            "Epoch 60, change: 0.00532192\n",
            "Epoch 83, change: 0.00246172\n",
            "Epoch 83, change: 0.00267608\n",
            "Epoch 60, change: 0.00549282\n",
            "Epoch 83, change: 0.00356608\n",
            "Epoch 59, change: 0.00596129\n",
            "Epoch 83, change: 0.00292795\n",
            "Epoch 61, change: 0.00603058\n",
            "Epoch 83, change: 0.00208161\n",
            "Epoch 83, change: 0.00199162\n",
            "Epoch 60, change: 0.00618738\n",
            "Epoch 60, change: 0.00645175\n",
            "Epoch 61, change: 0.00522765\n",
            "Epoch 84, change: 0.00241310\n",
            "Epoch 84, change: 0.00258072\n",
            "Epoch 61, change: 0.00541660\n",
            "Epoch 84, change: 0.00287901\n",
            "Epoch 60, change: 0.00590292\n",
            "Epoch 84, change: 0.00350087\n",
            "Epoch 84, change: 0.00202897\n",
            "Epoch 84, change: 0.00193815\n",
            "Epoch 62, change: 0.00578405\n",
            "Epoch 61, change: 0.00604975\n",
            "Epoch 61, change: 0.00628170\n",
            "Epoch 85, change: 0.00236889\n",
            "Epoch 85, change: 0.00251330\n",
            "Epoch 62, change: 0.00513259\n",
            "Epoch 62, change: 0.00525446\n",
            "Epoch 85, change: 0.00283514\n",
            "Epoch 85, change: 0.00343142\n",
            "Epoch 61, change: 0.00575035\n",
            "Epoch 85, change: 0.00198798\n",
            "Epoch 85, change: 0.00189798\n",
            "Epoch 63, change: 0.00573247\n",
            "Epoch 62, change: 0.00585033\n",
            "Epoch 86, change: 0.00231074\n",
            "Epoch 62, change: 0.00613835\n",
            "Epoch 86, change: 0.00246812\n",
            "Epoch 63, change: 0.00501598\n",
            "Epoch 63, change: 0.00520897\n",
            "Epoch 86, change: 0.00278483\n",
            "Epoch 86, change: 0.00336849\n",
            "Epoch 62, change: 0.00560081\n",
            "Epoch 86, change: 0.00193957\n",
            "Epoch 86, change: 0.00185334\n",
            "Epoch 87, change: 0.00223181\n",
            "Epoch 63, change: 0.00573208\n",
            "Epoch 64, change: 0.00557696\n",
            "Epoch 87, change: 0.00241812\n",
            "Epoch 63, change: 0.00603445\n",
            "Epoch 64, change: 0.00494492\n",
            "Epoch 64, change: 0.00507722\n",
            "Epoch 87, change: 0.00273829\n",
            "Epoch 87, change: 0.00330896\n",
            "Epoch 63, change: 0.00555747\n",
            "Epoch 87, change: 0.00188869\n",
            "Epoch 87, change: 0.00180995\n",
            "Epoch 88, change: 0.00218873\n",
            "Epoch 64, change: 0.00559439\n",
            "Epoch 88, change: 0.00235916\n",
            "Epoch 65, change: 0.00544536\n",
            "Epoch 64, change: 0.00589941\n",
            "Epoch 65, change: 0.00487040\n",
            "Epoch 65, change: 0.00493842\n",
            "Epoch 88, change: 0.00269764\n",
            "Epoch 88, change: 0.00326042\n",
            "Epoch 64, change: 0.00547022\n",
            "Epoch 88, change: 0.00186780\n",
            "Epoch 88, change: 0.00177167\n",
            "Epoch 89, change: 0.00215073\n",
            "Epoch 89, change: 0.00229246\n",
            "Epoch 65, change: 0.00545905\n",
            "Epoch 66, change: 0.00537110\n",
            "Epoch 65, change: 0.00575301\n",
            "Epoch 66, change: 0.00472360\n",
            "Epoch 66, change: 0.00489255\n",
            "Epoch 89, change: 0.00265277\n",
            "Epoch 89, change: 0.00320383\n",
            "Epoch 89, change: 0.00182186\n",
            "Epoch 65, change: 0.00523648\n",
            "Epoch 89, change: 0.00172353\n",
            "Epoch 90, change: 0.00210216\n",
            "Epoch 90, change: 0.00223662\n",
            "Epoch 66, change: 0.00531613\n",
            "Epoch 66, change: 0.00567762\n",
            "Epoch 67, change: 0.00521074\n",
            "Epoch 67, change: 0.00466189\n",
            "Epoch 67, change: 0.00481495\n",
            "Epoch 90, change: 0.00260215\n",
            "Epoch 90, change: 0.00313672\n",
            "Epoch 90, change: 0.00178584\n",
            "Epoch 66, change: 0.00517863\n",
            "Epoch 90, change: 0.00168855\n",
            "Epoch 91, change: 0.00204616\n",
            "Epoch 91, change: 0.00219014\n",
            "Epoch 67, change: 0.00519305\n",
            "Epoch 67, change: 0.00557479\n",
            "Epoch 68, change: 0.00512693\n",
            "Epoch 68, change: 0.00457877\n",
            "Epoch 91, change: 0.00256089\n",
            "Epoch 91, change: 0.00307449\n",
            "Epoch 68, change: 0.00469919\n",
            "Epoch 91, change: 0.00175885\n",
            "Epoch 67, change: 0.00507773\n",
            "Epoch 91, change: 0.00165311\n",
            "Epoch 92, change: 0.00200356\n",
            "Epoch 92, change: 0.00215160\n",
            "Epoch 68, change: 0.00505240\n",
            "Epoch 68, change: 0.00548873\n",
            "Epoch 69, change: 0.00449519\n",
            "Epoch 92, change: 0.00252110\n",
            "Epoch 92, change: 0.00302167\n",
            "Epoch 69, change: 0.00502199\n",
            "Epoch 69, change: 0.00461984\n",
            "Epoch 92, change: 0.00170791\n",
            "Epoch 68, change: 0.00496527\n",
            "Epoch 92, change: 0.00161845\n",
            "Epoch 93, change: 0.00196257\n",
            "Epoch 93, change: 0.00210860\n",
            "Epoch 69, change: 0.00492411\n",
            "Epoch 69, change: 0.00532592\n",
            "Epoch 93, change: 0.00248262\n",
            "Epoch 93, change: 0.00296289\n",
            "Epoch 70, change: 0.00439944\n",
            "Epoch 70, change: 0.00449393\n",
            "Epoch 70, change: 0.00493345\n",
            "Epoch 93, change: 0.00167341\n",
            "Epoch 69, change: 0.00489342\n",
            "Epoch 93, change: 0.00158315\n",
            "Epoch 94, change: 0.00192421\n",
            "Epoch 94, change: 0.00207108\n",
            "Epoch 70, change: 0.00483301\n",
            "Epoch 70, change: 0.00523812\n",
            "Epoch 94, change: 0.00244140\n",
            "Epoch 94, change: 0.00291237\n",
            "Epoch 71, change: 0.00434989\n",
            "Epoch 71, change: 0.00444484\n",
            "Epoch 71, change: 0.00482601\n",
            "Epoch 94, change: 0.00164407\n",
            "Epoch 70, change: 0.00483201\n",
            "Epoch 94, change: 0.00154926\n",
            "Epoch 95, change: 0.00203084\n",
            "Epoch 95, change: 0.00187834\n",
            "Epoch 71, change: 0.00475422\n",
            "Epoch 71, change: 0.00513816\n",
            "Epoch 95, change: 0.00239827\n",
            "Epoch 95, change: 0.00285920\n",
            "Epoch 72, change: 0.00474238\n",
            "Epoch 72, change: 0.00438736\n",
            "Epoch 95, change: 0.00161681\n",
            "Epoch 72, change: 0.00423654\n",
            "Epoch 71, change: 0.00478788\n",
            "Epoch 95, change: 0.00151531\n",
            "Epoch 96, change: 0.00199353\n",
            "Epoch 96, change: 0.00184292\n",
            "Epoch 72, change: 0.00457716\n",
            "Epoch 96, change: 0.00236084\n",
            "Epoch 72, change: 0.00504343\n",
            "Epoch 96, change: 0.00281474\n",
            "Epoch 96, change: 0.00157055\n",
            "Epoch 73, change: 0.00415697\n",
            "Epoch 73, change: 0.00467387\n",
            "Epoch 73, change: 0.00430772\n",
            "Epoch 72, change: 0.00467835\n",
            "Epoch 96, change: 0.00147723\n",
            "Epoch 97, change: 0.00195501\n",
            "Epoch 97, change: 0.00180176\n",
            "Epoch 73, change: 0.00451424\n",
            "Epoch 97, change: 0.00232557\n",
            "Epoch 73, change: 0.00492248\n",
            "Epoch 97, change: 0.00276555\n",
            "Epoch 97, change: 0.00154220\n",
            "Epoch 74, change: 0.00460279\n",
            "Epoch 74, change: 0.00410055\n",
            "Epoch 74, change: 0.00425160\n",
            "Epoch 97, change: 0.00144828\n",
            "Epoch 98, change: 0.00191971\n",
            "Epoch 73, change: 0.00463512\n",
            "Epoch 98, change: 0.00175892\n",
            "Epoch 74, change: 0.00442419\n",
            "Epoch 98, change: 0.00229097\n",
            "Epoch 74, change: 0.00485662\n",
            "Epoch 98, change: 0.00271012\n",
            "Epoch 98, change: 0.00151078\n",
            "Epoch 75, change: 0.00449558\n",
            "Epoch 75, change: 0.00419959\n",
            "Epoch 98, change: 0.00141805\n",
            "Epoch 75, change: 0.00403652\n",
            "Epoch 99, change: 0.00188554\n",
            "Epoch 74, change: 0.00456408\n",
            "Epoch 99, change: 0.00172206\n",
            "Epoch 75, change: 0.00426523\n",
            "Epoch 99, change: 0.00225771\n",
            "Epoch 99, change: 0.00266124\n",
            "Epoch 75, change: 0.00477469\n",
            "Epoch 99, change: 0.00147859\n",
            "Epoch 76, change: 0.00443827\n",
            "Epoch 99, change: 0.00139156\n",
            "Epoch 76, change: 0.00416395\n",
            "Epoch 76, change: 0.00394243\n",
            "Epoch 100, change: 0.00184918\n",
            "Epoch 100, change: 0.00168651\n",
            "Epoch 75, change: 0.00451811\n",
            "Epoch 100, change: 0.00221736\n",
            "Epoch 100, change: 0.00261800\n",
            "Epoch 76, change: 0.00419561\n",
            "Epoch 76, change: 0.00467868\n",
            "Epoch 100, change: 0.00144270\n",
            "Epoch 77, change: 0.00435781\n",
            "Epoch 100, change: 0.00135830\n",
            "Epoch 101, change: 0.00181417\n",
            "Epoch 77, change: 0.00387067\n",
            "Epoch 101, change: 0.00165100\n",
            "Epoch 76, change: 0.00445618\n",
            "Epoch 77, change: 0.00412982\n",
            "Epoch 101, change: 0.00217718\n",
            "Epoch 101, change: 0.00256995\n",
            "Epoch 77, change: 0.00408194\n",
            "Epoch 77, change: 0.00459714\n",
            "Epoch 101, change: 0.00140975\n",
            "Epoch 78, change: 0.00429145\n",
            "Epoch 102, change: 0.00178176\n",
            "Epoch 101, change: 0.00133119\n",
            "Epoch 78, change: 0.00381094\n",
            "Epoch 102, change: 0.00161466\n",
            "Epoch 77, change: 0.00438054\n",
            "Epoch 78, change: 0.00407791\n",
            "Epoch 102, change: 0.00214331\n",
            "Epoch 102, change: 0.00252691\n",
            "Epoch 78, change: 0.00453407\n",
            "Epoch 78, change: 0.00399119\n",
            "Epoch 102, change: 0.00138191\n",
            "Epoch 102, change: 0.00130386\n",
            "Epoch 79, change: 0.00422370\n",
            "Epoch 103, change: 0.00175136\n",
            "Epoch 79, change: 0.00372714\n",
            "Epoch 103, change: 0.00157881\n",
            "Epoch 78, change: 0.00434898\n",
            "Epoch 79, change: 0.00398457\n",
            "Epoch 103, change: 0.00210944\n",
            "Epoch 103, change: 0.00248434\n",
            "Epoch 79, change: 0.00441588\n",
            "Epoch 79, change: 0.00391638\n",
            "Epoch 103, change: 0.00136501\n",
            "Epoch 103, change: 0.00127411\n",
            "Epoch 104, change: 0.00172188\n",
            "Epoch 80, change: 0.00418484\n",
            "Epoch 104, change: 0.00154528\n",
            "Epoch 80, change: 0.00367354\n",
            "Epoch 79, change: 0.00429007\n",
            "Epoch 80, change: 0.00393995\n",
            "Epoch 104, change: 0.00207744\n",
            "Epoch 104, change: 0.00243634\n",
            "Epoch 80, change: 0.00437870\n",
            "Epoch 80, change: 0.00383542\n",
            "Epoch 104, change: 0.00134059\n",
            "Epoch 104, change: 0.00124609\n",
            "Epoch 81, change: 0.00405553\n",
            "Epoch 105, change: 0.00151727\n",
            "Epoch 105, change: 0.00168628\n",
            "Epoch 81, change: 0.00363168\n",
            "Epoch 80, change: 0.00425031\n",
            "Epoch 81, change: 0.00390474\n",
            "Epoch 105, change: 0.00204294\n",
            "Epoch 105, change: 0.00240150\n",
            "Epoch 81, change: 0.00425363\n",
            "Epoch 105, change: 0.00131453\n",
            "Epoch 81, change: 0.00374632\n",
            "Epoch 106, change: 0.00148205\n",
            "Epoch 105, change: 0.00121729\n",
            "Epoch 82, change: 0.00402336\n",
            "Epoch 106, change: 0.00165219\n",
            "Epoch 82, change: 0.00354180\n",
            "Epoch 81, change: 0.00416181\n",
            "Epoch 82, change: 0.00383120\n",
            "Epoch 106, change: 0.00236392\n",
            "Epoch 106, change: 0.00201181\n",
            "Epoch 106, change: 0.00128842\n",
            "Epoch 82, change: 0.00419506\n",
            "Epoch 82, change: 0.00367478\n",
            "Epoch 107, change: 0.00144917\n",
            "Epoch 106, change: 0.00119330\n",
            "Epoch 83, change: 0.00396269\n",
            "Epoch 107, change: 0.00162213\n",
            "Epoch 83, change: 0.00349745\n",
            "Epoch 82, change: 0.00413492\n",
            "Epoch 107, change: 0.00231051\n",
            "Epoch 107, change: 0.00198166\n",
            "Epoch 83, change: 0.00379271\n",
            "Epoch 107, change: 0.00125444\n",
            "Epoch 83, change: 0.00413667\n",
            "Epoch 83, change: 0.00356638\n",
            "Epoch 108, change: 0.00141957\n",
            "Epoch 107, change: 0.00116991\n",
            "Epoch 84, change: 0.00389251\n",
            "Epoch 108, change: 0.00159501\n",
            "Epoch 84, change: 0.00343299\n",
            "Epoch 83, change: 0.00406114\n",
            "Epoch 108, change: 0.00226723\n",
            "Epoch 108, change: 0.00194898\n",
            "Epoch 84, change: 0.00374008\n",
            "Epoch 108, change: 0.00122851\n",
            "Epoch 84, change: 0.00408351\n",
            "Epoch 109, change: 0.00139471\n",
            "Epoch 84, change: 0.00350565\n",
            "Epoch 108, change: 0.00114753\n",
            "Epoch 109, change: 0.00156511\n",
            "Epoch 85, change: 0.00382323\n",
            "Epoch 85, change: 0.00338297\n",
            "Epoch 84, change: 0.00402084\n",
            "Epoch 109, change: 0.00222733\n",
            "Epoch 109, change: 0.00191962\n",
            "Epoch 85, change: 0.00371724\n",
            "Epoch 109, change: 0.00120009\n",
            "Epoch 110, change: 0.00136588\n",
            "Epoch 85, change: 0.00398690\n",
            "Epoch 85, change: 0.00343348\n",
            "Epoch 110, change: 0.00153622\n",
            "Epoch 109, change: 0.00112463\n",
            "Epoch 86, change: 0.00379973\n",
            "Epoch 86, change: 0.00331080\n",
            "Epoch 85, change: 0.00396719\n",
            "Epoch 110, change: 0.00219131\n",
            "Epoch 110, change: 0.00188788\n",
            "Epoch 86, change: 0.00364184\n",
            "Epoch 110, change: 0.00118324\n",
            "Epoch 111, change: 0.00133428\n",
            "Epoch 86, change: 0.00391348\n",
            "Epoch 111, change: 0.00150721\n",
            "Epoch 110, change: 0.00110279\n",
            "Epoch 86, change: 0.00336659\n",
            "Epoch 87, change: 0.00370741\n",
            "Epoch 87, change: 0.00326533\n",
            "Epoch 86, change: 0.00392772\n",
            "Epoch 111, change: 0.00215458\n",
            "Epoch 111, change: 0.00185894\n",
            "Epoch 111, change: 0.00116099\n",
            "Epoch 87, change: 0.00360775\n",
            "Epoch 112, change: 0.00130770\n",
            "Epoch 112, change: 0.00148097\n",
            "Epoch 87, change: 0.00385248\n",
            "Epoch 111, change: 0.00107611\n",
            "Epoch 87, change: 0.00328658\n",
            "Epoch 88, change: 0.00364795\n",
            "Epoch 112, change: 0.00211966\n",
            "Epoch 88, change: 0.00320938\n",
            "Epoch 112, change: 0.00183054\n",
            "Epoch 87, change: 0.00387520\n",
            "Epoch 112, change: 0.00113595\n",
            "Epoch 113, change: 0.00128391\n",
            "Epoch 88, change: 0.00356975\n",
            "Epoch 113, change: 0.00145358\n",
            "Epoch 88, change: 0.00378753\n",
            "Epoch 112, change: 0.00105539\n",
            "Epoch 88, change: 0.00321244\n",
            "Epoch 89, change: 0.00359504\n",
            "Epoch 113, change: 0.00208244\n",
            "Epoch 113, change: 0.00180138\n",
            "Epoch 89, change: 0.00315870\n",
            "Epoch 88, change: 0.00384469\n",
            "Epoch 113, change: 0.00111884\n",
            "Epoch 114, change: 0.00126327\n",
            "Epoch 89, change: 0.00352173\n",
            "Epoch 114, change: 0.00142780\n",
            "Epoch 89, change: 0.00372213\n",
            "Epoch 90, change: 0.00355886\n",
            "Epoch 113, change: 0.00103952\n",
            "Epoch 89, change: 0.00315564\n",
            "Epoch 114, change: 0.00177327\n",
            "Epoch 114, change: 0.00204710\n",
            "Epoch 90, change: 0.00310816\n",
            "Epoch 114, change: 0.00110335\n",
            "Epoch 89, change: 0.00380161\n",
            "Epoch 115, change: 0.00124161\n",
            "Epoch 115, change: 0.00140286\n",
            "Epoch 90, change: 0.00349464\n",
            "Epoch 90, change: 0.00360599\n",
            "Epoch 114, change: 0.00102405\n",
            "Epoch 91, change: 0.00347931\n",
            "Epoch 90, change: 0.00310371\n",
            "Epoch 115, change: 0.00174585\n",
            "Epoch 115, change: 0.00199989\n",
            "Epoch 91, change: 0.00304765\n",
            "Epoch 115, change: 0.00108804\n",
            "Epoch 90, change: 0.00373369\n",
            "Epoch 116, change: 0.00122101\n",
            "Epoch 116, change: 0.00137629\n",
            "Epoch 91, change: 0.00345115\n",
            "Epoch 91, change: 0.00357857\n",
            "Epoch 115, change: 0.00100774\n",
            "Epoch 92, change: 0.00345051\n",
            "Epoch 91, change: 0.00301144\n",
            "Epoch 116, change: 0.00196633\n",
            "Epoch 116, change: 0.00171872\n",
            "Epoch 92, change: 0.00301981\n",
            "Epoch 116, change: 0.00107299\n",
            "Epoch 117, change: 0.00120084\n",
            "Epoch 117, change: 0.00135265\n",
            "Epoch 91, change: 0.00370080\n",
            "Epoch 92, change: 0.00337274\n",
            "Epoch 116, change: 0.00099275\n",
            "Epoch 92, change: 0.00350784\n",
            "Epoch 93, change: 0.00335903\n",
            "Epoch 117, change: 0.00169286\n",
            "Epoch 117, change: 0.00193386\n",
            "Epoch 92, change: 0.00296364\n",
            "Epoch 93, change: 0.00296202\n",
            "Epoch 117, change: 0.00105814\n",
            "Epoch 118, change: 0.00118010\n",
            "Epoch 118, change: 0.00132791\n",
            "Epoch 92, change: 0.00365251\n",
            "Epoch 117, change: 0.00097803\n",
            "Epoch 93, change: 0.00334405\n",
            "Epoch 93, change: 0.00346814\n",
            "Epoch 118, change: 0.00166681\n",
            "Epoch 94, change: 0.00332799\n",
            "Epoch 118, change: 0.00190008\n",
            "Epoch 93, change: 0.00292676\n",
            "Epoch 94, change: 0.00290768\n",
            "Epoch 118, change: 0.00104356\n",
            "Epoch 119, change: 0.00115388\n",
            "Epoch 119, change: 0.00130474\n",
            "Epoch 93, change: 0.00362005\n",
            "Epoch 118, change: 0.00096352\n",
            "Epoch 94, change: 0.00337548\n",
            "Epoch 94, change: 0.00332858\n",
            "Epoch 119, change: 0.00164088\n",
            "Epoch 95, change: 0.00327002\n",
            "Epoch 119, change: 0.00186451\n",
            "Epoch 94, change: 0.00284032\n",
            "Epoch 95, change: 0.00286678\n",
            "Epoch 119, change: 0.00102910\n",
            "Epoch 120, change: 0.00113251\n",
            "Epoch 120, change: 0.00127987\n",
            "Epoch 94, change: 0.00358582\n",
            "Epoch 119, change: 0.00094924\n",
            "Epoch 95, change: 0.00329741\n",
            "Epoch 95, change: 0.00326770\n",
            "Epoch 120, change: 0.00161537\n",
            "Epoch 95, change: 0.00279866\n",
            "Epoch 120, change: 0.00183021\n",
            "Epoch 96, change: 0.00324569\n",
            "Epoch 96, change: 0.00280992\n",
            "Epoch 120, change: 0.00101488\n",
            "Epoch 121, change: 0.00111616\n",
            "Epoch 121, change: 0.00125733\n",
            "Epoch 120, change: 0.00093517\n",
            "Epoch 95, change: 0.00353908\n",
            "Epoch 96, change: 0.00325250\n",
            "Epoch 96, change: 0.00324305\n",
            "Epoch 121, change: 0.00159078\n",
            "Epoch 121, change: 0.00180106\n",
            "Epoch 96, change: 0.00274790\n",
            "Epoch 97, change: 0.00320748\n",
            "Epoch 121, change: 0.00100091\n",
            "Epoch 97, change: 0.00278500\n",
            "Epoch 122, change: 0.00109748\n",
            "Epoch 122, change: 0.00123509\n",
            "Epoch 121, change: 0.00092136\n",
            "Epoch 96, change: 0.00349823\n",
            "Epoch 97, change: 0.00316891\n",
            "Epoch 97, change: 0.00318134\n",
            "Epoch 122, change: 0.00156552\n",
            "Epoch 97, change: 0.00268490\n",
            "Epoch 122, change: 0.00176766\n",
            "Epoch 98, change: 0.00312107\n",
            "Epoch 122, change: 0.00098715\n",
            "Epoch 123, change: 0.00121302\n",
            "Epoch 123, change: 0.00107979\n",
            "Epoch 98, change: 0.00273093\n",
            "Epoch 122, change: 0.00090776\n",
            "Epoch 97, change: 0.00345984\n",
            "Epoch 98, change: 0.00315647\n",
            "Epoch 123, change: 0.00154205\n",
            "Epoch 98, change: 0.00314751\n",
            "Epoch 123, change: 0.00173597\n",
            "Epoch 98, change: 0.00263648\n",
            "Epoch 99, change: 0.00308855\n",
            "Epoch 123, change: 0.00097348\n",
            "Epoch 124, change: 0.00105750\n",
            "Epoch 124, change: 0.00119045\n",
            "Epoch 99, change: 0.00268465\n",
            "Epoch 123, change: 0.00089433\n",
            "Epoch 98, change: 0.00341954\n",
            "Epoch 124, change: 0.00151825\n",
            "Epoch 99, change: 0.00310015\n",
            "Epoch 99, change: 0.00308118\n",
            "Epoch 124, change: 0.00170895\n",
            "Epoch 99, change: 0.00258410\n",
            "Epoch 124, change: 0.00096008\n",
            "Epoch 100, change: 0.00304478\n",
            "Epoch 125, change: 0.00117083\n",
            "Epoch 125, change: 0.00103669\n",
            "Epoch 100, change: 0.00263240\n",
            "Epoch 124, change: 0.00088117\n",
            "Epoch 99, change: 0.00338001\n",
            "Epoch 125, change: 0.00149515\n",
            "Epoch 100, change: 0.00302496\n",
            "Epoch 100, change: 0.00307241\n",
            "Epoch 125, change: 0.00168306\n",
            "Epoch 100, change: 0.00253300\n",
            "Epoch 125, change: 0.00094682\n",
            "Epoch 101, change: 0.00300787\n",
            "Epoch 126, change: 0.00114883\n",
            "Epoch 126, change: 0.00102179\n",
            "Epoch 101, change: 0.00261117\n",
            "Epoch 125, change: 0.00086817\n",
            "Epoch 126, change: 0.00147226\n",
            "Epoch 100, change: 0.00334699\n",
            "Epoch 101, change: 0.00298942\n",
            "Epoch 101, change: 0.00303657\n",
            "Epoch 126, change: 0.00164742\n",
            "Epoch 126, change: 0.00093377\n",
            "Epoch 101, change: 0.00248631\n",
            "Epoch 127, change: 0.00112907\n",
            "Epoch 127, change: 0.00100708\n",
            "Epoch 102, change: 0.00298135\n",
            "Epoch 126, change: 0.00085537\n",
            "Epoch 102, change: 0.00257075\n",
            "Epoch 127, change: 0.00145021\n",
            "Epoch 102, change: 0.00294075\n",
            "Epoch 101, change: 0.00331538\n",
            "Epoch 127, change: 0.00161137\n",
            "Epoch 102, change: 0.00299602\n",
            "Epoch 102, change: 0.00243657\n",
            "Epoch 127, change: 0.00092097\n",
            "Epoch 128, change: 0.00099236\n",
            "Epoch 128, change: 0.00110849\n",
            "Epoch 103, change: 0.00291187\n",
            "Epoch 127, change: 0.00084282\n",
            "Epoch 103, change: 0.00252719\n",
            "Epoch 103, change: 0.00287809\n",
            "Epoch 128, change: 0.00142750\n",
            "Epoch 102, change: 0.00326592\n",
            "Epoch 128, change: 0.00158284\n",
            "Epoch 103, change: 0.00295772\n",
            "Epoch 128, change: 0.00090827\n",
            "Epoch 103, change: 0.00239389\n",
            "Epoch 129, change: 0.00097595\n",
            "Epoch 104, change: 0.00287471\n",
            "Epoch 129, change: 0.00108836\n",
            "Epoch 128, change: 0.00083042\n",
            "Epoch 104, change: 0.00248874\n",
            "Epoch 104, change: 0.00282415\n",
            "Epoch 129, change: 0.00140697\n",
            "Epoch 129, change: 0.00155127\n",
            "Epoch 103, change: 0.00324895\n",
            "Epoch 104, change: 0.00291933\n",
            "Epoch 129, change: 0.00089577\n",
            "Epoch 104, change: 0.00232023\n",
            "Epoch 130, change: 0.00096198\n",
            "Epoch 130, change: 0.00107016\n",
            "Epoch 105, change: 0.00283708\n",
            "Epoch 129, change: 0.00081823\n",
            "Epoch 105, change: 0.00245146\n",
            "Epoch 130, change: 0.00138598\n",
            "Epoch 105, change: 0.00278061\n",
            "Epoch 130, change: 0.00152145\n",
            "Epoch 104, change: 0.00319780\n",
            "Epoch 105, change: 0.00288613\n",
            "Epoch 130, change: 0.00088349\n",
            "Epoch 105, change: 0.00228938\n",
            "Epoch 131, change: 0.00094820\n",
            "Epoch 131, change: 0.00105025\n",
            "Epoch 106, change: 0.00279226\n",
            "Epoch 130, change: 0.00080624\n",
            "Epoch 106, change: 0.00241612\n",
            "Epoch 131, change: 0.00136364\n",
            "Epoch 106, change: 0.00274824\n",
            "Epoch 131, change: 0.00149209\n",
            "Epoch 105, change: 0.00317302\n",
            "Epoch 106, change: 0.00285011\n",
            "Epoch 131, change: 0.00087138\n",
            "Epoch 132, change: 0.00093438\n",
            "Epoch 106, change: 0.00224879\n",
            "Epoch 132, change: 0.00103162\n",
            "Epoch 107, change: 0.00275990\n",
            "Epoch 131, change: 0.00079437\n",
            "Epoch 107, change: 0.00237586\n",
            "Epoch 132, change: 0.00134378\n",
            "Epoch 107, change: 0.00269695\n",
            "Epoch 132, change: 0.00146542\n",
            "Epoch 132, change: 0.00085938\n",
            "Epoch 106, change: 0.00314030\n",
            "Epoch 107, change: 0.00282477\n",
            "Epoch 107, change: 0.00221284\n",
            "Epoch 133, change: 0.00092060\n",
            "Epoch 133, change: 0.00101329\n",
            "Epoch 108, change: 0.00269910\n",
            "Epoch 132, change: 0.00078270\n",
            "Epoch 108, change: 0.00234027\n",
            "Epoch 133, change: 0.00132241\n",
            "Epoch 133, change: 0.00143840\n",
            "Epoch 108, change: 0.00265588\n",
            "Epoch 133, change: 0.00084757\n",
            "Epoch 107, change: 0.00311351\n",
            "Epoch 108, change: 0.00277243\n",
            "Epoch 134, change: 0.00090707\n",
            "Epoch 108, change: 0.00215749\n",
            "Epoch 134, change: 0.00099573\n",
            "Epoch 133, change: 0.00077121\n",
            "Epoch 109, change: 0.00267814\n",
            "Epoch 134, change: 0.00130254\n",
            "Epoch 109, change: 0.00230852\n",
            "Epoch 134, change: 0.00141601\n",
            "Epoch 109, change: 0.00261943\n",
            "Epoch 134, change: 0.00083595\n",
            "Epoch 108, change: 0.00306940\n",
            "Epoch 135, change: 0.00089344\n",
            "Epoch 109, change: 0.00213368\n",
            "Epoch 109, change: 0.00274528\n",
            "Epoch 135, change: 0.00097829\n",
            "Epoch 134, change: 0.00075990\n",
            "Epoch 110, change: 0.00263453\n",
            "Epoch 110, change: 0.00227670\n",
            "Epoch 135, change: 0.00128297\n",
            "Epoch 135, change: 0.00138974\n",
            "Epoch 110, change: 0.00257879\n",
            "Epoch 135, change: 0.00082455\n",
            "Epoch 109, change: 0.00303848\n",
            "Epoch 136, change: 0.00088087\n",
            "Epoch 110, change: 0.00271146\n",
            "Epoch 136, change: 0.00096136\n",
            "Epoch 110, change: 0.00208679\n",
            "Epoch 135, change: 0.00074879\n",
            "Epoch 111, change: 0.00260443\n",
            "Epoch 136, change: 0.00126333\n",
            "Epoch 111, change: 0.00223854\n",
            "Epoch 136, change: 0.00135550\n",
            "Epoch 111, change: 0.00251429\n",
            "Epoch 136, change: 0.00081329\n",
            "Epoch 110, change: 0.00301516\n",
            "Epoch 137, change: 0.00086840\n",
            "Epoch 137, change: 0.00094418\n",
            "Epoch 111, change: 0.00205212\n",
            "Epoch 111, change: 0.00268493\n",
            "Epoch 136, change: 0.00073783\n",
            "Epoch 112, change: 0.00257696\n",
            "Epoch 137, change: 0.00124504\n",
            "Epoch 112, change: 0.00219990\n",
            "Epoch 137, change: 0.00133373\n",
            "Epoch 137, change: 0.00080207\n",
            "Epoch 112, change: 0.00248873\n",
            "Epoch 138, change: 0.00092788\n",
            "Epoch 138, change: 0.00085417\n",
            "Epoch 111, change: 0.00298518\n",
            "Epoch 112, change: 0.00201562\n",
            "Epoch 112, change: 0.00264654\n",
            "Epoch 137, change: 0.00072705\n",
            "Epoch 113, change: 0.00252682\n",
            "Epoch 138, change: 0.00122711\n",
            "Epoch 138, change: 0.00130694\n",
            "Epoch 113, change: 0.00217901\n",
            "Epoch 138, change: 0.00079109\n",
            "Epoch 113, change: 0.00243460\n",
            "Epoch 139, change: 0.00091254\n",
            "Epoch 139, change: 0.00084189\n",
            "Epoch 112, change: 0.00293661\n",
            "Epoch 113, change: 0.00196721\n",
            "Epoch 138, change: 0.00071645\n",
            "Epoch 113, change: 0.00261927\n",
            "Epoch 114, change: 0.00249694\n",
            "Epoch 139, change: 0.00120837\n",
            "Epoch 139, change: 0.00128256\n",
            "Epoch 139, change: 0.00078029\n",
            "Epoch 114, change: 0.00213436\n",
            "Epoch 114, change: 0.00240378\n",
            "Epoch 140, change: 0.00089539\n",
            "Epoch 140, change: 0.00083044\n",
            "Epoch 113, change: 0.00292097\n",
            "Epoch 114, change: 0.00193108\n",
            "Epoch 139, change: 0.00070596\n",
            "Epoch 114, change: 0.00257180\n",
            "Epoch 115, change: 0.00245560\n",
            "Epoch 140, change: 0.00119011\n",
            "Epoch 140, change: 0.00125903\n",
            "Epoch 140, change: 0.00076957\n",
            "Epoch 115, change: 0.00211464\n",
            "Epoch 141, change: 0.00087873\n",
            "Epoch 115, change: 0.00237213\n",
            "Epoch 141, change: 0.00081815\n",
            "Epoch 114, change: 0.00288214\n",
            "Epoch 115, change: 0.00191250\n",
            "Epoch 140, change: 0.00069560\n",
            "Epoch 115, change: 0.00255431\n",
            "Epoch 141, change: 0.00117188\n",
            "Epoch 116, change: 0.00242828\n",
            "Epoch 141, change: 0.00123515\n",
            "Epoch 141, change: 0.00075903\n",
            "Epoch 142, change: 0.00086352\n",
            "Epoch 116, change: 0.00232231\n",
            "Epoch 116, change: 0.00207368\n",
            "Epoch 142, change: 0.00080540\n",
            "Epoch 115, change: 0.00285299\n",
            "Epoch 141, change: 0.00068546\n",
            "Epoch 116, change: 0.00187852\n",
            "Epoch 116, change: 0.00252918\n",
            "Epoch 142, change: 0.00115437\n",
            "Epoch 142, change: 0.00121354\n",
            "Epoch 117, change: 0.00240088\n",
            "Epoch 142, change: 0.00074865\n",
            "Epoch 143, change: 0.00084861\n",
            "Epoch 117, change: 0.00204701\n",
            "Epoch 143, change: 0.00079384\n",
            "Epoch 117, change: 0.00228380\n",
            "Epoch 142, change: 0.00067549\n",
            "Epoch 117, change: 0.00183815\n",
            "Epoch 116, change: 0.00282676\n",
            "Epoch 117, change: 0.00247777\n",
            "Epoch 143, change: 0.00113734\n",
            "Epoch 143, change: 0.00119075\n",
            "Epoch 118, change: 0.00236467\n",
            "Epoch 143, change: 0.00073842\n",
            "Epoch 144, change: 0.00083419\n",
            "Epoch 144, change: 0.00078225\n",
            "Epoch 118, change: 0.00201167\n",
            "Epoch 118, change: 0.00226179\n",
            "Epoch 143, change: 0.00066563\n",
            "Epoch 118, change: 0.00181676\n",
            "Epoch 118, change: 0.00246739\n",
            "Epoch 117, change: 0.00279845\n",
            "Epoch 144, change: 0.00112032\n",
            "Epoch 144, change: 0.00116730\n",
            "Epoch 144, change: 0.00072834\n",
            "Epoch 119, change: 0.00233999\n",
            "Epoch 145, change: 0.00082025\n",
            "Epoch 145, change: 0.00077033\n",
            "Epoch 119, change: 0.00198312\n",
            "Epoch 119, change: 0.00221622\n",
            "Epoch 144, change: 0.00065592\n",
            "Epoch 119, change: 0.00178446\n",
            "Epoch 119, change: 0.00242147\n",
            "Epoch 118, change: 0.00277528\n",
            "Epoch 145, change: 0.00110240\n",
            "Epoch 145, change: 0.00114643\n",
            "Epoch 146, change: 0.00080612\n",
            "Epoch 145, change: 0.00071840\n",
            "Epoch 120, change: 0.00230414\n",
            "Epoch 146, change: 0.00075978\n",
            "Epoch 120, change: 0.00195141\n",
            "Epoch 145, change: 0.00064639\n",
            "Epoch 120, change: 0.00218830\n",
            "Epoch 120, change: 0.00176457\n",
            "Epoch 120, change: 0.00239673\n",
            "Epoch 119, change: 0.00274828\n",
            "Epoch 146, change: 0.00108616\n",
            "Epoch 146, change: 0.00112474\n",
            "Epoch 147, change: 0.00079125\n",
            "Epoch 146, change: 0.00070857\n",
            "Epoch 147, change: 0.00074746\n",
            "Epoch 121, change: 0.00226101\n",
            "Epoch 121, change: 0.00193551\n",
            "Epoch 146, change: 0.00063692\n",
            "Epoch 121, change: 0.00214845\n",
            "Epoch 121, change: 0.00173769\n",
            "Epoch 121, change: 0.00237431\n",
            "Epoch 147, change: 0.00107039\n",
            "Epoch 120, change: 0.00272104\n",
            "Epoch 147, change: 0.00110450\n",
            "Epoch 148, change: 0.00077667\n",
            "Epoch 147, change: 0.00069891\n",
            "Epoch 148, change: 0.00073666\n",
            "Epoch 122, change: 0.00223835\n",
            "Epoch 122, change: 0.00190343\n",
            "Epoch 147, change: 0.00062765\n",
            "Epoch 122, change: 0.00211295\n",
            "Epoch 148, change: 0.00105418\n",
            "Epoch 122, change: 0.00171887\n",
            "Epoch 122, change: 0.00234633\n",
            "Epoch 121, change: 0.00268811\n",
            "Epoch 148, change: 0.00108453\n",
            "Epoch 149, change: 0.00076425\n",
            "Epoch 148, change: 0.00068940\n",
            "Epoch 149, change: 0.00072579\n",
            "Epoch 123, change: 0.00220597\n",
            "Epoch 148, change: 0.00061851\n",
            "Epoch 123, change: 0.00187576\n",
            "Epoch 123, change: 0.00208332\n",
            "Epoch 149, change: 0.00103900\n",
            "Epoch 123, change: 0.00170279\n",
            "Epoch 123, change: 0.00231904\n",
            "Epoch 149, change: 0.00106402\n",
            "Epoch 122, change: 0.00266202\n",
            "Epoch 150, change: 0.00071468\n",
            "Epoch 149, change: 0.00067995\n",
            "Epoch 150, change: 0.00074978\n",
            "Epoch 124, change: 0.00217945\n",
            "Epoch 149, change: 0.00060954\n",
            "Epoch 124, change: 0.00184862\n",
            "Epoch 124, change: 0.00205687\n",
            "Epoch 150, change: 0.00102306\n",
            "Epoch 124, change: 0.00167240\n",
            "Epoch 124, change: 0.00228602\n",
            "Epoch 150, change: 0.00104611\n",
            "Epoch 123, change: 0.00263416\n",
            "Epoch 150, change: 0.00067069\n",
            "Epoch 151, change: 0.00070363\n",
            "Epoch 151, change: 0.00073757\n",
            "Epoch 125, change: 0.00215665\n",
            "Epoch 150, change: 0.00060065\n",
            "Epoch 125, change: 0.00182868\n",
            "Epoch 125, change: 0.00202524\n",
            "Epoch 151, change: 0.00100729\n",
            "Epoch 125, change: 0.00165206\n",
            "Epoch 125, change: 0.00225354\n",
            "Epoch 151, change: 0.00102977\n",
            "Epoch 152, change: 0.00069433\n",
            "Epoch 151, change: 0.00066158\n",
            "Epoch 124, change: 0.00261030\n",
            "Epoch 152, change: 0.00072413\n",
            "Epoch 126, change: 0.00213183\n",
            "Epoch 151, change: 0.00059192\n",
            "Epoch 126, change: 0.00179491\n",
            "Epoch 152, change: 0.00099211\n",
            "Epoch 126, change: 0.00198062\n",
            "Epoch 126, change: 0.00163240\n",
            "Epoch 152, change: 0.00101125\n",
            "Epoch 126, change: 0.00224102\n",
            "Epoch 153, change: 0.00068436\n",
            "Epoch 153, change: 0.00071155\n",
            "Epoch 152, change: 0.00065254\n",
            "Epoch 125, change: 0.00258480\n",
            "Epoch 152, change: 0.00058331\n",
            "Epoch 127, change: 0.00209311\n",
            "Epoch 127, change: 0.00176882\n",
            "Epoch 127, change: 0.00196443\n",
            "Epoch 153, change: 0.00097769\n",
            "Epoch 127, change: 0.00160976\n",
            "Epoch 153, change: 0.00098963\n",
            "Epoch 127, change: 0.00219860\n",
            "Epoch 154, change: 0.00067419\n",
            "Epoch 153, change: 0.00064363\n",
            "Epoch 154, change: 0.00069880\n",
            "Epoch 126, change: 0.00256451\n",
            "Epoch 153, change: 0.00057483\n",
            "Epoch 128, change: 0.00206493\n",
            "Epoch 128, change: 0.00174466\n",
            "Epoch 128, change: 0.00193348\n",
            "Epoch 154, change: 0.00096362\n",
            "Epoch 128, change: 0.00159406\n",
            "Epoch 154, change: 0.00097148\n",
            "Epoch 155, change: 0.00066281\n",
            "Epoch 128, change: 0.00217359\n",
            "Epoch 154, change: 0.00063484\n",
            "Epoch 155, change: 0.00068688\n",
            "Epoch 154, change: 0.00056648\n",
            "Epoch 127, change: 0.00253216\n",
            "Epoch 129, change: 0.00203661\n",
            "Epoch 129, change: 0.00172246\n",
            "Epoch 129, change: 0.00190297\n",
            "Epoch 155, change: 0.00094842\n",
            "Epoch 155, change: 0.00095424\n",
            "Epoch 129, change: 0.00156756\n",
            "Epoch 156, change: 0.00065362\n",
            "Epoch 155, change: 0.00062622\n",
            "Epoch 156, change: 0.00067504\n",
            "Epoch 129, change: 0.00213554\n",
            "Epoch 155, change: 0.00055826\n",
            "Epoch 128, change: 0.00251338\n",
            "Epoch 130, change: 0.00202259\n",
            "Epoch 130, change: 0.00169444\n",
            "Epoch 130, change: 0.00187582\n",
            "Epoch 156, change: 0.00093454\n",
            "Epoch 156, change: 0.00093474\n",
            "Epoch 157, change: 0.00064429\n",
            "Epoch 130, change: 0.00155548\n",
            "Epoch 156, change: 0.00061773\n",
            "Epoch 157, change: 0.00066403\n",
            "Epoch 130, change: 0.00211701\n",
            "Epoch 156, change: 0.00055016\n",
            "Epoch 129, change: 0.00249462\n",
            "Epoch 131, change: 0.00199811\n",
            "Epoch 131, change: 0.00166809\n",
            "Epoch 131, change: 0.00183839\n",
            "Epoch 157, change: 0.00092060\n",
            "Epoch 157, change: 0.00060934\n",
            "Epoch 158, change: 0.00063450\n",
            "Epoch 157, change: 0.00091964\n",
            "Epoch 158, change: 0.00065275\n",
            "Epoch 131, change: 0.00153418\n",
            "Epoch 131, change: 0.00208049\n",
            "Epoch 157, change: 0.00054220\n",
            "Epoch 130, change: 0.00246211\n",
            "Epoch 132, change: 0.00198080\n",
            "Epoch 132, change: 0.00165204\n",
            "Epoch 158, change: 0.00090656\n",
            "Epoch 132, change: 0.00181812\n",
            "Epoch 159, change: 0.00062528\n",
            "Epoch 158, change: 0.00060096\n",
            "Epoch 158, change: 0.00090298\n",
            "Epoch 159, change: 0.00064036\n",
            "Epoch 132, change: 0.00151132\n",
            "Epoch 158, change: 0.00053434\n",
            "Epoch 132, change: 0.00206747\n",
            "Epoch 131, change: 0.00243696\n",
            "Epoch 133, change: 0.00196453\n",
            "Epoch 133, change: 0.00162841\n",
            "Epoch 159, change: 0.00089329\n",
            "Epoch 133, change: 0.00179461\n",
            "Epoch 159, change: 0.00059278\n",
            "Epoch 159, change: 0.00088653\n",
            "Epoch 160, change: 0.00061555\n",
            "Epoch 160, change: 0.00062919\n",
            "Epoch 159, change: 0.00052659\n",
            "Epoch 133, change: 0.00204156\n",
            "Epoch 133, change: 0.00149715\n",
            "Epoch 132, change: 0.00242142\n",
            "Epoch 134, change: 0.00194814\n",
            "Epoch 160, change: 0.00088010\n",
            "Epoch 134, change: 0.00176730\n",
            "Epoch 134, change: 0.00160498\n",
            "Epoch 161, change: 0.00060698\n",
            "Epoch 160, change: 0.00058472\n",
            "Epoch 160, change: 0.00086989\n",
            "Epoch 161, change: 0.00061822\n",
            "Epoch 160, change: 0.00051894\n",
            "Epoch 134, change: 0.00200969\n",
            "Epoch 134, change: 0.00147678\n",
            "Epoch 133, change: 0.00238570\n",
            "Epoch 135, change: 0.00192459\n",
            "Epoch 161, change: 0.00086693\n",
            "Epoch 162, change: 0.00059762\n",
            "Epoch 161, change: 0.00057677\n",
            "Epoch 161, change: 0.00085483\n",
            "Epoch 135, change: 0.00174272\n",
            "Epoch 135, change: 0.00157820\n",
            "Epoch 162, change: 0.00060771\n",
            "Epoch 161, change: 0.00051140\n",
            "Epoch 135, change: 0.00146165\n",
            "Epoch 135, change: 0.00197325\n",
            "Epoch 134, change: 0.00236795\n",
            "Epoch 162, change: 0.00085455\n",
            "Epoch 136, change: 0.00191010\n",
            "Epoch 162, change: 0.00056893\n",
            "Epoch 136, change: 0.00171944\n",
            "Epoch 162, change: 0.00084065\n",
            "Epoch 163, change: 0.00059736\n",
            "Epoch 136, change: 0.00156396\n",
            "Epoch 163, change: 0.00058872\n",
            "Epoch 162, change: 0.00050399\n",
            "Epoch 136, change: 0.00195635\n",
            "Epoch 136, change: 0.00144418\n",
            "Epoch 135, change: 0.00234201\n",
            "Epoch 163, change: 0.00084193\n",
            "Epoch 137, change: 0.00189445\n",
            "Epoch 163, change: 0.00056121\n",
            "Epoch 163, change: 0.00082358\n",
            "Epoch 164, change: 0.00058685\n",
            "Epoch 137, change: 0.00153825\n",
            "Epoch 164, change: 0.00058033\n",
            "Epoch 137, change: 0.00168898\n",
            "Epoch 163, change: 0.00049668\n",
            "Epoch 137, change: 0.00193585\n",
            "Epoch 137, change: 0.00142836\n",
            "Epoch 164, change: 0.00082979\n",
            "Epoch 138, change: 0.00187876\n",
            "Epoch 136, change: 0.00232086\n",
            "Epoch 165, change: 0.00057695\n",
            "Epoch 164, change: 0.00055354\n",
            "Epoch 164, change: 0.00080847\n",
            "Epoch 165, change: 0.00057276\n",
            "Epoch 138, change: 0.00152305\n",
            "Epoch 138, change: 0.00166579\n",
            "Epoch 164, change: 0.00048949\n",
            "Epoch 138, change: 0.00190039\n",
            "Epoch 138, change: 0.00140759\n",
            "Epoch 165, change: 0.00081738\n",
            "Epoch 139, change: 0.00185618\n",
            "Epoch 137, change: 0.00230104\n",
            "Epoch 166, change: 0.00056739\n",
            "Epoch 165, change: 0.00054603\n",
            "Epoch 165, change: 0.00079411\n",
            "Epoch 139, change: 0.00150153\n",
            "Epoch 166, change: 0.00056526\n",
            "Epoch 139, change: 0.00163564\n",
            "Epoch 165, change: 0.00048240\n",
            "Epoch 139, change: 0.00138196\n",
            "Epoch 139, change: 0.00188573\n",
            "Epoch 166, change: 0.00080502\n",
            "Epoch 138, change: 0.00227740\n",
            "Epoch 140, change: 0.00184142\n",
            "Epoch 167, change: 0.00055745\n",
            "Epoch 166, change: 0.00053859\n",
            "Epoch 166, change: 0.00078003\n",
            "Epoch 167, change: 0.00055773\n",
            "Epoch 140, change: 0.00147562\n",
            "Epoch 140, change: 0.00162003\n",
            "Epoch 166, change: 0.00047543\n",
            "Epoch 140, change: 0.00137152\n",
            "Epoch 140, change: 0.00185235\n",
            "Epoch 167, change: 0.00079293\n",
            "Epoch 139, change: 0.00225566\n",
            "Epoch 168, change: 0.00054761\n",
            "Epoch 167, change: 0.00053129\n",
            "Epoch 167, change: 0.00076584\n",
            "Epoch 141, change: 0.00182639\n",
            "Epoch 168, change: 0.00055041\n",
            "Epoch 141, change: 0.00145083\n",
            "Epoch 141, change: 0.00159843\n",
            "Epoch 167, change: 0.00046857\n",
            "Epoch 141, change: 0.00135791\n",
            "Epoch 141, change: 0.00183880\n",
            "Epoch 168, change: 0.00078123\n",
            "Epoch 169, change: 0.00053779\n",
            "Epoch 168, change: 0.00052406\n",
            "Epoch 142, change: 0.00180824\n",
            "Epoch 140, change: 0.00224259\n",
            "Epoch 168, change: 0.00075291\n",
            "Epoch 142, change: 0.00142998\n",
            "Epoch 169, change: 0.00054318\n",
            "Epoch 168, change: 0.00046180\n",
            "Epoch 142, change: 0.00156960\n",
            "Epoch 142, change: 0.00134090\n",
            "Epoch 142, change: 0.00180301\n",
            "Epoch 169, change: 0.00076996\n",
            "Epoch 170, change: 0.00052862\n",
            "Epoch 169, change: 0.00051694\n",
            "Epoch 141, change: 0.00221694\n",
            "Epoch 169, change: 0.00073990\n",
            "Epoch 143, change: 0.00179425\n",
            "Epoch 170, change: 0.00053613\n",
            "Epoch 143, change: 0.00141743\n",
            "Epoch 169, change: 0.00045508\n",
            "Epoch 143, change: 0.00155140\n",
            "Epoch 143, change: 0.00178293\n",
            "Epoch 143, change: 0.00132857\n",
            "Epoch 170, change: 0.00075882\n",
            "Epoch 171, change: 0.00052015\n",
            "Epoch 170, change: 0.00050993\n",
            "Epoch 170, change: 0.00072438\n",
            "Epoch 144, change: 0.00177647\n",
            "Epoch 171, change: 0.00052914\n",
            "Epoch 142, change: 0.00219248\n",
            "Epoch 144, change: 0.00138869\n",
            "Epoch 170, change: 0.00044848\n",
            "Epoch 144, change: 0.00152859\n",
            "Epoch 144, change: 0.00176536\n",
            "Epoch 144, change: 0.00130249\n",
            "Epoch 171, change: 0.00074766\n",
            "Epoch 172, change: 0.00051114\n",
            "Epoch 171, change: 0.00050301\n",
            "Epoch 171, change: 0.00071136\n",
            "Epoch 172, change: 0.00052208\n",
            "Epoch 145, change: 0.00176212\n",
            "Epoch 143, change: 0.00217057\n",
            "Epoch 171, change: 0.00044200\n",
            "Epoch 145, change: 0.00137706\n",
            "Epoch 145, change: 0.00151354\n",
            "Epoch 145, change: 0.00174165\n",
            "Epoch 145, change: 0.00129140\n",
            "Epoch 172, change: 0.00073638\n",
            "Epoch 173, change: 0.00050172\n",
            "Epoch 172, change: 0.00049618\n",
            "Epoch 172, change: 0.00069836\n",
            "Epoch 173, change: 0.00051526\n",
            "Epoch 144, change: 0.00215854\n",
            "Epoch 146, change: 0.00174600\n",
            "Epoch 172, change: 0.00043562\n",
            "Epoch 146, change: 0.00135972\n",
            "Epoch 146, change: 0.00149581\n",
            "Epoch 146, change: 0.00171243\n",
            "Epoch 146, change: 0.00127480\n",
            "Epoch 174, change: 0.00049283\n",
            "Epoch 173, change: 0.00072478\n",
            "Epoch 173, change: 0.00048943\n",
            "Epoch 173, change: 0.00068619\n",
            "Epoch 174, change: 0.00050849\n",
            "Epoch 173, change: 0.00042931\n",
            "Epoch 145, change: 0.00212573\n",
            "Epoch 147, change: 0.00173151\n",
            "Epoch 147, change: 0.00133769\n",
            "Epoch 147, change: 0.00148378\n",
            "Epoch 174, change: 0.00071416\n",
            "Epoch 175, change: 0.00048461\n",
            "Epoch 147, change: 0.00169802\n",
            "Epoch 174, change: 0.00048278\n",
            "Epoch 147, change: 0.00126123\n",
            "Epoch 175, change: 0.00050182\n",
            "Epoch 174, change: 0.00067340\n",
            "Epoch 174, change: 0.00042311\n",
            "Epoch 146, change: 0.00211440\n",
            "Epoch 148, change: 0.00171561\n",
            "Epoch 148, change: 0.00132782\n",
            "Epoch 148, change: 0.00146463\n",
            "Epoch 176, change: 0.00047631\n",
            "Epoch 175, change: 0.00070386\n",
            "Epoch 148, change: 0.00167775\n",
            "Epoch 175, change: 0.00047623\n",
            "Epoch 148, change: 0.00124830\n",
            "Epoch 176, change: 0.00049532\n",
            "Epoch 175, change: 0.00066145\n",
            "Epoch 175, change: 0.00041702\n",
            "Epoch 149, change: 0.00170057\n",
            "Epoch 149, change: 0.00144347\n",
            "Epoch 149, change: 0.00130237\n",
            "Epoch 147, change: 0.00208970\n",
            "Epoch 177, change: 0.00046842\n",
            "Epoch 176, change: 0.00069357\n",
            "Epoch 176, change: 0.00046977\n",
            "Epoch 149, change: 0.00165108\n",
            "Epoch 149, change: 0.00123099\n",
            "Epoch 177, change: 0.00048877\n",
            "Epoch 176, change: 0.00064986\n",
            "Epoch 176, change: 0.00041096\n",
            "Epoch 150, change: 0.00129006\n",
            "Epoch 150, change: 0.00143723\n",
            "Epoch 150, change: 0.00168603\n",
            "Epoch 148, change: 0.00206990\n",
            "Epoch 178, change: 0.00046026\n",
            "Epoch 177, change: 0.00068379\n",
            "Epoch 177, change: 0.00046342\n",
            "Epoch 150, change: 0.00163221\n",
            "Epoch 178, change: 0.00048237\n",
            "Epoch 150, change: 0.00121775\n",
            "Epoch 177, change: 0.00063746\n",
            "Epoch 177, change: 0.00040501\n",
            "Epoch 151, change: 0.00141696\n",
            "Epoch 149, change: 0.00205305\n",
            "Epoch 151, change: 0.00167187\n",
            "Epoch 151, change: 0.00126839\n",
            "Epoch 179, change: 0.00045292\n",
            "Epoch 178, change: 0.00067400\n",
            "Epoch 178, change: 0.00045711\n",
            "Epoch 179, change: 0.00047608\n",
            "Epoch 151, change: 0.00161186\n",
            "Epoch 178, change: 0.00062738\n",
            "Epoch 151, change: 0.00120718\n",
            "Epoch 178, change: 0.00039918\n",
            "Epoch 152, change: 0.00139603\n",
            "Epoch 152, change: 0.00165640\n",
            "Epoch 152, change: 0.00125070\n",
            "Epoch 150, change: 0.00203636\n",
            "Epoch 180, change: 0.00044466\n",
            "Epoch 179, change: 0.00066346\n",
            "Epoch 180, change: 0.00046984\n",
            "Epoch 179, change: 0.00045093\n",
            "Epoch 152, change: 0.00160364\n",
            "Epoch 179, change: 0.00061695\n",
            "Epoch 152, change: 0.00119487\n",
            "Epoch 179, change: 0.00039340\n",
            "Epoch 153, change: 0.00138739\n",
            "Epoch 153, change: 0.00164213\n",
            "Epoch 151, change: 0.00201761\n",
            "Epoch 181, change: 0.00043725\n",
            "Epoch 153, change: 0.00123571\n",
            "Epoch 181, change: 0.00046371\n",
            "Epoch 180, change: 0.00065354\n",
            "Epoch 180, change: 0.00044482\n",
            "Epoch 153, change: 0.00157084\n",
            "Epoch 180, change: 0.00060616\n",
            "Epoch 153, change: 0.00117581\n",
            "Epoch 180, change: 0.00038772\n",
            "Epoch 154, change: 0.00162830\n",
            "Epoch 154, change: 0.00136717\n",
            "Epoch 152, change: 0.00200216\n",
            "Epoch 154, change: 0.00122307\n",
            "Epoch 182, change: 0.00043019\n",
            "Epoch 182, change: 0.00045772\n",
            "Epoch 181, change: 0.00064405\n",
            "Epoch 181, change: 0.00043878\n",
            "Epoch 181, change: 0.00059298\n",
            "Epoch 154, change: 0.00155233\n",
            "Epoch 154, change: 0.00116059\n",
            "Epoch 181, change: 0.00038213\n",
            "Epoch 155, change: 0.00161483\n",
            "Epoch 155, change: 0.00135813\n",
            "Epoch 153, change: 0.00198004\n",
            "Epoch 183, change: 0.00042311\n",
            "Epoch 155, change: 0.00121131\n",
            "Epoch 183, change: 0.00045172\n",
            "Epoch 182, change: 0.00043285\n",
            "Epoch 182, change: 0.00063497\n",
            "Epoch 182, change: 0.00058277\n",
            "Epoch 155, change: 0.00153223\n",
            "Epoch 155, change: 0.00115230\n",
            "Epoch 182, change: 0.00037661\n",
            "Epoch 156, change: 0.00160159\n",
            "Epoch 156, change: 0.00134402\n",
            "Epoch 184, change: 0.00041544\n",
            "Epoch 184, change: 0.00044580\n",
            "Epoch 154, change: 0.00195748\n",
            "Epoch 156, change: 0.00119736\n",
            "Epoch 183, change: 0.00042696\n",
            "Epoch 183, change: 0.00062573\n",
            "Epoch 183, change: 0.00057401\n",
            "Epoch 156, change: 0.00152475\n",
            "Epoch 156, change: 0.00113351\n",
            "Epoch 183, change: 0.00037116\n",
            "Epoch 185, change: 0.00040772\n",
            "Epoch 157, change: 0.00132104\n",
            "Epoch 157, change: 0.00158649\n",
            "Epoch 185, change: 0.00044002\n",
            "Epoch 155, change: 0.00194203\n",
            "Epoch 157, change: 0.00117452\n",
            "Epoch 184, change: 0.00042117\n",
            "Epoch 184, change: 0.00061637\n",
            "Epoch 184, change: 0.00056396\n",
            "Epoch 157, change: 0.00149634\n",
            "Epoch 157, change: 0.00112242\n",
            "Epoch 184, change: 0.00036581\n",
            "Epoch 186, change: 0.00040075\n",
            "Epoch 158, change: 0.00131358\n",
            "Epoch 158, change: 0.00157456\n",
            "Epoch 186, change: 0.00043430\n",
            "Epoch 158, change: 0.00115729\n",
            "Epoch 156, change: 0.00191903\n",
            "Epoch 185, change: 0.00041547\n",
            "Epoch 185, change: 0.00060700\n",
            "Epoch 185, change: 0.00055451\n",
            "Epoch 158, change: 0.00147466\n",
            "Epoch 158, change: 0.00110891\n",
            "Epoch 185, change: 0.00036052\n",
            "Epoch 187, change: 0.00039406\n",
            "Epoch 159, change: 0.00129746\n",
            "Epoch 159, change: 0.00155939\n",
            "Epoch 187, change: 0.00042859\n",
            "Epoch 186, change: 0.00040984\n",
            "Epoch 159, change: 0.00115086\n",
            "Epoch 157, change: 0.00190509\n",
            "Epoch 186, change: 0.00059778\n",
            "Epoch 186, change: 0.00054459\n",
            "Epoch 159, change: 0.00146446\n",
            "Epoch 159, change: 0.00109936\n",
            "Epoch 186, change: 0.00035532\n",
            "Epoch 188, change: 0.00038707\n",
            "Epoch 160, change: 0.00154756\n",
            "Epoch 160, change: 0.00127558\n",
            "Epoch 187, change: 0.00040428\n",
            "Epoch 188, change: 0.00042298\n",
            "Epoch 160, change: 0.00113183\n",
            "Epoch 187, change: 0.00058924\n",
            "Epoch 158, change: 0.00188594\n",
            "Epoch 187, change: 0.00053427\n",
            "Epoch 160, change: 0.00143840\n",
            "Epoch 160, change: 0.00108528\n",
            "Epoch 189, change: 0.00038040\n",
            "Epoch 187, change: 0.00035019\n",
            "Epoch 161, change: 0.00153282\n",
            "Epoch 188, change: 0.00039881\n",
            "Epoch 189, change: 0.00041744\n",
            "Epoch 161, change: 0.00126751\n",
            "Epoch 188, change: 0.00058085\n",
            "Epoch 161, change: 0.00112363\n",
            "Epoch 159, change: 0.00187362\n",
            "Epoch 188, change: 0.00052328\n",
            "Epoch 161, change: 0.00141564\n",
            "Epoch 190, change: 0.00037436\n",
            "Epoch 161, change: 0.00107215\n",
            "Epoch 188, change: 0.00034514\n",
            "Epoch 162, change: 0.00152128\n",
            "Epoch 190, change: 0.00041200\n",
            "Epoch 189, change: 0.00039341\n",
            "Epoch 189, change: 0.00057192\n",
            "Epoch 162, change: 0.00125410\n",
            "Epoch 162, change: 0.00111242\n",
            "Epoch 160, change: 0.00185721\n",
            "Epoch 189, change: 0.00051385\n",
            "Epoch 162, change: 0.00141179\n",
            "Epoch 191, change: 0.00036746\n",
            "Epoch 189, change: 0.00034016\n",
            "Epoch 162, change: 0.00106037\n",
            "Epoch 163, change: 0.00150771\n",
            "Epoch 191, change: 0.00040661\n",
            "Epoch 190, change: 0.00038808\n",
            "Epoch 163, change: 0.00124170\n",
            "Epoch 190, change: 0.00056393\n",
            "Epoch 163, change: 0.00109439\n",
            "Epoch 190, change: 0.00050559\n",
            "Epoch 161, change: 0.00183742\n",
            "Epoch 192, change: 0.00036174\n",
            "Epoch 163, change: 0.00139640\n",
            "Epoch 190, change: 0.00033526\n",
            "Epoch 163, change: 0.00105003\n",
            "Epoch 192, change: 0.00040132\n",
            "Epoch 164, change: 0.00149559\n",
            "Epoch 191, change: 0.00038284\n",
            "Epoch 164, change: 0.00123080\n",
            "Epoch 191, change: 0.00055596\n",
            "Epoch 164, change: 0.00108919\n",
            "Epoch 191, change: 0.00049567\n",
            "Epoch 162, change: 0.00181521\n",
            "Epoch 193, change: 0.00035510\n",
            "Epoch 164, change: 0.00137405\n",
            "Epoch 191, change: 0.00033042\n",
            "Epoch 164, change: 0.00103936\n",
            "Epoch 193, change: 0.00039611\n",
            "Epoch 192, change: 0.00037768\n",
            "Epoch 165, change: 0.00148284\n",
            "Epoch 165, change: 0.00121760\n",
            "Epoch 192, change: 0.00054733\n",
            "Epoch 192, change: 0.00048700\n",
            "Epoch 165, change: 0.00106868\n",
            "Epoch 163, change: 0.00180247\n",
            "Epoch 194, change: 0.00034937\n",
            "Epoch 165, change: 0.00136162\n",
            "Epoch 192, change: 0.00032565\n",
            "Epoch 165, change: 0.00102361\n",
            "Epoch 193, change: 0.00037258\n",
            "Epoch 194, change: 0.00039095\n",
            "Epoch 193, change: 0.00053905\n",
            "Epoch 166, change: 0.00147004\n",
            "Epoch 166, change: 0.00120753\n",
            "Epoch 193, change: 0.00047883\n",
            "Epoch 164, change: 0.00178845\n",
            "Epoch 166, change: 0.00106232\n",
            "Epoch 195, change: 0.00034340\n",
            "Epoch 166, change: 0.00134602\n",
            "Epoch 193, change: 0.00032096\n",
            "Epoch 194, change: 0.00036748\n",
            "Epoch 195, change: 0.00038586\n",
            "Epoch 166, change: 0.00101503\n",
            "Epoch 194, change: 0.00053169\n",
            "Epoch 167, change: 0.00145764\n",
            "Epoch 167, change: 0.00119563\n",
            "Epoch 194, change: 0.00047088\n",
            "Epoch 165, change: 0.00177442\n",
            "Epoch 167, change: 0.00104442\n",
            "Epoch 196, change: 0.00033725\n",
            "Epoch 167, change: 0.00133075\n",
            "Epoch 194, change: 0.00031633\n",
            "Epoch 195, change: 0.00036253\n",
            "Epoch 196, change: 0.00038083\n",
            "Epoch 167, change: 0.00100213\n",
            "Epoch 195, change: 0.00052348\n",
            "Epoch 168, change: 0.00144627\n",
            "Epoch 195, change: 0.00046346\n",
            "Epoch 168, change: 0.00118515\n",
            "Epoch 166, change: 0.00175253\n",
            "Epoch 168, change: 0.00103315\n",
            "Epoch 197, change: 0.00033152\n",
            "Epoch 168, change: 0.00132038\n",
            "Epoch 195, change: 0.00031177\n",
            "Epoch 197, change: 0.00037589\n",
            "Epoch 196, change: 0.00035761\n",
            "Epoch 196, change: 0.00051603\n",
            "Epoch 168, change: 0.00099263\n",
            "Epoch 169, change: 0.00143387\n",
            "Epoch 196, change: 0.00045654\n",
            "Epoch 169, change: 0.00115430\n",
            "Epoch 167, change: 0.00173667\n",
            "Epoch 169, change: 0.00102143\n",
            "Epoch 198, change: 0.00032582\n",
            "Epoch 169, change: 0.00127323\n",
            "Epoch 196, change: 0.00030728\n",
            "Epoch 197, change: 0.00035277\n",
            "Epoch 198, change: 0.00037099\n",
            "Epoch 197, change: 0.00050829\n",
            "Epoch 169, change: 0.00098132\n",
            "Epoch 170, change: 0.00142225\n",
            "Epoch 197, change: 0.00044573\n",
            "Epoch 170, change: 0.00114496\n",
            "Epoch 168, change: 0.00172148\n",
            "Epoch 170, change: 0.00100249\n",
            "Epoch 199, change: 0.00032023\n",
            "Epoch 170, change: 0.00127545\n",
            "Epoch 197, change: 0.00030285\n",
            "Epoch 198, change: 0.00034799\n",
            "Epoch 199, change: 0.00036616\n",
            "Epoch 198, change: 0.00050078\n",
            "Epoch 170, change: 0.00097169\n",
            "Epoch 171, change: 0.00141090\n",
            "Epoch 198, change: 0.00043779\n",
            "Epoch 171, change: 0.00113384\n",
            "Epoch 171, change: 0.00099750\n",
            "Epoch 200, change: 0.00031499\n",
            "Epoch 169, change: 0.00170563\n",
            "Epoch 200, change: 0.00036143\n",
            "Epoch 199, change: 0.00034330\n",
            "Epoch 198, change: 0.00029849\n",
            "Epoch 171, change: 0.00126504\n",
            "Epoch 199, change: 0.00049358\n",
            "Epoch 171, change: 0.00096113\n",
            "Epoch 199, change: 0.00043034\n",
            "Epoch 172, change: 0.00139784\n",
            "Epoch 172, change: 0.00112322\n",
            "Epoch 201, change: 0.00030969\n",
            "Epoch 172, change: 0.00098044\n",
            "Epoch 170, change: 0.00169191\n",
            "Epoch 200, change: 0.00033863\n",
            "Epoch 201, change: 0.00035677\n",
            "Epoch 199, change: 0.00029419\n",
            "Epoch 200, change: 0.00048617\n",
            "Epoch 172, change: 0.00123737\n",
            "Epoch 172, change: 0.00094968\n",
            "Epoch 200, change: 0.00042280\n",
            "Epoch 173, change: 0.00138684\n",
            "Epoch 173, change: 0.00111370\n",
            "Epoch 202, change: 0.00030421\n",
            "Epoch 173, change: 0.00097071\n",
            "Epoch 171, change: 0.00167630\n",
            "Epoch 200, change: 0.00028996\n",
            "Epoch 201, change: 0.00033405\n",
            "Epoch 202, change: 0.00035207\n",
            "Epoch 173, change: 0.00123257\n",
            "Epoch 201, change: 0.00047919\n",
            "Epoch 173, change: 0.00093666\n",
            "Epoch 201, change: 0.00041553\n",
            "Epoch 174, change: 0.00137577\n",
            "Epoch 174, change: 0.00109957\n",
            "Epoch 203, change: 0.00029923\n",
            "Epoch 174, change: 0.00095852\n",
            "Epoch 172, change: 0.00166090\n",
            "Epoch 203, change: 0.00034748\n",
            "Epoch 201, change: 0.00028578\n",
            "Epoch 202, change: 0.00032953\n",
            "Epoch 202, change: 0.00047226\n",
            "Epoch 174, change: 0.00121575\n",
            "Epoch 202, change: 0.00040817\n",
            "Epoch 174, change: 0.00093018\n",
            "Epoch 204, change: 0.00029445\n",
            "Epoch 175, change: 0.00136430\n",
            "Epoch 175, change: 0.00109213\n",
            "Epoch 175, change: 0.00094284\n",
            "Epoch 173, change: 0.00164706\n",
            "Epoch 204, change: 0.00034298\n",
            "Epoch 203, change: 0.00032507\n",
            "Epoch 202, change: 0.00028165\n",
            "Epoch 203, change: 0.00046532\n",
            "Epoch 203, change: 0.00040070\n",
            "Epoch 175, change: 0.00120033\n",
            "Epoch 175, change: 0.00091781\n",
            "Epoch 205, change: 0.00028981\n",
            "Epoch 176, change: 0.00107033\n",
            "Epoch 176, change: 0.00135389\n",
            "Epoch 176, change: 0.00094229\n",
            "Epoch 174, change: 0.00163537\n",
            "Epoch 205, change: 0.00033854\n",
            "Epoch 204, change: 0.00032068\n",
            "Epoch 203, change: 0.00027759\n",
            "Epoch 204, change: 0.00045868\n",
            "Epoch 204, change: 0.00039389\n",
            "Epoch 176, change: 0.00118598\n",
            "Epoch 206, change: 0.00028510\n",
            "Epoch 176, change: 0.00090828\n",
            "Epoch 177, change: 0.00106349\n",
            "Epoch 177, change: 0.00134076\n",
            "Epoch 206, change: 0.00033412\n",
            "Epoch 175, change: 0.00162403\n",
            "Epoch 177, change: 0.00093015\n",
            "Epoch 205, change: 0.00031635\n",
            "Epoch 204, change: 0.00027360\n",
            "Epoch 205, change: 0.00045212\n",
            "Epoch 205, change: 0.00038730\n",
            "Epoch 207, change: 0.00028043\n",
            "Epoch 177, change: 0.00117250\n",
            "Epoch 177, change: 0.00089807\n",
            "Epoch 207, change: 0.00032978\n",
            "Epoch 178, change: 0.00133012\n",
            "Epoch 176, change: 0.00160024\n",
            "Epoch 178, change: 0.00105083\n",
            "Epoch 206, change: 0.00031207\n",
            "Epoch 178, change: 0.00092370\n",
            "Epoch 205, change: 0.00026966\n",
            "Epoch 206, change: 0.00044544\n",
            "Epoch 206, change: 0.00038056\n",
            "Epoch 208, change: 0.00027596\n",
            "Epoch 178, change: 0.00115814\n",
            "Epoch 178, change: 0.00088974\n",
            "Epoch 208, change: 0.00032553\n",
            "Epoch 207, change: 0.00030784\n",
            "Epoch 179, change: 0.00132032\n",
            "Epoch 179, change: 0.00104125\n",
            "Epoch 179, change: 0.00090650\n",
            "Epoch 177, change: 0.00159003\n",
            "Epoch 206, change: 0.00026574\n",
            "Epoch 207, change: 0.00043889\n",
            "Epoch 207, change: 0.00037348\n",
            "Epoch 209, change: 0.00026995\n",
            "Epoch 179, change: 0.00114723\n",
            "Epoch 179, change: 0.00088121\n",
            "Epoch 209, change: 0.00032127\n",
            "Epoch 208, change: 0.00030368\n",
            "Epoch 178, change: 0.00157884\n",
            "Epoch 207, change: 0.00026193\n",
            "Epoch 180, change: 0.00102716\n",
            "Epoch 180, change: 0.00090171\n",
            "Epoch 180, change: 0.00130874\n",
            "Epoch 208, change: 0.00043230\n",
            "Epoch 208, change: 0.00036736\n",
            "Epoch 210, change: 0.00026531\n",
            "Epoch 180, change: 0.00112918\n",
            "Epoch 180, change: 0.00086970\n",
            "Epoch 210, change: 0.00031709\n",
            "Epoch 209, change: 0.00029958\n",
            "Epoch 208, change: 0.00025814\n",
            "Epoch 181, change: 0.00129832\n",
            "Epoch 181, change: 0.00101897\n",
            "Epoch 179, change: 0.00155680\n",
            "Epoch 181, change: 0.00088146\n",
            "Epoch 209, change: 0.00042608\n",
            "Epoch 209, change: 0.00036148\n",
            "Epoch 211, change: 0.00026116\n",
            "Epoch 211, change: 0.00031298\n",
            "Epoch 181, change: 0.00111971\n",
            "Epoch 181, change: 0.00086260\n",
            "Epoch 209, change: 0.00025443\n",
            "Epoch 210, change: 0.00029553\n",
            "Epoch 182, change: 0.00128734\n",
            "Epoch 182, change: 0.00101214\n",
            "Epoch 210, change: 0.00041979\n",
            "Epoch 180, change: 0.00154918\n",
            "Epoch 182, change: 0.00087417\n",
            "Epoch 210, change: 0.00035436\n",
            "Epoch 212, change: 0.00025646\n",
            "Epoch 212, change: 0.00030893\n",
            "Epoch 182, change: 0.00110974\n",
            "Epoch 182, change: 0.00084974\n",
            "Epoch 210, change: 0.00025076\n",
            "Epoch 211, change: 0.00029155\n",
            "Epoch 183, change: 0.00127690\n",
            "Epoch 211, change: 0.00041366\n",
            "Epoch 183, change: 0.00100350\n",
            "Epoch 181, change: 0.00152651\n",
            "Epoch 183, change: 0.00087095\n",
            "Epoch 211, change: 0.00034881\n",
            "Epoch 213, change: 0.00025212\n",
            "Epoch 213, change: 0.00030493\n",
            "Epoch 183, change: 0.00109953\n",
            "Epoch 212, change: 0.00028762\n",
            "Epoch 211, change: 0.00024715\n",
            "Epoch 183, change: 0.00084263\n",
            "Epoch 212, change: 0.00040783\n",
            "Epoch 184, change: 0.00126674\n",
            "Epoch 184, change: 0.00099309\n",
            "Epoch 182, change: 0.00151888\n",
            "Epoch 184, change: 0.00085515\n",
            "Epoch 212, change: 0.00034354\n",
            "Epoch 214, change: 0.00024762\n",
            "Epoch 214, change: 0.00030099\n",
            "Epoch 213, change: 0.00028370\n",
            "Epoch 184, change: 0.00108935\n",
            "Epoch 212, change: 0.00024358\n",
            "Epoch 213, change: 0.00040165\n",
            "Epoch 185, change: 0.00125746\n",
            "Epoch 185, change: 0.00096739\n",
            "Epoch 184, change: 0.00083375\n",
            "Epoch 185, change: 0.00084748\n",
            "Epoch 183, change: 0.00150283\n",
            "Epoch 213, change: 0.00033584\n",
            "Epoch 215, change: 0.00024351\n",
            "Epoch 215, change: 0.00029708\n",
            "Epoch 214, change: 0.00027987\n",
            "Epoch 213, change: 0.00024009\n",
            "Epoch 214, change: 0.00039578\n",
            "Epoch 185, change: 0.00107931\n",
            "Epoch 186, change: 0.00124587\n",
            "Epoch 186, change: 0.00096456\n",
            "Epoch 185, change: 0.00082461\n",
            "Epoch 186, change: 0.00084128\n",
            "Epoch 214, change: 0.00033058\n",
            "Epoch 184, change: 0.00149139\n",
            "Epoch 216, change: 0.00023927\n",
            "Epoch 216, change: 0.00029324\n",
            "Epoch 215, change: 0.00027609\n",
            "Epoch 214, change: 0.00023661\n",
            "Epoch 215, change: 0.00039012\n",
            "Epoch 186, change: 0.00106788\n",
            "Epoch 187, change: 0.00095522\n",
            "Epoch 187, change: 0.00123636\n",
            "Epoch 186, change: 0.00081640\n",
            "Epoch 187, change: 0.00082910\n",
            "Epoch 215, change: 0.00032529\n",
            "Epoch 185, change: 0.00147923\n",
            "Epoch 217, change: 0.00023515\n",
            "Epoch 217, change: 0.00028945\n",
            "Epoch 216, change: 0.00027236\n",
            "Epoch 215, change: 0.00023321\n",
            "Epoch 216, change: 0.00038460\n",
            "Epoch 187, change: 0.00105793\n",
            "Epoch 187, change: 0.00080587\n",
            "Epoch 188, change: 0.00122599\n",
            "Epoch 188, change: 0.00094259\n",
            "Epoch 216, change: 0.00031845\n",
            "Epoch 188, change: 0.00081877\n",
            "Epoch 186, change: 0.00146015\n",
            "Epoch 218, change: 0.00023131\n",
            "Epoch 218, change: 0.00028568\n",
            "Epoch 217, change: 0.00026867\n",
            "Epoch 216, change: 0.00022985\n",
            "Epoch 217, change: 0.00037897\n",
            "Epoch 188, change: 0.00079765\n",
            "Epoch 188, change: 0.00104838\n",
            "Epoch 189, change: 0.00121715\n",
            "Epoch 217, change: 0.00031308\n",
            "Epoch 189, change: 0.00081406\n",
            "Epoch 189, change: 0.00093569\n",
            "Epoch 219, change: 0.00022748\n",
            "Epoch 187, change: 0.00144998\n",
            "Epoch 219, change: 0.00028196\n",
            "Epoch 218, change: 0.00026504\n",
            "Epoch 217, change: 0.00022654\n",
            "Epoch 218, change: 0.00037319\n",
            "Epoch 190, change: 0.00120699\n",
            "Epoch 189, change: 0.00078845\n",
            "Epoch 189, change: 0.00103881\n",
            "Epoch 218, change: 0.00030769\n",
            "Epoch 220, change: 0.00022348\n",
            "Epoch 190, change: 0.00080454\n",
            "Epoch 188, change: 0.00143576\n",
            "Epoch 190, change: 0.00092809\n",
            "Epoch 220, change: 0.00027834\n",
            "Epoch 219, change: 0.00026146\n",
            "Epoch 218, change: 0.00022328\n",
            "Epoch 219, change: 0.00036781\n",
            "Epoch 191, change: 0.00119624\n",
            "Epoch 219, change: 0.00030241\n",
            "Epoch 190, change: 0.00102949\n",
            "Epoch 190, change: 0.00078074\n",
            "Epoch 221, change: 0.00021973\n",
            "Epoch 189, change: 0.00142510\n",
            "Epoch 191, change: 0.00079373\n",
            "Epoch 191, change: 0.00091813\n",
            "Epoch 221, change: 0.00027474\n",
            "Epoch 220, change: 0.00025793\n",
            "Epoch 219, change: 0.00022008\n",
            "Epoch 220, change: 0.00036262\n",
            "Epoch 192, change: 0.00118741\n",
            "Epoch 220, change: 0.00029718\n",
            "Epoch 222, change: 0.00021607\n",
            "Epoch 191, change: 0.00102055\n",
            "Epoch 191, change: 0.00077183\n",
            "Epoch 190, change: 0.00141132\n",
            "Epoch 192, change: 0.00078582\n",
            "Epoch 192, change: 0.00090407\n",
            "Epoch 222, change: 0.00027115\n",
            "Epoch 221, change: 0.00025446\n",
            "Epoch 220, change: 0.00021691\n",
            "Epoch 221, change: 0.00035732\n",
            "Epoch 193, change: 0.00117812\n",
            "Epoch 223, change: 0.00021260\n",
            "Epoch 221, change: 0.00029176\n",
            "Epoch 192, change: 0.00101160\n",
            "Epoch 192, change: 0.00076417\n",
            "Epoch 191, change: 0.00140068\n",
            "Epoch 193, change: 0.00077644\n",
            "Epoch 223, change: 0.00026762\n",
            "Epoch 193, change: 0.00089412\n",
            "Epoch 222, change: 0.00025101\n",
            "Epoch 221, change: 0.00021379\n",
            "Epoch 222, change: 0.00035218\n",
            "Epoch 224, change: 0.00020881\n",
            "Epoch 222, change: 0.00028689\n",
            "Epoch 194, change: 0.00116933\n",
            "Epoch 193, change: 0.00099909\n",
            "Epoch 193, change: 0.00075678\n",
            "Epoch 192, change: 0.00138578\n",
            "Epoch 194, change: 0.00077484\n",
            "Epoch 224, change: 0.00026416\n",
            "Epoch 223, change: 0.00024762\n",
            "Epoch 194, change: 0.00088524\n",
            "Epoch 222, change: 0.00021069\n",
            "Epoch 223, change: 0.00034711\n",
            "Epoch 225, change: 0.00020551\n",
            "Epoch 223, change: 0.00028221\n",
            "Epoch 195, change: 0.00115827\n",
            "Epoch 194, change: 0.00099136\n",
            "Epoch 194, change: 0.00075042\n",
            "Epoch 193, change: 0.00137488\n",
            "Epoch 225, change: 0.00026074\n",
            "Epoch 224, change: 0.00024427\n",
            "Epoch 195, change: 0.00076380\n",
            "Epoch 195, change: 0.00087500\n",
            "Epoch 223, change: 0.00020767\n",
            "Epoch 224, change: 0.00034180\n",
            "Epoch 226, change: 0.00020173\n",
            "Epoch 224, change: 0.00027700\n",
            "Epoch 196, change: 0.00115031\n",
            "Epoch 195, change: 0.00098324\n",
            "Epoch 195, change: 0.00074059\n",
            "Epoch 194, change: 0.00136318\n",
            "Epoch 225, change: 0.00024097\n",
            "Epoch 226, change: 0.00025736\n",
            "Epoch 196, change: 0.00075806\n",
            "Epoch 196, change: 0.00086625\n",
            "Epoch 224, change: 0.00020468\n",
            "Epoch 225, change: 0.00033681\n",
            "Epoch 227, change: 0.00019834\n",
            "Epoch 225, change: 0.00027231\n",
            "Epoch 196, change: 0.00097501\n",
            "Epoch 197, change: 0.00114123\n",
            "Epoch 196, change: 0.00073253\n",
            "Epoch 227, change: 0.00025405\n",
            "Epoch 226, change: 0.00023772\n",
            "Epoch 197, change: 0.00074667\n",
            "Epoch 195, change: 0.00134937\n",
            "Epoch 197, change: 0.00086009\n",
            "Epoch 225, change: 0.00020172\n",
            "Epoch 226, change: 0.00033211\n",
            "Epoch 228, change: 0.00019503\n",
            "Epoch 226, change: 0.00026779\n",
            "Epoch 198, change: 0.00113080\n",
            "Epoch 197, change: 0.00096611\n",
            "Epoch 228, change: 0.00025076\n",
            "Epoch 227, change: 0.00023452\n",
            "Epoch 197, change: 0.00072516\n",
            "Epoch 198, change: 0.00074057\n",
            "Epoch 196, change: 0.00133680\n",
            "Epoch 198, change: 0.00084814\n",
            "Epoch 226, change: 0.00019882\n",
            "Epoch 229, change: 0.00019169\n",
            "Epoch 227, change: 0.00032720\n",
            "Epoch 227, change: 0.00026341\n",
            "Epoch 199, change: 0.00112303\n",
            "Epoch 198, change: 0.00095743\n",
            "Epoch 229, change: 0.00024751\n",
            "Epoch 228, change: 0.00023134\n",
            "Epoch 198, change: 0.00071664\n",
            "Epoch 199, change: 0.00073195\n",
            "Epoch 197, change: 0.00132662\n",
            "Epoch 227, change: 0.00019596\n",
            "Epoch 199, change: 0.00084195\n",
            "Epoch 230, change: 0.00018868\n",
            "Epoch 228, change: 0.00032250\n",
            "Epoch 228, change: 0.00025832\n",
            "Epoch 200, change: 0.00111396\n",
            "Epoch 199, change: 0.00094617\n",
            "Epoch 229, change: 0.00022822\n",
            "Epoch 230, change: 0.00024431\n",
            "Epoch 199, change: 0.00071155\n",
            "Epoch 200, change: 0.00072668\n",
            "Epoch 228, change: 0.00019314\n",
            "Epoch 198, change: 0.00131292\n",
            "Epoch 229, change: 0.00031778\n",
            "Epoch 200, change: 0.00082950\n",
            "Epoch 231, change: 0.00018555\n",
            "Epoch 229, change: 0.00025387\n",
            "Epoch 201, change: 0.00110462\n",
            "Epoch 200, change: 0.00093888\n",
            "Epoch 230, change: 0.00022513\n",
            "Epoch 231, change: 0.00024113\n",
            "Epoch 200, change: 0.00070336\n",
            "Epoch 229, change: 0.00019037\n",
            "Epoch 201, change: 0.00072050\n",
            "Epoch 230, change: 0.00031303\n",
            "Epoch 199, change: 0.00130477\n",
            "Epoch 201, change: 0.00082360\n",
            "Epoch 232, change: 0.00018225\n",
            "Epoch 230, change: 0.00024934\n",
            "Epoch 202, change: 0.00109557\n",
            "Epoch 231, change: 0.00022210\n",
            "Epoch 201, change: 0.00093027\n",
            "Epoch 232, change: 0.00023804\n",
            "Epoch 230, change: 0.00018761\n",
            "Epoch 202, change: 0.00070946\n",
            "Epoch 201, change: 0.00069636\n",
            "Epoch 231, change: 0.00030868\n",
            "Epoch 202, change: 0.00081643\n",
            "Epoch 200, change: 0.00129042\n",
            "Epoch 233, change: 0.00017903\n",
            "Epoch 231, change: 0.00024507\n",
            "Epoch 203, change: 0.00108714\n",
            "Epoch 232, change: 0.00021910\n",
            "Epoch 202, change: 0.00092157\n",
            "Epoch 233, change: 0.00023499\n",
            "Epoch 232, change: 0.00030423\n",
            "Epoch 231, change: 0.00018492\n",
            "Epoch 202, change: 0.00068988\n",
            "Epoch 203, change: 0.00070739\n",
            "Epoch 203, change: 0.00080452\n",
            "Epoch 201, change: 0.00127854\n",
            "Epoch 234, change: 0.00017607\n",
            "Epoch 232, change: 0.00024131\n",
            "Epoch 204, change: 0.00107847\n",
            "Epoch 233, change: 0.00021614\n",
            "Epoch 234, change: 0.00023198\n",
            "Epoch 203, change: 0.00091158\n",
            "Epoch 233, change: 0.00029959\n",
            "Epoch 232, change: 0.00018226\n",
            "Epoch 204, change: 0.00069744\n",
            "Epoch 204, change: 0.00079606\n",
            "Epoch 203, change: 0.00068289\n",
            "Epoch 202, change: 0.00126829\n",
            "Epoch 235, change: 0.00017315\n",
            "Epoch 233, change: 0.00023700\n",
            "Epoch 234, change: 0.00021324\n",
            "Epoch 205, change: 0.00107083\n",
            "Epoch 235, change: 0.00022901\n",
            "Epoch 204, change: 0.00090372\n",
            "Epoch 234, change: 0.00029539\n",
            "Epoch 233, change: 0.00017963\n",
            "Epoch 205, change: 0.00068649\n",
            "Epoch 205, change: 0.00078930\n",
            "Epoch 203, change: 0.00125923\n",
            "Epoch 236, change: 0.00017032\n",
            "Epoch 204, change: 0.00067089\n",
            "Epoch 234, change: 0.00023285\n",
            "Epoch 206, change: 0.00106127\n",
            "Epoch 235, change: 0.00021037\n",
            "Epoch 236, change: 0.00022608\n",
            "Epoch 205, change: 0.00089632\n",
            "Epoch 235, change: 0.00029119\n",
            "Epoch 234, change: 0.00017704\n",
            "Epoch 237, change: 0.00016734\n",
            "Epoch 206, change: 0.00068237\n",
            "Epoch 206, change: 0.00077926\n",
            "Epoch 204, change: 0.00124582\n",
            "Epoch 205, change: 0.00066633\n",
            "Epoch 235, change: 0.00022840\n",
            "Epoch 207, change: 0.00105348\n",
            "Epoch 236, change: 0.00020751\n",
            "Epoch 237, change: 0.00022318\n",
            "Epoch 206, change: 0.00088689\n",
            "Epoch 236, change: 0.00028686\n",
            "Epoch 235, change: 0.00017450\n",
            "Epoch 238, change: 0.00016458\n",
            "Epoch 207, change: 0.00067646\n",
            "Epoch 207, change: 0.00077226\n",
            "Epoch 206, change: 0.00065998\n",
            "Epoch 205, change: 0.00123678\n",
            "Epoch 236, change: 0.00022487\n",
            "Epoch 237, change: 0.00020470\n",
            "Epoch 208, change: 0.00104496\n",
            "Epoch 238, change: 0.00022033\n",
            "Epoch 207, change: 0.00087836\n",
            "Epoch 237, change: 0.00028274\n",
            "Epoch 236, change: 0.00017199\n",
            "Epoch 239, change: 0.00016188\n",
            "Epoch 207, change: 0.00065222\n",
            "Epoch 208, change: 0.00067253\n",
            "Epoch 208, change: 0.00076459\n",
            "Epoch 206, change: 0.00122423\n",
            "Epoch 237, change: 0.00022113\n",
            "Epoch 238, change: 0.00020195\n",
            "Epoch 239, change: 0.00021751\n",
            "Epoch 209, change: 0.00103695\n",
            "Epoch 238, change: 0.00027869\n",
            "Epoch 208, change: 0.00087084\n",
            "Epoch 237, change: 0.00016953\n",
            "Epoch 240, change: 0.00015910\n",
            "Epoch 208, change: 0.00064638\n",
            "Epoch 209, change: 0.00065831\n",
            "Epoch 238, change: 0.00021693\n",
            "Epoch 207, change: 0.00121284\n",
            "Epoch 209, change: 0.00075802\n",
            "Epoch 239, change: 0.00019924\n",
            "Epoch 240, change: 0.00021473\n",
            "Epoch 210, change: 0.00102976\n",
            "Epoch 239, change: 0.00027447\n",
            "Epoch 238, change: 0.00016710\n",
            "Epoch 209, change: 0.00086387\n",
            "Epoch 241, change: 0.00015658\n",
            "Epoch 209, change: 0.00063954\n",
            "Epoch 210, change: 0.00065571\n",
            "Epoch 239, change: 0.00021302\n",
            "Epoch 208, change: 0.00120511\n",
            "Epoch 210, change: 0.00075256\n",
            "Epoch 240, change: 0.00019652\n",
            "Epoch 241, change: 0.00021198\n",
            "Epoch 211, change: 0.00102194\n",
            "Epoch 240, change: 0.00027054\n",
            "Epoch 239, change: 0.00016467\n",
            "Epoch 210, change: 0.00085490\n",
            "Epoch 242, change: 0.00015380\n",
            "Epoch 211, change: 0.00064877\n",
            "Epoch 210, change: 0.00063329\n",
            "Epoch 240, change: 0.00020930\n",
            "Epoch 209, change: 0.00119270\n",
            "Epoch 211, change: 0.00074269\n",
            "Epoch 241, change: 0.00019387\n",
            "Epoch 242, change: 0.00020927\n",
            "Epoch 212, change: 0.00101386\n",
            "Epoch 241, change: 0.00026659\n",
            "Epoch 240, change: 0.00016230\n",
            "Epoch 243, change: 0.00015115\n",
            "Epoch 211, change: 0.00084808\n",
            "Epoch 212, change: 0.00064422\n",
            "Epoch 241, change: 0.00020629\n",
            "Epoch 211, change: 0.00062548\n",
            "Epoch 210, change: 0.00118045\n",
            "Epoch 242, change: 0.00019125\n",
            "Epoch 212, change: 0.00073086\n",
            "Epoch 243, change: 0.00020659\n",
            "Epoch 213, change: 0.00100315\n",
            "Epoch 241, change: 0.00015997\n",
            "Epoch 242, change: 0.00026274\n",
            "Epoch 244, change: 0.00014855\n",
            "Epoch 212, change: 0.00083949\n",
            "Epoch 213, change: 0.00063566\n",
            "Epoch 242, change: 0.00020350\n",
            "Epoch 212, change: 0.00061897\n",
            "Epoch 211, change: 0.00117061\n",
            "Epoch 243, change: 0.00018867\n",
            "Epoch 213, change: 0.00072404\n",
            "Epoch 244, change: 0.00020395\n",
            "Epoch 242, change: 0.00015767\n",
            "Epoch 243, change: 0.00025890\n",
            "Epoch 214, change: 0.00099682\n",
            "Epoch 245, change: 0.00014617\n",
            "Epoch 213, change: 0.00083269\n",
            "Epoch 214, change: 0.00062722\n",
            "Epoch 243, change: 0.00020072\n",
            "Epoch 213, change: 0.00061391\n",
            "Epoch 212, change: 0.00116190\n",
            "Epoch 244, change: 0.00018613\n",
            "Epoch 214, change: 0.00071768\n",
            "Epoch 245, change: 0.00020134\n",
            "Epoch 243, change: 0.00015540\n",
            "Epoch 244, change: 0.00025514\n",
            "Epoch 215, change: 0.00098929\n",
            "Epoch 246, change: 0.00014365\n",
            "Epoch 214, change: 0.00082522\n",
            "Epoch 244, change: 0.00019803\n",
            "Epoch 215, change: 0.00062294\n",
            "Epoch 245, change: 0.00018361\n",
            "Epoch 214, change: 0.00060726\n",
            "Epoch 213, change: 0.00115136\n",
            "Epoch 246, change: 0.00019876\n",
            "Epoch 215, change: 0.00071155\n",
            "Epoch 216, change: 0.00098219\n",
            "Epoch 244, change: 0.00015315\n",
            "Epoch 245, change: 0.00025144\n",
            "Epoch 247, change: 0.00014132\n",
            "Epoch 215, change: 0.00081805\n",
            "Epoch 245, change: 0.00019540\n",
            "Epoch 216, change: 0.00061665\n",
            "Epoch 246, change: 0.00018113\n",
            "Epoch 215, change: 0.00060162\n",
            "Epoch 214, change: 0.00114353\n",
            "Epoch 247, change: 0.00019622\n",
            "Epoch 216, change: 0.00070379\n",
            "Epoch 217, change: 0.00097412\n",
            "Epoch 245, change: 0.00015096\n",
            "Epoch 246, change: 0.00024787\n",
            "Epoch 248, change: 0.00013890\n",
            "Epoch 216, change: 0.00080869\n",
            "Epoch 246, change: 0.00019275\n",
            "Epoch 217, change: 0.00061204\n",
            "Epoch 247, change: 0.00017869\n",
            "Epoch 215, change: 0.00113049\n",
            "Epoch 216, change: 0.00059526\n",
            "Epoch 248, change: 0.00019371\n",
            "Epoch 217, change: 0.00069803\n",
            "Epoch 246, change: 0.00014878\n",
            "Epoch 218, change: 0.00096482\n",
            "Epoch 247, change: 0.00024435\n",
            "Epoch 249, change: 0.00013651\n",
            "Epoch 217, change: 0.00080219\n",
            "Epoch 247, change: 0.00019017\n",
            "Epoch 248, change: 0.00017628\n",
            "Epoch 218, change: 0.00060781\n",
            "Epoch 249, change: 0.00019123\n",
            "Epoch 217, change: 0.00058925\n",
            "Epoch 216, change: 0.00111953\n",
            "Epoch 218, change: 0.00069088\n",
            "Epoch 250, change: 0.00013428\n",
            "Epoch 247, change: 0.00014664\n",
            "Epoch 248, change: 0.00024073\n",
            "Epoch 219, change: 0.00095826\n",
            "Epoch 218, change: 0.00079589\n",
            "Epoch 248, change: 0.00018761\n",
            "Epoch 249, change: 0.00017390\n",
            "Epoch 219, change: 0.00060364\n",
            "Epoch 250, change: 0.00018878\n",
            "Epoch 217, change: 0.00111183\n",
            "Epoch 218, change: 0.00058239\n",
            "Epoch 219, change: 0.00068409\n",
            "Epoch 251, change: 0.00013196\n",
            "Epoch 249, change: 0.00023722\n",
            "Epoch 248, change: 0.00014452\n",
            "Epoch 220, change: 0.00095149\n",
            "Epoch 249, change: 0.00018508\n",
            "Epoch 219, change: 0.00078813\n",
            "Epoch 250, change: 0.00017156\n",
            "Epoch 251, change: 0.00018637\n",
            "Epoch 220, change: 0.00059945\n",
            "Epoch 218, change: 0.00110293\n",
            "Epoch 219, change: 0.00057648\n",
            "Epoch 220, change: 0.00067878\n",
            "Epoch 252, change: 0.00012987\n",
            "Epoch 250, change: 0.00023370\n",
            "Epoch 249, change: 0.00014245\n",
            "Epoch 221, change: 0.00094426\n",
            "Epoch 220, change: 0.00078048\n",
            "Epoch 250, change: 0.00018256\n",
            "Epoch 251, change: 0.00016924\n",
            "Epoch 252, change: 0.00018399\n",
            "Epoch 219, change: 0.00109013\n",
            "Epoch 220, change: 0.00057048\n",
            "Epoch 221, change: 0.00059532\n",
            "Epoch 251, change: 0.00023037\n",
            "Epoch 250, change: 0.00014040\n",
            "Epoch 221, change: 0.00067170\n",
            "Epoch 253, change: 0.00012763\n",
            "Epoch 222, change: 0.00093605\n",
            "Epoch 251, change: 0.00018009\n",
            "Epoch 221, change: 0.00077421\n",
            "Epoch 252, change: 0.00016696\n",
            "Epoch 253, change: 0.00018164\n",
            "Epoch 220, change: 0.00108276\n",
            "Epoch 221, change: 0.00056526\n",
            "Epoch 252, change: 0.00022700\n",
            "Epoch 251, change: 0.00013838\n",
            "Epoch 222, change: 0.00059124\n",
            "Epoch 254, change: 0.00012548\n",
            "Epoch 222, change: 0.00066725\n",
            "Epoch 223, change: 0.00092987\n",
            "Epoch 252, change: 0.00017767\n",
            "Epoch 222, change: 0.00076763\n",
            "Epoch 253, change: 0.00016471\n",
            "Epoch 254, change: 0.00017932\n",
            "Epoch 221, change: 0.00107350\n",
            "Epoch 222, change: 0.00055981\n",
            "Epoch 252, change: 0.00013640\n",
            "Epoch 253, change: 0.00022370\n",
            "Epoch 255, change: 0.00012336\n",
            "Epoch 223, change: 0.00058714\n",
            "Epoch 223, change: 0.00066105\n",
            "Epoch 224, change: 0.00092325\n",
            "Epoch 253, change: 0.00017528\n",
            "Epoch 223, change: 0.00075880\n",
            "Epoch 254, change: 0.00016248\n",
            "Epoch 255, change: 0.00017702\n",
            "Epoch 222, change: 0.00106356\n",
            "Epoch 223, change: 0.00055423\n",
            "Epoch 253, change: 0.00013444\n",
            "Epoch 254, change: 0.00022051\n",
            "Epoch 256, change: 0.00012139\n",
            "Epoch 224, change: 0.00058309\n",
            "Epoch 224, change: 0.00065639\n",
            "Epoch 225, change: 0.00091676\n",
            "Epoch 254, change: 0.00017297\n",
            "Epoch 255, change: 0.00016029\n",
            "Epoch 224, change: 0.00075323\n",
            "Epoch 256, change: 0.00017476\n",
            "Epoch 254, change: 0.00013250\n",
            "Epoch 224, change: 0.00054764\n",
            "Epoch 255, change: 0.00021728\n",
            "Epoch 257, change: 0.00011929\n",
            "Epoch 223, change: 0.00105355\n",
            "Epoch 225, change: 0.00057907\n",
            "Epoch 225, change: 0.00064909\n",
            "Epoch 226, change: 0.00090620\n",
            "Epoch 255, change: 0.00017069\n",
            "Epoch 256, change: 0.00015813\n",
            "Epoch 257, change: 0.00017252\n",
            "Epoch 225, change: 0.00074664\n",
            "Epoch 255, change: 0.00013059\n",
            "Epoch 258, change: 0.00011724\n",
            "Epoch 225, change: 0.00054367\n",
            "Epoch 256, change: 0.00021426\n",
            "Epoch 224, change: 0.00104239\n",
            "Epoch 226, change: 0.00057512\n",
            "Epoch 256, change: 0.00016840\n",
            "Epoch 227, change: 0.00090124\n",
            "Epoch 226, change: 0.00064550\n",
            "Epoch 257, change: 0.00015600\n",
            "Epoch 258, change: 0.00017031\n",
            "Epoch 226, change: 0.00073895\n",
            "Epoch 256, change: 0.00012872\n",
            "Epoch 259, change: 0.00011536\n",
            "Epoch 226, change: 0.00053897\n",
            "Epoch 257, change: 0.00021100\n",
            "Epoch 225, change: 0.00103515\n",
            "Epoch 227, change: 0.00057117\n",
            "Epoch 257, change: 0.00016609\n",
            "Epoch 228, change: 0.00089392\n",
            "Epoch 227, change: 0.00063700\n",
            "Epoch 258, change: 0.00015389\n",
            "Epoch 259, change: 0.00016814\n",
            "Epoch 227, change: 0.00073320\n",
            "Epoch 257, change: 0.00012685\n",
            "Epoch 260, change: 0.00011356\n",
            "Epoch 227, change: 0.00053211\n",
            "Epoch 258, change: 0.00020797\n",
            "Epoch 228, change: 0.00056726\n",
            "Epoch 258, change: 0.00016383\n",
            "Epoch 226, change: 0.00102785\n",
            "Epoch 229, change: 0.00088617\n",
            "Epoch 228, change: 0.00063220\n",
            "Epoch 259, change: 0.00015181\n",
            "Epoch 260, change: 0.00016599\n",
            "Epoch 258, change: 0.00012503\n",
            "Epoch 228, change: 0.00072750\n",
            "Epoch 261, change: 0.00011158\n",
            "Epoch 259, change: 0.00020502\n",
            "Epoch 228, change: 0.00052551\n",
            "Epoch 259, change: 0.00016162\n",
            "Epoch 229, change: 0.00056330\n",
            "Epoch 227, change: 0.00102087\n",
            "Epoch 230, change: 0.00087993\n",
            "Epoch 229, change: 0.00062831\n",
            "Epoch 260, change: 0.00014977\n",
            "Epoch 261, change: 0.00016386\n",
            "Epoch 259, change: 0.00012323\n",
            "Epoch 262, change: 0.00010959\n",
            "Epoch 260, change: 0.00020209\n",
            "Epoch 229, change: 0.00071961\n",
            "Epoch 229, change: 0.00052149\n",
            "Epoch 260, change: 0.00015949\n",
            "Epoch 230, change: 0.00055945\n",
            "Epoch 228, change: 0.00100744\n",
            "Epoch 231, change: 0.00087281\n",
            "Epoch 261, change: 0.00014775\n",
            "Epoch 230, change: 0.00062000\n",
            "Epoch 262, change: 0.00016177\n",
            "Epoch 260, change: 0.00012146\n",
            "Epoch 263, change: 0.00010774\n",
            "Epoch 261, change: 0.00019914\n",
            "Epoch 230, change: 0.00071354\n",
            "Epoch 230, change: 0.00051687\n",
            "Epoch 261, change: 0.00015731\n",
            "Epoch 231, change: 0.00055560\n",
            "Epoch 229, change: 0.00100193\n",
            "Epoch 262, change: 0.00014575\n",
            "Epoch 232, change: 0.00086602\n",
            "Epoch 231, change: 0.00061604\n",
            "Epoch 263, change: 0.00015971\n",
            "Epoch 261, change: 0.00011971\n",
            "Epoch 264, change: 0.00010588\n",
            "Epoch 262, change: 0.00019624\n",
            "Epoch 262, change: 0.00015516\n",
            "Epoch 231, change: 0.00070592\n",
            "Epoch 231, change: 0.00050974\n",
            "Epoch 232, change: 0.00055179\n",
            "Epoch 230, change: 0.00099517\n",
            "Epoch 263, change: 0.00014379\n",
            "Epoch 232, change: 0.00061061\n",
            "Epoch 264, change: 0.00015766\n",
            "Epoch 233, change: 0.00085942\n",
            "Epoch 262, change: 0.00011799\n",
            "Epoch 265, change: 0.00010421\n",
            "Epoch 263, change: 0.00019342\n",
            "Epoch 263, change: 0.00015309\n",
            "Epoch 232, change: 0.00070075\n",
            "Epoch 232, change: 0.00050586\n",
            "Epoch 233, change: 0.00054800\n",
            "Epoch 231, change: 0.00098670\n",
            "Epoch 264, change: 0.00014185\n",
            "Epoch 265, change: 0.00015564\n",
            "Epoch 233, change: 0.00060546\n",
            "Epoch 234, change: 0.00085370\n",
            "Epoch 263, change: 0.00011629\n",
            "Epoch 266, change: 0.00010243\n",
            "Epoch 264, change: 0.00019071\n",
            "Epoch 264, change: 0.00015105\n",
            "Epoch 233, change: 0.00069350\n",
            "Epoch 233, change: 0.00050049\n",
            "Epoch 234, change: 0.00054426\n",
            "Epoch 265, change: 0.00013993\n",
            "Epoch 232, change: 0.00096888\n",
            "Epoch 266, change: 0.00015366\n",
            "Epoch 234, change: 0.00060050\n",
            "Epoch 264, change: 0.00011462\n",
            "Epoch 267, change: 0.00010068\n",
            "Epoch 235, change: 0.00084599\n",
            "Epoch 265, change: 0.00018798\n",
            "Epoch 265, change: 0.00014903\n",
            "Epoch 234, change: 0.00049620\n",
            "Epoch 234, change: 0.00068832\n",
            "Epoch 235, change: 0.00054053\n",
            "Epoch 266, change: 0.00013805\n",
            "Epoch 267, change: 0.00015169\n",
            "Epoch 233, change: 0.00096581\n",
            "Epoch 265, change: 0.00011297\n",
            "Epoch 235, change: 0.00059488\n",
            "convergence after 268 epochs took 278 seconds\n",
            "Epoch 236, change: 0.00083979\n",
            "Epoch 266, change: 0.00018513\n",
            "Epoch 266, change: 0.00014699\n",
            "Epoch 235, change: 0.00049171\n",
            "Epoch 235, change: 0.00068245\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.40194D-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 236, change: 0.00053684\n",
            "Epoch 267, change: 0.00013619\n",
            "Epoch 268, change: 0.00014976\n",
            "Epoch 234, change: 0.00095676\n",
            "Epoch 266, change: 0.00011134\n",
            "Epoch 236, change: 0.00059105\n",
            "Epoch 237, change: 0.00083411\n",
            "Epoch 267, change: 0.00014508\n",
            "Epoch 267, change: 0.00018255\n",
            "Epoch 236, change: 0.00048720\n",
            "Epoch 236, change: 0.00067519\n",
            "Epoch 268, change: 0.00013436\n",
            "Epoch 269, change: 0.00014784\n",
            "Epoch 237, change: 0.00053317\n",
            "Epoch 235, change: 0.00094837\n",
            "Epoch 267, change: 0.00010974\n",
            "Epoch 237, change: 0.00058355\n",
            "Epoch 238, change: 0.00082687\n",
            "Epoch 268, change: 0.00017996\n",
            "Epoch 268, change: 0.00014316\n",
            "Epoch 237, change: 0.00048340\n",
            "Epoch 237, change: 0.00066941\n",
            "Epoch 269, change: 0.00013254\n",
            "Epoch 270, change: 0.00014595\n",
            "Epoch 238, change: 0.00052942\n",
            "Epoch 236, change: 0.00094036\n",
            "Epoch 268, change: 0.00010817\n",
            "Epoch 238, change: 0.00057914\n",
            "Epoch 239, change: 0.00082046\n",
            "Epoch 269, change: 0.00014124\n",
            "Epoch 269, change: 0.00017737\n",
            "Epoch 238, change: 0.00047977\n",
            "Epoch 270, change: 0.00013075\n",
            "Epoch 238, change: 0.00066391\n",
            "Epoch 271, change: 0.00014408\n",
            "Epoch 239, change: 0.00052585\n",
            "Epoch 237, change: 0.00093347\n",
            "Epoch 269, change: 0.00010661\n",
            "Epoch 239, change: 0.00057579\n",
            "Epoch 240, change: 0.00081499\n",
            "Epoch 270, change: 0.00013935\n",
            "Epoch 270, change: 0.00017469\n",
            "Epoch 271, change: 0.00012899\n",
            "Epoch 239, change: 0.00047610\n",
            "Epoch 239, change: 0.00065811\n",
            "Epoch 272, change: 0.00014224\n",
            "Epoch 240, change: 0.00052226\n",
            "Epoch 270, change: 0.00010506\n",
            "\n",
            "At iterate   50    f=  2.48657D-01    |proj g|=  8.58704D-04\n",
            "Epoch 238, change: 0.00092437\n",
            "Epoch 271, change: 0.00013744\n",
            "Epoch 241, change: 0.00080868\n",
            "Epoch 240, change: 0.00056981\n",
            "Epoch 271, change: 0.00017224\n",
            "Epoch 272, change: 0.00012724\n",
            "Epoch 273, change: 0.00014042\n",
            "Epoch 240, change: 0.00047246\n",
            "Epoch 240, change: 0.00065156\n",
            "Epoch 241, change: 0.00051866\n",
            "Epoch 271, change: 0.00010356\n",
            "Epoch 239, change: 0.00091742\n",
            "Epoch 272, change: 0.00013554\n",
            "Epoch 272, change: 0.00016972\n",
            "Epoch 242, change: 0.00080151\n",
            "Epoch 241, change: 0.00056527\n",
            "Epoch 273, change: 0.00012553\n",
            "Epoch 274, change: 0.00013863\n",
            "Epoch 241, change: 0.00046895\n",
            "Epoch 241, change: 0.00064712\n",
            "Epoch 242, change: 0.00051511\n",
            "Epoch 272, change: 0.00010208\n",
            "Epoch 240, change: 0.00090527\n",
            "Epoch 273, change: 0.00016717\n",
            "Epoch 273, change: 0.00013374\n",
            "Epoch 243, change: 0.00079652\n",
            "Epoch 242, change: 0.00055970\n",
            "Epoch 274, change: 0.00012383\n",
            "Epoch 275, change: 0.00013685\n",
            "Epoch 242, change: 0.00046548\n",
            "Epoch 242, change: 0.00064163\n",
            "Epoch 243, change: 0.00051159\n",
            "Epoch 273, change: 0.00010060\n",
            "Epoch 274, change: 0.00016486\n",
            "Epoch 274, change: 0.00013198\n",
            "Epoch 241, change: 0.00089968\n",
            "Epoch 244, change: 0.00079052\n",
            "Epoch 243, change: 0.00055345\n",
            "Epoch 275, change: 0.00012217\n",
            "Epoch 276, change: 0.00013510\n",
            "Epoch 243, change: 0.00046198\n",
            "Epoch 243, change: 0.00063428\n",
            "convergence after 274 epochs took 288 seconds\n",
            "Epoch 244, change: 0.00050808\n",
            "Epoch 275, change: 0.00016255\n",
            "Epoch 275, change: 0.00013024\n",
            "Epoch 242, change: 0.00089275\n",
            "Epoch 245, change: 0.00078318\n",
            "\n",
            "Epoch 276, change: 0.00012053\n",
            "At iterate  100    f=  2.25728D-01    |proj g|=  9.29805D-04\n",
            "Epoch 244, change: 0.00054976\n",
            "Epoch 277, change: 0.00013338\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.41774D-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 244, change: 0.00045826\n",
            "Epoch 244, change: 0.00062913\n",
            "Epoch 276, change: 0.00016009\n",
            "Epoch 245, change: 0.00050461\n",
            "Epoch 276, change: 0.00012846\n",
            "Epoch 243, change: 0.00088433\n",
            "Epoch 246, change: 0.00077801\n",
            "Epoch 277, change: 0.00011889\n",
            "Epoch 245, change: 0.00054484\n",
            "Epoch 278, change: 0.00013167\n",
            "Epoch 245, change: 0.00045480\n",
            "Epoch 245, change: 0.00062315\n",
            "Epoch 277, change: 0.00015781\n",
            "Epoch 246, change: 0.00050116\n",
            "Epoch 277, change: 0.00012673\n",
            "Epoch 244, change: 0.00087555\n",
            "Epoch 247, change: 0.00077243\n",
            "Epoch 278, change: 0.00011729\n",
            "Epoch 246, change: 0.00053985\n",
            "Epoch 279, change: 0.00012999\n",
            "Epoch 246, change: 0.00045143\n",
            "Epoch 246, change: 0.00061805\n",
            "Epoch 278, change: 0.00015544\n",
            "Epoch 247, change: 0.00049775\n",
            "Epoch 278, change: 0.00012503\n",
            "Epoch 279, change: 0.00011571\n",
            "Epoch 245, change: 0.00086955\n",
            "Epoch 248, change: 0.00076674\n",
            "Epoch 280, change: 0.00012833\n",
            "Epoch 247, change: 0.00053603\n",
            "Epoch 247, change: 0.00044809\n",
            "Epoch 247, change: 0.00061238\n",
            "Epoch 279, change: 0.00015331\n",
            "Epoch 279, change: 0.00012333\n",
            "Epoch 248, change: 0.00049436\n",
            "Epoch 280, change: 0.00011415\n",
            "Epoch 246, change: 0.00086198\n",
            "Epoch 249, change: 0.00076146\n",
            "Epoch 281, change: 0.00012669\n",
            "Epoch 248, change: 0.00053078\n",
            "\n",
            "At iterate  150    f=  2.19493D-01    |proj g|=  2.73578D-04\n",
            "Epoch 248, change: 0.00044445\n",
            "Epoch 280, change: 0.00015104\n",
            "Epoch 248, change: 0.00060710\n",
            "\n",
            "At iterate   50    f=  2.49618D-01    |proj g|=  2.02680D-03\n",
            "Epoch 280, change: 0.00012170\n",
            "Epoch 281, change: 0.00011261\n",
            "Epoch 249, change: 0.00049093\n",
            "Epoch 247, change: 0.00085321\n",
            "Epoch 250, change: 0.00075419\n",
            "Epoch 282, change: 0.00012507\n",
            "Epoch 249, change: 0.00052740\n",
            "Epoch 281, change: 0.00014882\n",
            "Epoch 249, change: 0.00060228\n",
            "Epoch 249, change: 0.00044125\n",
            "Epoch 281, change: 0.00012010\n",
            "Epoch 282, change: 0.00011110\n",
            "Epoch 250, change: 0.00048762\n",
            "Epoch 248, change: 0.00084752\n",
            "Epoch 283, change: 0.00012347\n",
            "Epoch 251, change: 0.00074862\n",
            "Epoch 250, change: 0.00052216\n",
            "Epoch 282, change: 0.00014656\n",
            "Epoch 250, change: 0.00059619\n",
            "Epoch 282, change: 0.00011845\n",
            "Epoch 250, change: 0.00043798\n",
            "Epoch 283, change: 0.00010960\n",
            "Epoch 284, change: 0.00012190\n",
            "Epoch 249, change: 0.00083879\n",
            "Epoch 251, change: 0.00048427\n",
            "Epoch 252, change: 0.00074254\n",
            "Epoch 251, change: 0.00051881\n",
            "Epoch 283, change: 0.00014448\n",
            "Epoch 283, change: 0.00011687\n",
            "Epoch 251, change: 0.00059101\n",
            "Epoch 284, change: 0.00010813\n",
            "Epoch 251, change: 0.00043450\n",
            "Epoch 285, change: 0.00012033\n",
            "Epoch 252, change: 0.00048098\n",
            "Epoch 250, change: 0.00083256\n",
            "Epoch 253, change: 0.00073725\n",
            "Epoch 252, change: 0.00051335\n",
            "Epoch 284, change: 0.00014251\n",
            "\n",
            "At iterate  200    f=  2.17493D-01    |proj g|=  2.39255D-04\n",
            "Epoch 284, change: 0.00011532\n",
            "Epoch 285, change: 0.00010667\n",
            "Epoch 252, change: 0.00058567\n",
            "Epoch 252, change: 0.00043134\n",
            "Epoch 286, change: 0.00011879\n",
            "Epoch 251, change: 0.00082092\n",
            "Epoch 253, change: 0.00047767\n",
            "Epoch 254, change: 0.00073227\n",
            "\n",
            "At iterate  100    f=  2.28005D-01    |proj g|=  3.96574D-04\n",
            "Epoch 253, change: 0.00050930\n",
            "Epoch 285, change: 0.00014035\n",
            "Epoch 285, change: 0.00011377\n",
            "Epoch 286, change: 0.00010522\n",
            "Epoch 253, change: 0.00058069\n",
            "Epoch 253, change: 0.00042794\n",
            "Epoch 254, change: 0.00047444\n",
            "Epoch 252, change: 0.00081520\n",
            "Epoch 287, change: 0.00011728\n",
            "Epoch 255, change: 0.00072598\n",
            "Epoch 286, change: 0.00013825\n",
            "Epoch 254, change: 0.00050561\n",
            "Epoch 286, change: 0.00011226\n",
            "Epoch 287, change: 0.00010380\n",
            "Epoch 254, change: 0.00057524\n",
            "Epoch 254, change: 0.00042477\n",
            "Epoch 253, change: 0.00080810\n",
            "Epoch 288, change: 0.00011578\n",
            "Epoch 255, change: 0.00047118\n",
            "Epoch 287, change: 0.00013628\n",
            "Epoch 255, change: 0.00050025\n",
            "Epoch 256, change: 0.00072048\n",
            "Epoch 287, change: 0.00011077\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    236    244      1     0     0   8.997D-05   2.169D-01\n",
            "  F =  0.21691900493881494     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "Epoch 288, change: 0.00010241\n",
            "Epoch 255, change: 0.00057079\n",
            "Epoch 289, change: 0.00011430\n",
            "Epoch 255, change: 0.00042151\n",
            "Epoch 254, change: 0.00080003\n",
            "Epoch 256, change: 0.00046797\n",
            "Epoch 257, change: 0.00071561\n",
            "Epoch 256, change: 0.00049728\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.40563D-02\n",
            "Epoch 288, change: 0.00013431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 288, change: 0.00010933\n",
            "Epoch 256, change: 0.00056545\n",
            "Epoch 289, change: 0.00010103\n",
            "Epoch 290, change: 0.00011284\n",
            "Epoch 255, change: 0.00079277\n",
            "Epoch 256, change: 0.00041836\n",
            "Epoch 257, change: 0.00046478\n",
            "Epoch 258, change: 0.00070955\n",
            "Epoch 289, change: 0.00013234\n",
            "Epoch 257, change: 0.00049348\n",
            "\n",
            "At iterate  150    f=  2.21330D-01    |proj g|=  3.43288D-04\n",
            "Epoch 289, change: 0.00010784\n",
            "convergence after 290 epochs took 304 seconds\n",
            "Epoch 257, change: 0.00056039\n",
            "Epoch 291, change: 0.00011139\n",
            "Epoch 256, change: 0.00078548\n",
            "Epoch 257, change: 0.00041526\n",
            "Epoch 258, change: 0.00046162\n",
            "Epoch 259, change: 0.00070454\n",
            "Epoch 290, change: 0.00013046\n",
            "Epoch 258, change: 0.00048989\n",
            "Epoch 290, change: 0.00010637\n",
            "Epoch 292, change: 0.00010997\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.77256D-02\n",
            "Epoch 258, change: 0.00055583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 257, change: 0.00077890\n",
            "Epoch 258, change: 0.00041229\n",
            "Epoch 259, change: 0.00045846\n",
            "Epoch 291, change: 0.00012854\n",
            "Epoch 260, change: 0.00069936\n",
            "Epoch 259, change: 0.00048624\n",
            "Epoch 291, change: 0.00010495\n",
            "Epoch 293, change: 0.00010857\n",
            "Epoch 259, change: 0.00055089\n",
            "Epoch 258, change: 0.00077269\n",
            "\n",
            "At iterate   50    f=  2.57646D-01    |proj g|=  2.05869D-03\n",
            "Epoch 259, change: 0.00040909\n",
            "Epoch 260, change: 0.00045536\n",
            "Epoch 292, change: 0.00012672\n",
            "Epoch 261, change: 0.00069393\n",
            "Epoch 292, change: 0.00010352\n",
            "Epoch 260, change: 0.00048282\n",
            "Epoch 294, change: 0.00010718\n",
            "Epoch 260, change: 0.00054623\n",
            "Epoch 259, change: 0.00076063\n",
            "Epoch 260, change: 0.00040584\n",
            "Epoch 261, change: 0.00045223\n",
            "Epoch 293, change: 0.00012491\n",
            "Epoch 262, change: 0.00068864\n",
            "Epoch 293, change: 0.00010213\n",
            "Epoch 261, change: 0.00047944\n",
            "Epoch 295, change: 0.00010581\n",
            "\n",
            "At iterate  200    f=  2.19293D-01    |proj g|=  2.07331D-04\n",
            "Epoch 261, change: 0.00054052\n",
            "Epoch 260, change: 0.00075610\n",
            "Epoch 294, change: 0.00012303\n",
            "Epoch 261, change: 0.00040269\n",
            "Epoch 262, change: 0.00044917\n",
            "Epoch 263, change: 0.00068308\n",
            "Epoch 262, change: 0.00047617\n",
            "Epoch 294, change: 0.00010078\n",
            "Epoch 296, change: 0.00010445\n",
            "Epoch 262, change: 0.00053684\n",
            "Epoch 261, change: 0.00074924\n",
            "\n",
            "At iterate   50    f=  2.51174D-01    |proj g|=  8.43499D-04\n",
            "Epoch 295, change: 0.00012131\n",
            "Epoch 262, change: 0.00039984\n",
            "Epoch 263, change: 0.00044610\n",
            "Epoch 264, change: 0.00067825\n",
            "convergence after 295 epochs took 311 seconds\n",
            "Epoch 263, change: 0.00047217\n",
            "Epoch 297, change: 0.00010312\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    225    240      1     0     0   9.598D-05   2.189D-01\n",
            "  F =  0.21886837990007435     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "Epoch 263, change: 0.00053242\n",
            "Epoch 262, change: 0.00074257\n",
            "Epoch 296, change: 0.00011953\n",
            "Epoch 263, change: 0.00039669\n",
            "\n",
            "At iterate  100    f=  2.34153D-01    |proj g|=  5.74130D-04\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.75006D-02\n",
            "Epoch 264, change: 0.00044307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 265, change: 0.00067312\n",
            "Epoch 264, change: 0.00046931\n",
            "Epoch 298, change: 0.00010180\n",
            "RUNNING THE L-BFGS-B CODE\n",
            "\n",
            "           * * *\n",
            "\n",
            "Machine precision = 2.220D-16\n",
            " N =         7850     M =           10\n",
            "\n",
            "At X0         0 variables are exactly at the bounds\n",
            "\n",
            "At iterate    0    f=  2.30259D+00    |proj g|=  6.74506D-02\n",
            "Epoch 263, change: 0.00073657\n",
            "Epoch 297, change: 0.00011788\n",
            "Epoch 264, change: 0.00052770\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " This problem is unconstrained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 264, change: 0.00039378\n",
            "Epoch 265, change: 0.00044005\n",
            "Epoch 266, change: 0.00066836\n",
            "Epoch 265, change: 0.00046478\n",
            "Epoch 299, change: 0.00010050\n",
            "Epoch 298, change: 0.00011611\n",
            "Epoch 264, change: 0.00072931\n",
            "Epoch 265, change: 0.00052122\n",
            "Epoch 265, change: 0.00039093\n",
            "Epoch 266, change: 0.00043707\n",
            "Epoch 267, change: 0.00066345\n",
            "Epoch 266, change: 0.00046168\n",
            "convergence after 300 epochs took 315 seconds\n",
            "Epoch 299, change: 0.00011439\n",
            "\n",
            "At iterate  100    f=  2.30368D-01    |proj g|=  3.75305D-04\n",
            "Epoch 265, change: 0.00072073\n",
            "Epoch 266, change: 0.00051798\n",
            "Epoch 267, change: 0.00043408\n",
            "Epoch 266, change: 0.00038767\n",
            "Epoch 268, change: 0.00065833\n",
            "Epoch 267, change: 0.00045874\n",
            "Epoch 300, change: 0.00011278\n",
            "Epoch 267, change: 0.00051355\n",
            "Epoch 266, change: 0.00071608\n",
            "Epoch 267, change: 0.00038493\n",
            "Epoch 268, change: 0.00043114\n",
            "\n",
            "At iterate   50    f=  2.51098D-01    |proj g|=  1.17335D-03\n",
            "Epoch 269, change: 0.00065278\n",
            "Epoch 268, change: 0.00045493\n",
            "\n",
            "At iterate  150    f=  2.27741D-01    |proj g|=  8.60072D-04\n",
            "Epoch 301, change: 0.00011118\n",
            "Epoch 267, change: 0.00070699\n",
            "Epoch 268, change: 0.00050953\n",
            "Epoch 268, change: 0.00038192\n",
            "\n",
            "At iterate   50    f=  2.59041D-01    |proj g|=  1.61150D-03\n",
            "Epoch 269, change: 0.00042822\n",
            "Epoch 270, change: 0.00064821\n",
            "Epoch 269, change: 0.00045183\n",
            "Epoch 302, change: 0.00010953\n",
            "Epoch 268, change: 0.00070159\n",
            "Epoch 269, change: 0.00050511\n",
            "Epoch 269, change: 0.00037909\n",
            "Epoch 270, change: 0.00042531\n",
            "Epoch 271, change: 0.00064307\n",
            "Epoch 270, change: 0.00044854\n",
            "Epoch 303, change: 0.00010794\n",
            "Epoch 270, change: 0.00049872\n",
            "Epoch 269, change: 0.00069563\n",
            "Epoch 270, change: 0.00037620\n",
            "Epoch 271, change: 0.00042237\n",
            "Epoch 272, change: 0.00063841\n",
            "Epoch 271, change: 0.00044536\n",
            "\n",
            "At iterate  150    f=  2.24908D-01    |proj g|=  2.55051D-04\n",
            "Epoch 304, change: 0.00010637\n",
            "Epoch 271, change: 0.00049555\n",
            "Epoch 270, change: 0.00068877\n",
            "Epoch 271, change: 0.00037353\n",
            "Epoch 272, change: 0.00041954\n",
            "Epoch 273, change: 0.00063376\n",
            "Epoch 272, change: 0.00044222\n",
            "Epoch 305, change: 0.00010486\n",
            "\n",
            "At iterate  100    f=  2.30823D-01    |proj g|=  4.62179D-04\n",
            "Epoch 272, change: 0.00049191\n",
            "Epoch 271, change: 0.00068361\n",
            "Epoch 272, change: 0.00037051\n",
            "Epoch 273, change: 0.00041667\n",
            "\n",
            "At iterate  200    f=  2.25512D-01    |proj g|=  5.93379D-04\n",
            "Epoch 274, change: 0.00062931\n",
            "Epoch 273, change: 0.00043861\n",
            "Epoch 306, change: 0.00010336\n",
            "\n",
            "At iterate  100    f=  2.36663D-01    |proj g|=  4.59939D-04\n",
            "Epoch 273, change: 0.00048654\n",
            "Epoch 273, change: 0.00036787\n",
            "Epoch 274, change: 0.00041385\n",
            "Epoch 272, change: 0.00067472\n",
            "Epoch 274, change: 0.00043586\n",
            "Epoch 275, change: 0.00062454\n",
            "Epoch 307, change: 0.00010184\n",
            "Epoch 274, change: 0.00048290\n",
            "Epoch 274, change: 0.00036504\n",
            "Epoch 275, change: 0.00041104\n",
            "Epoch 273, change: 0.00066882\n",
            "Epoch 275, change: 0.00043294\n",
            "Epoch 276, change: 0.00061926\n",
            "Epoch 308, change: 0.00010039\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    226    236      1     0     0   9.580D-05   2.250D-01\n",
            "  F =  0.22501516174437450     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "Epoch 275, change: 0.00047788\n",
            "Epoch 274, change: 0.00066401\n",
            "Epoch 276, change: 0.00040826\n",
            "\n",
            "At iterate  200    f=  2.23098D-01    |proj g|=  7.30354D-04\n",
            "Epoch 275, change: 0.00036237\n",
            "Epoch 276, change: 0.00042841\n",
            "Epoch 277, change: 0.00061497\n",
            "convergence after 309 epochs took 326 seconds\n",
            "Epoch 277, change: 0.00040550\n",
            "Epoch 275, change: 0.00065736\n",
            "Epoch 276, change: 0.00035947\n",
            "Epoch 276, change: 0.00047415\n",
            "Epoch 277, change: 0.00042602\n",
            "Epoch 278, change: 0.00061098\n",
            "\n",
            "At iterate  150    f=  2.25270D-01    |proj g|=  2.46029D-04\n",
            "Epoch 278, change: 0.00040275\n",
            "Epoch 276, change: 0.00065063\n",
            "\n",
            "At iterate  150    f=  2.30723D-01    |proj g|=  3.15636D-04\n",
            "Epoch 277, change: 0.00035686\n",
            "Epoch 277, change: 0.00047045\n",
            "Epoch 278, change: 0.00042295\n",
            "Epoch 279, change: 0.00060545\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    231    240      1     0     0   8.468D-05   2.226D-01\n",
            "  F =  0.22261627156838107     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "Epoch 279, change: 0.00040003\n",
            "Epoch 277, change: 0.00064448\n",
            "Epoch 278, change: 0.00035420\n",
            "Epoch 278, change: 0.00046579\n",
            "Epoch 279, change: 0.00041988\n",
            "Epoch 280, change: 0.00060135\n",
            "Epoch 280, change: 0.00039728\n",
            "Epoch 278, change: 0.00063947\n",
            "Epoch 279, change: 0.00035151\n",
            "Epoch 279, change: 0.00046247\n",
            "Epoch 280, change: 0.00041685\n",
            "Epoch 281, change: 0.00059717\n",
            "Epoch 281, change: 0.00039459\n",
            "Epoch 279, change: 0.00063311\n",
            "Epoch 280, change: 0.00034884\n",
            "Epoch 280, change: 0.00045740\n",
            "Epoch 281, change: 0.00041420\n",
            "Epoch 282, change: 0.00059220\n",
            "Epoch 282, change: 0.00039191\n",
            "Epoch 280, change: 0.00062760\n",
            "\n",
            "At iterate  200    f=  2.23443D-01    |proj g|=  1.24995D-04\n",
            "Epoch 281, change: 0.00034619\n",
            "Epoch 281, change: 0.00045381\n",
            "Epoch 282, change: 0.00040982\n",
            "Epoch 283, change: 0.00058808\n",
            "\n",
            "At iterate  200    f=  2.28983D-01    |proj g|=  1.57403D-04\n",
            "Epoch 283, change: 0.00038925\n",
            "Epoch 281, change: 0.00062075\n",
            "Epoch 282, change: 0.00034373\n",
            "Epoch 282, change: 0.00044968\n",
            "Epoch 283, change: 0.00040720\n",
            "Epoch 284, change: 0.00058375\n",
            "Epoch 284, change: 0.00038661\n",
            "Epoch 282, change: 0.00061576\n",
            "Epoch 283, change: 0.00034112\n",
            "Epoch 283, change: 0.00044634\n",
            "Epoch 284, change: 0.00040451\n",
            "Epoch 285, change: 0.00057875\n",
            "Epoch 285, change: 0.00038399\n",
            "Epoch 283, change: 0.00061092\n",
            "Epoch 284, change: 0.00033835\n",
            "Epoch 284, change: 0.00044196\n",
            "Epoch 285, change: 0.00040142\n",
            "Epoch 286, change: 0.00057466\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    237    255      1     0     0   9.772D-05   2.229D-01\n",
            "  F =  0.22288823377694297     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "Epoch 286, change: 0.00038139\n",
            "Epoch 284, change: 0.00060625\n",
            "Epoch 285, change: 0.00033595\n",
            "Epoch 285, change: 0.00043846\n",
            "Epoch 286, change: 0.00039861\n",
            "Epoch 287, change: 0.00057096\n",
            "\n",
            "           * * *\n",
            "\n",
            "Tit   = total number of iterations\n",
            "Tnf   = total number of function evaluations\n",
            "Tnint = total number of segments explored during Cauchy searches\n",
            "Skip  = number of BFGS updates skipped\n",
            "Nact  = number of active bounds at final generalized Cauchy point\n",
            "Projg = norm of the final projected gradient\n",
            "F     = final function value\n",
            "\n",
            "           * * *\n",
            "\n",
            "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
            " 7850    246    261      1     0     0   9.073D-05   2.284D-01\n",
            "  F =  0.22837426555392010     \n",
            "\n",
            "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
            "Epoch 287, change: 0.00037880\n",
            "Epoch 285, change: 0.00059975\n",
            "Epoch 286, change: 0.00043432\n",
            "Epoch 286, change: 0.00033338\n",
            "Epoch 287, change: 0.00039542\n",
            "Epoch 288, change: 0.00056654\n",
            "Epoch 288, change: 0.00037623\n",
            "Epoch 286, change: 0.00059234\n",
            "Epoch 287, change: 0.00043061\n",
            "Epoch 287, change: 0.00033088\n",
            "Epoch 288, change: 0.00039270\n",
            "Epoch 289, change: 0.00056188\n",
            "Epoch 289, change: 0.00037370\n",
            "Epoch 287, change: 0.00058905\n",
            "Epoch 288, change: 0.00032832\n",
            "Epoch 288, change: 0.00042691\n",
            "Epoch 289, change: 0.00038951\n",
            "Epoch 290, change: 0.00055807\n",
            "Epoch 290, change: 0.00037116\n",
            "Epoch 288, change: 0.00058290\n",
            "Epoch 289, change: 0.00032590\n",
            "Epoch 289, change: 0.00042350\n",
            "Epoch 290, change: 0.00038700\n",
            "Epoch 291, change: 0.00055354\n",
            "Epoch 291, change: 0.00036866\n",
            "Epoch 289, change: 0.00057857\n",
            "Epoch 290, change: 0.00032359\n",
            "Epoch 290, change: 0.00041962\n",
            "Epoch 291, change: 0.00038393\n",
            "Epoch 292, change: 0.00054931\n",
            "Epoch 292, change: 0.00036614\n",
            "Epoch 290, change: 0.00057307\n",
            "Epoch 291, change: 0.00032105\n",
            "Epoch 291, change: 0.00041591\n",
            "Epoch 292, change: 0.00038153\n",
            "Epoch 293, change: 0.00054563\n",
            "Epoch 293, change: 0.00036369\n",
            "Epoch 291, change: 0.00056559\n",
            "Epoch 292, change: 0.00031873\n",
            "Epoch 292, change: 0.00041231\n",
            "Epoch 293, change: 0.00037892\n",
            "Epoch 294, change: 0.00054185\n",
            "Epoch 294, change: 0.00036120\n",
            "Epoch 292, change: 0.00056158\n",
            "Epoch 293, change: 0.00031641\n",
            "Epoch 293, change: 0.00040899\n",
            "Epoch 294, change: 0.00037570\n",
            "Epoch 295, change: 0.00053684\n",
            "Epoch 295, change: 0.00035876\n",
            "Epoch 293, change: 0.00055628\n",
            "Epoch 294, change: 0.00031413\n",
            "Epoch 294, change: 0.00040503\n",
            "Epoch 295, change: 0.00037283\n",
            "Epoch 296, change: 0.00053354\n",
            "Epoch 296, change: 0.00035634\n",
            "Epoch 294, change: 0.00055169\n",
            "Epoch 295, change: 0.00031186\n",
            "Epoch 295, change: 0.00040197\n",
            "Epoch 296, change: 0.00036983\n",
            "Epoch 297, change: 0.00052915\n",
            "Epoch 297, change: 0.00035393\n",
            "Epoch 295, change: 0.00054694\n",
            "Epoch 296, change: 0.00030962\n",
            "Epoch 296, change: 0.00039822\n",
            "Epoch 297, change: 0.00036739\n",
            "Epoch 298, change: 0.00052555\n",
            "Epoch 298, change: 0.00035153\n",
            "Epoch 296, change: 0.00054029\n",
            "Epoch 297, change: 0.00030739\n",
            "Epoch 298, change: 0.00036475\n",
            "Epoch 297, change: 0.00039489\n",
            "Epoch 299, change: 0.00052135\n",
            "Epoch 299, change: 0.00034917\n",
            "Epoch 297, change: 0.00053647\n",
            "Epoch 298, change: 0.00030516\n",
            "Epoch 299, change: 0.00036215\n",
            "Epoch 298, change: 0.00039183\n",
            "Epoch 300, change: 0.00051774\n",
            "Epoch 300, change: 0.00034679\n",
            "Epoch 298, change: 0.00053184\n",
            "Epoch 299, change: 0.00030297\n",
            "Epoch 300, change: 0.00035910\n",
            "Epoch 299, change: 0.00038856\n",
            "Epoch 301, change: 0.00051392\n",
            "Epoch 301, change: 0.00034445\n",
            "Epoch 299, change: 0.00052581\n",
            "Epoch 301, change: 0.00035703\n",
            "Epoch 300, change: 0.00030077\n",
            "Epoch 300, change: 0.00038441\n",
            "Epoch 302, change: 0.00051006\n",
            "Epoch 302, change: 0.00034213\n",
            "Epoch 300, change: 0.00052249\n",
            "Epoch 302, change: 0.00035417\n",
            "Epoch 301, change: 0.00029861\n",
            "Epoch 301, change: 0.00038137\n",
            "Epoch 303, change: 0.00050661\n",
            "Epoch 303, change: 0.00033981\n",
            "Epoch 301, change: 0.00051693\n",
            "Epoch 303, change: 0.00035166\n",
            "Epoch 302, change: 0.00029646\n",
            "Epoch 302, change: 0.00037801\n",
            "Epoch 304, change: 0.00050229\n",
            "Epoch 304, change: 0.00033751\n",
            "Epoch 302, change: 0.00051222\n",
            "Epoch 304, change: 0.00034936\n",
            "Epoch 303, change: 0.00029432\n",
            "Epoch 303, change: 0.00037477\n",
            "Epoch 305, change: 0.00049885\n",
            "Epoch 305, change: 0.00033524\n",
            "Epoch 303, change: 0.00050744\n",
            "Epoch 305, change: 0.00034620\n",
            "Epoch 304, change: 0.00029221\n",
            "Epoch 304, change: 0.00037185\n",
            "Epoch 306, change: 0.00049531\n",
            "Epoch 306, change: 0.00033299\n",
            "Epoch 304, change: 0.00050368\n",
            "Epoch 306, change: 0.00034413\n",
            "Epoch 305, change: 0.00029010\n",
            "Epoch 305, change: 0.00036821\n",
            "Epoch 307, change: 0.00049130\n",
            "Epoch 307, change: 0.00033071\n",
            "Epoch 305, change: 0.00049897\n",
            "Epoch 307, change: 0.00034138\n",
            "Epoch 306, change: 0.00028802\n",
            "Epoch 306, change: 0.00036537\n",
            "Epoch 308, change: 0.00048796\n",
            "Epoch 306, change: 0.00049397\n",
            "Epoch 308, change: 0.00032849\n",
            "Epoch 308, change: 0.00033861\n",
            "Epoch 307, change: 0.00028595\n",
            "Epoch 307, change: 0.00036186\n",
            "Epoch 309, change: 0.00048447\n",
            "Epoch 307, change: 0.00049045\n",
            "Epoch 309, change: 0.00032628\n",
            "Epoch 309, change: 0.00033648\n",
            "Epoch 308, change: 0.00028388\n",
            "Epoch 308, change: 0.00035889\n",
            "Epoch 310, change: 0.00048064\n",
            "Epoch 308, change: 0.00048668\n",
            "Epoch 310, change: 0.00032405\n",
            "Epoch 310, change: 0.00033355\n",
            "Epoch 309, change: 0.00028184\n",
            "Epoch 309, change: 0.00035620\n",
            "Epoch 311, change: 0.00047707\n",
            "Epoch 309, change: 0.00047914\n",
            "Epoch 311, change: 0.00032188\n",
            "Epoch 311, change: 0.00033129\n",
            "Epoch 310, change: 0.00027981\n",
            "Epoch 310, change: 0.00035333\n",
            "Epoch 312, change: 0.00047379\n",
            "Epoch 310, change: 0.00047656\n",
            "Epoch 312, change: 0.00031970\n",
            "Epoch 312, change: 0.00032912\n",
            "Epoch 311, change: 0.00027780\n",
            "Epoch 311, change: 0.00035021\n",
            "Epoch 313, change: 0.00047034\n",
            "Epoch 311, change: 0.00047286\n",
            "Epoch 313, change: 0.00031755\n",
            "Epoch 313, change: 0.00032665\n",
            "Epoch 312, change: 0.00027580\n",
            "Epoch 312, change: 0.00034613\n",
            "Epoch 314, change: 0.00046623\n",
            "Epoch 312, change: 0.00046787\n",
            "Epoch 314, change: 0.00031540\n",
            "Epoch 314, change: 0.00032416\n",
            "Epoch 313, change: 0.00027382\n",
            "Epoch 313, change: 0.00034376\n",
            "Epoch 315, change: 0.00046298\n",
            "Epoch 313, change: 0.00046272\n",
            "Epoch 315, change: 0.00031328\n",
            "Epoch 315, change: 0.00032187\n",
            "Epoch 314, change: 0.00027185\n",
            "Epoch 314, change: 0.00034099\n",
            "Epoch 316, change: 0.00045954\n",
            "Epoch 314, change: 0.00045971\n",
            "Epoch 316, change: 0.00031117\n",
            "Epoch 316, change: 0.00031961\n",
            "Epoch 315, change: 0.00026990\n",
            "Epoch 315, change: 0.00033839\n",
            "Epoch 317, change: 0.00045620\n",
            "Epoch 315, change: 0.00045452\n",
            "Epoch 317, change: 0.00030908\n",
            "Epoch 317, change: 0.00031743\n",
            "Epoch 316, change: 0.00026795\n",
            "Epoch 316, change: 0.00033457\n",
            "Epoch 318, change: 0.00045305\n",
            "Epoch 316, change: 0.00045136\n",
            "Epoch 318, change: 0.00030696\n",
            "Epoch 318, change: 0.00031493\n",
            "Epoch 317, change: 0.00026603\n",
            "Epoch 317, change: 0.00033248\n",
            "Epoch 319, change: 0.00044946\n",
            "Epoch 317, change: 0.00044765\n",
            "Epoch 319, change: 0.00030491\n",
            "Epoch 319, change: 0.00031187\n",
            "Epoch 318, change: 0.00026413\n",
            "Epoch 318, change: 0.00032983\n",
            "Epoch 320, change: 0.00044635\n",
            "Epoch 318, change: 0.00044325\n",
            "Epoch 320, change: 0.00030286\n",
            "Epoch 320, change: 0.00030998\n",
            "Epoch 319, change: 0.00026222\n",
            "Epoch 319, change: 0.00032605\n",
            "Epoch 321, change: 0.00044274\n",
            "Epoch 319, change: 0.00043905\n",
            "Epoch 321, change: 0.00030782\n",
            "Epoch 321, change: 0.00030081\n",
            "Epoch 320, change: 0.00026035\n",
            "Epoch 320, change: 0.00032360\n",
            "Epoch 322, change: 0.00043998\n",
            "Epoch 320, change: 0.00043551\n",
            "Epoch 322, change: 0.00030572\n",
            "Epoch 322, change: 0.00029878\n",
            "Epoch 321, change: 0.00025849\n",
            "Epoch 321, change: 0.00032091\n",
            "Epoch 323, change: 0.00043664\n",
            "Epoch 321, change: 0.00043057\n",
            "Epoch 323, change: 0.00030321\n",
            "Epoch 323, change: 0.00029677\n",
            "Epoch 322, change: 0.00025660\n",
            "Epoch 322, change: 0.00031832\n",
            "Epoch 324, change: 0.00043300\n",
            "Epoch 322, change: 0.00042733\n",
            "Epoch 324, change: 0.00030095\n",
            "Epoch 324, change: 0.00029477\n",
            "Epoch 323, change: 0.00025478\n",
            "Epoch 323, change: 0.00031507\n",
            "Epoch 325, change: 0.00043021\n",
            "Epoch 323, change: 0.00042358\n",
            "Epoch 325, change: 0.00029894\n",
            "Epoch 325, change: 0.00029278\n",
            "Epoch 324, change: 0.00025295\n",
            "Epoch 324, change: 0.00031281\n",
            "Epoch 326, change: 0.00042663\n",
            "Epoch 324, change: 0.00041974\n",
            "Epoch 326, change: 0.00029696\n",
            "Epoch 326, change: 0.00029082\n",
            "Epoch 325, change: 0.00025114\n",
            "Epoch 325, change: 0.00030996\n",
            "Epoch 327, change: 0.00042365\n",
            "Epoch 325, change: 0.00041595\n",
            "Epoch 327, change: 0.00029434\n",
            "Epoch 327, change: 0.00028886\n",
            "Epoch 326, change: 0.00024934\n",
            "Epoch 326, change: 0.00030746\n",
            "Epoch 328, change: 0.00042067\n",
            "Epoch 328, change: 0.00029233\n",
            "Epoch 326, change: 0.00041262\n",
            "Epoch 328, change: 0.00028693\n",
            "Epoch 327, change: 0.00024754\n",
            "Epoch 327, change: 0.00030459\n",
            "Epoch 329, change: 0.00041763\n",
            "Epoch 329, change: 0.00029039\n",
            "Epoch 327, change: 0.00040815\n",
            "Epoch 329, change: 0.00028497\n",
            "Epoch 328, change: 0.00024576\n",
            "Epoch 328, change: 0.00030205\n",
            "Epoch 330, change: 0.00041448\n",
            "Epoch 330, change: 0.00028836\n",
            "Epoch 328, change: 0.00040587\n",
            "Epoch 330, change: 0.00028305\n",
            "Epoch 329, change: 0.00024401\n",
            "Epoch 329, change: 0.00029986\n",
            "Epoch 331, change: 0.00041158\n",
            "Epoch 331, change: 0.00028650\n",
            "Epoch 329, change: 0.00040030\n",
            "Epoch 331, change: 0.00028114\n",
            "Epoch 330, change: 0.00024225\n",
            "Epoch 330, change: 0.00029724\n",
            "Epoch 332, change: 0.00040886\n",
            "Epoch 332, change: 0.00028464\n",
            "Epoch 330, change: 0.00039701\n",
            "Epoch 332, change: 0.00027926\n",
            "Epoch 331, change: 0.00024051\n",
            "Epoch 331, change: 0.00029420\n",
            "Epoch 333, change: 0.00040523\n",
            "Epoch 333, change: 0.00028282\n",
            "Epoch 331, change: 0.00039427\n",
            "Epoch 333, change: 0.00027737\n",
            "Epoch 332, change: 0.00023880\n",
            "Epoch 332, change: 0.00029196\n",
            "Epoch 334, change: 0.00040252\n",
            "Epoch 334, change: 0.00028099\n",
            "Epoch 332, change: 0.00039015\n",
            "Epoch 334, change: 0.00027551\n",
            "Epoch 333, change: 0.00023708\n",
            "Epoch 333, change: 0.00028953\n",
            "Epoch 335, change: 0.00039950\n",
            "Epoch 335, change: 0.00027918\n",
            "Epoch 333, change: 0.00038736\n",
            "Epoch 335, change: 0.00027364\n",
            "Epoch 334, change: 0.00023538\n",
            "Epoch 334, change: 0.00028730\n",
            "Epoch 336, change: 0.00039660\n",
            "Epoch 336, change: 0.00027740\n",
            "Epoch 334, change: 0.00038346\n",
            "Epoch 336, change: 0.00027182\n",
            "Epoch 335, change: 0.00023369\n",
            "Epoch 335, change: 0.00028427\n",
            "Epoch 337, change: 0.00039340\n",
            "Epoch 337, change: 0.00027561\n",
            "Epoch 335, change: 0.00038105\n",
            "Epoch 337, change: 0.00026999\n",
            "Epoch 336, change: 0.00023202\n",
            "Epoch 336, change: 0.00028228\n",
            "Epoch 338, change: 0.00039074\n",
            "Epoch 338, change: 0.00027383\n",
            "Epoch 336, change: 0.00037636\n",
            "Epoch 338, change: 0.00026818\n",
            "Epoch 337, change: 0.00023035\n",
            "Epoch 337, change: 0.00027969\n",
            "Epoch 339, change: 0.00038791\n",
            "Epoch 339, change: 0.00027208\n",
            "Epoch 337, change: 0.00037313\n",
            "Epoch 339, change: 0.00026638\n",
            "Epoch 338, change: 0.00022871\n",
            "Epoch 338, change: 0.00027747\n",
            "Epoch 340, change: 0.00038515\n",
            "Epoch 340, change: 0.00027032\n",
            "Epoch 338, change: 0.00037014\n",
            "Epoch 340, change: 0.00026455\n",
            "Epoch 339, change: 0.00022707\n",
            "Epoch 339, change: 0.00027484\n",
            "Epoch 341, change: 0.00038206\n",
            "Epoch 341, change: 0.00026860\n",
            "Epoch 339, change: 0.00036743\n",
            "Epoch 341, change: 0.00026279\n",
            "Epoch 340, change: 0.00022544\n",
            "Epoch 340, change: 0.00027253\n",
            "Epoch 342, change: 0.00037943\n",
            "Epoch 342, change: 0.00026687\n",
            "Epoch 340, change: 0.00036316\n",
            "Epoch 342, change: 0.00026101\n",
            "Epoch 341, change: 0.00022383\n",
            "Epoch 341, change: 0.00027016\n",
            "Epoch 343, change: 0.00037667\n",
            "Epoch 343, change: 0.00026515\n",
            "Epoch 341, change: 0.00036066\n",
            "Epoch 343, change: 0.00025926\n",
            "Epoch 342, change: 0.00022222\n",
            "Epoch 342, change: 0.00026792\n",
            "Epoch 344, change: 0.00037389\n",
            "Epoch 344, change: 0.00026345\n",
            "Epoch 342, change: 0.00035720\n",
            "Epoch 344, change: 0.00025751\n",
            "Epoch 343, change: 0.00022063\n",
            "Epoch 345, change: 0.00037120\n",
            "Epoch 343, change: 0.00026563\n",
            "Epoch 345, change: 0.00026175\n",
            "Epoch 343, change: 0.00035495\n",
            "Epoch 345, change: 0.00025579\n",
            "Epoch 344, change: 0.00021905\n",
            "Epoch 346, change: 0.00036854\n",
            "Epoch 344, change: 0.00026364\n",
            "Epoch 346, change: 0.00026008\n",
            "Epoch 344, change: 0.00034956\n",
            "Epoch 346, change: 0.00025406\n",
            "Epoch 345, change: 0.00021749\n",
            "Epoch 347, change: 0.00036586\n",
            "Epoch 345, change: 0.00026096\n",
            "Epoch 347, change: 0.00025841\n",
            "Epoch 345, change: 0.00034789\n",
            "Epoch 347, change: 0.00025235\n",
            "Epoch 346, change: 0.00021592\n",
            "Epoch 348, change: 0.00036336\n",
            "Epoch 346, change: 0.00025887\n",
            "Epoch 348, change: 0.00025675\n",
            "Epoch 346, change: 0.00034457\n",
            "Epoch 348, change: 0.00025065\n",
            "Epoch 347, change: 0.00021438\n",
            "Epoch 349, change: 0.00036044\n",
            "Epoch 347, change: 0.00025680\n",
            "Epoch 349, change: 0.00025511\n",
            "Epoch 347, change: 0.00034209\n",
            "Epoch 349, change: 0.00024897\n",
            "Epoch 348, change: 0.00021284\n",
            "Epoch 350, change: 0.00035757\n",
            "Epoch 348, change: 0.00025453\n",
            "Epoch 350, change: 0.00025346\n",
            "Epoch 348, change: 0.00033817\n",
            "Epoch 350, change: 0.00024730\n",
            "Epoch 349, change: 0.00021132\n",
            "Epoch 351, change: 0.00035502\n",
            "Epoch 349, change: 0.00025229\n",
            "Epoch 351, change: 0.00025184\n",
            "Epoch 349, change: 0.00033498\n",
            "Epoch 351, change: 0.00024563\n",
            "Epoch 350, change: 0.00020980\n",
            "Epoch 352, change: 0.00035250\n",
            "Epoch 350, change: 0.00025035\n",
            "Epoch 352, change: 0.00025023\n",
            "Epoch 350, change: 0.00033241\n",
            "Epoch 352, change: 0.00024398\n",
            "Epoch 351, change: 0.00020831\n",
            "Epoch 353, change: 0.00035010\n",
            "Epoch 351, change: 0.00024794\n",
            "Epoch 353, change: 0.00024862\n",
            "Epoch 351, change: 0.00032975\n",
            "Epoch 353, change: 0.00024234\n",
            "Epoch 352, change: 0.00020683\n",
            "Epoch 354, change: 0.00034740\n",
            "Epoch 352, change: 0.00024610\n",
            "Epoch 354, change: 0.00024703\n",
            "Epoch 352, change: 0.00032701\n",
            "Epoch 354, change: 0.00024071\n",
            "Epoch 353, change: 0.00020533\n",
            "Epoch 355, change: 0.00034503\n",
            "Epoch 353, change: 0.00024382\n",
            "Epoch 355, change: 0.00024544\n",
            "Epoch 353, change: 0.00032290\n",
            "Epoch 355, change: 0.00023910\n",
            "Epoch 354, change: 0.00020386\n",
            "Epoch 356, change: 0.00034249\n",
            "Epoch 354, change: 0.00024192\n",
            "Epoch 356, change: 0.00024387\n",
            "Epoch 354, change: 0.00032067\n",
            "Epoch 356, change: 0.00023748\n",
            "Epoch 355, change: 0.00020241\n",
            "Epoch 357, change: 0.00034000\n",
            "Epoch 355, change: 0.00023966\n",
            "Epoch 357, change: 0.00024231\n",
            "Epoch 355, change: 0.00031870\n",
            "Epoch 357, change: 0.00023590\n",
            "Epoch 356, change: 0.00020096\n",
            "Epoch 358, change: 0.00033742\n",
            "Epoch 356, change: 0.00023764\n",
            "Epoch 358, change: 0.00024076\n",
            "Epoch 356, change: 0.00031458\n",
            "Epoch 358, change: 0.00023430\n",
            "Epoch 357, change: 0.00019952\n",
            "Epoch 359, change: 0.00033473\n",
            "Epoch 357, change: 0.00023581\n",
            "Epoch 359, change: 0.00023921\n",
            "Epoch 357, change: 0.00031241\n",
            "Epoch 359, change: 0.00023273\n",
            "Epoch 358, change: 0.00019810\n",
            "Epoch 360, change: 0.00033239\n",
            "Epoch 358, change: 0.00023390\n",
            "Epoch 360, change: 0.00023767\n",
            "Epoch 358, change: 0.00030958\n",
            "Epoch 360, change: 0.00023117\n",
            "Epoch 359, change: 0.00019668\n",
            "Epoch 361, change: 0.00033004\n",
            "Epoch 359, change: 0.00023173\n",
            "Epoch 361, change: 0.00023617\n",
            "Epoch 359, change: 0.00030707\n",
            "Epoch 361, change: 0.00022962\n",
            "Epoch 360, change: 0.00019528\n",
            "Epoch 362, change: 0.00032774\n",
            "Epoch 360, change: 0.00022967\n",
            "Epoch 362, change: 0.00023465\n",
            "Epoch 360, change: 0.00030453\n",
            "Epoch 362, change: 0.00022809\n",
            "Epoch 361, change: 0.00019388\n",
            "Epoch 363, change: 0.00032509\n",
            "Epoch 361, change: 0.00022792\n",
            "Epoch 363, change: 0.00023315\n",
            "Epoch 361, change: 0.00030209\n",
            "Epoch 363, change: 0.00022654\n",
            "Epoch 362, change: 0.00019248\n",
            "Epoch 364, change: 0.00032280\n",
            "Epoch 362, change: 0.00022591\n",
            "Epoch 364, change: 0.00023165\n",
            "Epoch 362, change: 0.00029942\n",
            "Epoch 364, change: 0.00022502\n",
            "Epoch 363, change: 0.00019111\n",
            "Epoch 365, change: 0.00032041\n",
            "Epoch 363, change: 0.00022434\n",
            "Epoch 365, change: 0.00023016\n",
            "Epoch 363, change: 0.00029709\n",
            "Epoch 365, change: 0.00022351\n",
            "Epoch 364, change: 0.00018975\n",
            "Epoch 366, change: 0.00031818\n",
            "Epoch 364, change: 0.00022250\n",
            "Epoch 366, change: 0.00022871\n",
            "Epoch 364, change: 0.00029343\n",
            "Epoch 366, change: 0.00022201\n",
            "Epoch 365, change: 0.00018839\n",
            "Epoch 367, change: 0.00031571\n",
            "Epoch 365, change: 0.00022072\n",
            "Epoch 367, change: 0.00022724\n",
            "Epoch 365, change: 0.00029069\n",
            "Epoch 367, change: 0.00022052\n",
            "Epoch 366, change: 0.00018704\n",
            "Epoch 368, change: 0.00031356\n",
            "Epoch 366, change: 0.00021873\n",
            "Epoch 368, change: 0.00022579\n",
            "Epoch 366, change: 0.00028887\n",
            "Epoch 368, change: 0.00021904\n",
            "Epoch 367, change: 0.00018571\n",
            "Epoch 369, change: 0.00031121\n",
            "Epoch 367, change: 0.00021599\n",
            "Epoch 369, change: 0.00022433\n",
            "Epoch 367, change: 0.00028576\n",
            "Epoch 369, change: 0.00021757\n",
            "Epoch 368, change: 0.00018438\n",
            "Epoch 370, change: 0.00030898\n",
            "Epoch 368, change: 0.00021476\n",
            "Epoch 370, change: 0.00022291\n",
            "Epoch 368, change: 0.00028337\n",
            "Epoch 370, change: 0.00021612\n",
            "Epoch 369, change: 0.00018307\n",
            "Epoch 371, change: 0.00030658\n",
            "Epoch 369, change: 0.00021274\n",
            "Epoch 371, change: 0.00022148\n",
            "Epoch 369, change: 0.00028063\n",
            "Epoch 371, change: 0.00021467\n",
            "Epoch 370, change: 0.00018175\n",
            "Epoch 372, change: 0.00030445\n",
            "Epoch 370, change: 0.00021112\n",
            "Epoch 372, change: 0.00022007\n",
            "Epoch 370, change: 0.00027840\n",
            "Epoch 372, change: 0.00021324\n",
            "Epoch 373, change: 0.00030223\n",
            "Epoch 371, change: 0.00018046\n",
            "Epoch 371, change: 0.00020920\n",
            "Epoch 373, change: 0.00021865\n",
            "Epoch 371, change: 0.00027585\n",
            "Epoch 373, change: 0.00021181\n",
            "Epoch 374, change: 0.00030004\n",
            "Epoch 372, change: 0.00017918\n",
            "Epoch 372, change: 0.00020761\n",
            "Epoch 374, change: 0.00021727\n",
            "Epoch 372, change: 0.00027405\n",
            "Epoch 374, change: 0.00021035\n",
            "Epoch 375, change: 0.00029797\n",
            "Epoch 373, change: 0.00017788\n",
            "Epoch 373, change: 0.00020586\n",
            "Epoch 375, change: 0.00021587\n",
            "Epoch 373, change: 0.00027154\n",
            "Epoch 375, change: 0.00020895\n",
            "Epoch 376, change: 0.00029567\n",
            "Epoch 374, change: 0.00017662\n",
            "Epoch 374, change: 0.00020391\n",
            "Epoch 376, change: 0.00021449\n",
            "Epoch 374, change: 0.00026960\n",
            "Epoch 376, change: 0.00020756\n",
            "Epoch 377, change: 0.00029373\n",
            "Epoch 375, change: 0.00017537\n",
            "Epoch 375, change: 0.00020216\n",
            "Epoch 377, change: 0.00021313\n",
            "Epoch 375, change: 0.00026588\n",
            "Epoch 377, change: 0.00020615\n",
            "Epoch 378, change: 0.00029146\n",
            "Epoch 376, change: 0.00017410\n",
            "Epoch 376, change: 0.00020067\n",
            "Epoch 378, change: 0.00021176\n",
            "Epoch 376, change: 0.00026390\n",
            "Epoch 378, change: 0.00020478\n",
            "Epoch 379, change: 0.00028911\n",
            "Epoch 377, change: 0.00017286\n",
            "Epoch 377, change: 0.00019887\n",
            "Epoch 379, change: 0.00021041\n",
            "Epoch 377, change: 0.00026213\n",
            "Epoch 379, change: 0.00020341\n",
            "Epoch 380, change: 0.00028714\n",
            "Epoch 378, change: 0.00017163\n",
            "Epoch 378, change: 0.00019712\n",
            "Epoch 380, change: 0.00020906\n",
            "Epoch 378, change: 0.00025955\n",
            "Epoch 380, change: 0.00020203\n",
            "Epoch 381, change: 0.00028509\n",
            "Epoch 379, change: 0.00017040\n",
            "Epoch 379, change: 0.00019549\n",
            "Epoch 381, change: 0.00020773\n",
            "Epoch 379, change: 0.00025768\n",
            "Epoch 381, change: 0.00020069\n",
            "Epoch 382, change: 0.00028302\n",
            "Epoch 380, change: 0.00016919\n",
            "Epoch 380, change: 0.00019399\n",
            "Epoch 382, change: 0.00020641\n",
            "Epoch 380, change: 0.00025533\n",
            "Epoch 382, change: 0.00019933\n",
            "Epoch 383, change: 0.00028100\n",
            "Epoch 381, change: 0.00016797\n",
            "Epoch 381, change: 0.00019222\n",
            "Epoch 383, change: 0.00020509\n",
            "Epoch 381, change: 0.00025301\n",
            "Epoch 383, change: 0.00019799\n",
            "Epoch 384, change: 0.00027888\n",
            "Epoch 382, change: 0.00016678\n",
            "Epoch 382, change: 0.00019076\n",
            "Epoch 384, change: 0.00020378\n",
            "Epoch 382, change: 0.00025023\n",
            "Epoch 384, change: 0.00019667\n",
            "Epoch 385, change: 0.00027693\n",
            "Epoch 383, change: 0.00016560\n",
            "Epoch 383, change: 0.00018881\n",
            "Epoch 385, change: 0.00020248\n",
            "Epoch 383, change: 0.00024849\n",
            "Epoch 385, change: 0.00019535\n",
            "Epoch 386, change: 0.00027490\n",
            "Epoch 384, change: 0.00016440\n",
            "Epoch 384, change: 0.00018736\n",
            "Epoch 386, change: 0.00020118\n",
            "Epoch 384, change: 0.00024634\n",
            "Epoch 386, change: 0.00019404\n",
            "Epoch 387, change: 0.00027282\n",
            "Epoch 385, change: 0.00016324\n",
            "Epoch 385, change: 0.00018588\n",
            "Epoch 387, change: 0.00019991\n",
            "Epoch 385, change: 0.00024456\n",
            "Epoch 387, change: 0.00019274\n",
            "Epoch 388, change: 0.00027101\n",
            "Epoch 386, change: 0.00016206\n",
            "Epoch 386, change: 0.00018419\n",
            "Epoch 388, change: 0.00019863\n",
            "Epoch 386, change: 0.00024116\n",
            "Epoch 388, change: 0.00019145\n",
            "Epoch 389, change: 0.00026919\n",
            "Epoch 387, change: 0.00016091\n",
            "Epoch 387, change: 0.00018278\n",
            "Epoch 389, change: 0.00019736\n",
            "Epoch 387, change: 0.00024016\n",
            "Epoch 389, change: 0.00019017\n",
            "Epoch 390, change: 0.00026700\n",
            "Epoch 388, change: 0.00015975\n",
            "Epoch 388, change: 0.00018110\n",
            "Epoch 390, change: 0.00019610\n",
            "Epoch 388, change: 0.00023744\n",
            "Epoch 390, change: 0.00018890\n",
            "Epoch 391, change: 0.00026525\n",
            "Epoch 389, change: 0.00015862\n",
            "Epoch 389, change: 0.00017968\n",
            "Epoch 391, change: 0.00019485\n",
            "Epoch 389, change: 0.00023567\n",
            "Epoch 391, change: 0.00018761\n",
            "Epoch 392, change: 0.00026313\n",
            "Epoch 390, change: 0.00015749\n",
            "Epoch 390, change: 0.00017796\n",
            "Epoch 392, change: 0.00019361\n",
            "Epoch 390, change: 0.00023345\n",
            "Epoch 392, change: 0.00018637\n",
            "Epoch 393, change: 0.00026151\n",
            "Epoch 391, change: 0.00015637\n",
            "Epoch 391, change: 0.00017674\n",
            "Epoch 393, change: 0.00019238\n",
            "Epoch 391, change: 0.00023152\n",
            "Epoch 393, change: 0.00018511\n",
            "Epoch 394, change: 0.00025929\n",
            "Epoch 392, change: 0.00015525\n",
            "Epoch 392, change: 0.00017510\n",
            "Epoch 394, change: 0.00019115\n",
            "Epoch 392, change: 0.00022943\n",
            "Epoch 394, change: 0.00018387\n",
            "Epoch 395, change: 0.00025747\n",
            "Epoch 393, change: 0.00015414\n",
            "Epoch 393, change: 0.00017356\n",
            "Epoch 395, change: 0.00018994\n",
            "Epoch 393, change: 0.00022779\n",
            "Epoch 395, change: 0.00018264\n",
            "Epoch 396, change: 0.00025556\n",
            "Epoch 394, change: 0.00015304\n",
            "Epoch 394, change: 0.00017228\n",
            "Epoch 396, change: 0.00018872\n",
            "Epoch 394, change: 0.00022510\n",
            "Epoch 396, change: 0.00018142\n",
            "Epoch 397, change: 0.00025368\n",
            "Epoch 395, change: 0.00015195\n",
            "Epoch 395, change: 0.00017089\n",
            "Epoch 397, change: 0.00018752\n",
            "Epoch 395, change: 0.00022360\n",
            "Epoch 397, change: 0.00018021\n",
            "Epoch 398, change: 0.00025197\n",
            "Epoch 396, change: 0.00015086\n",
            "Epoch 396, change: 0.00016932\n",
            "Epoch 398, change: 0.00018633\n",
            "Epoch 396, change: 0.00022211\n",
            "Epoch 398, change: 0.00017899\n",
            "Epoch 399, change: 0.00024991\n",
            "Epoch 397, change: 0.00014979\n",
            "Epoch 397, change: 0.00016783\n",
            "Epoch 399, change: 0.00018514\n",
            "Epoch 397, change: 0.00021972\n",
            "Epoch 399, change: 0.00017779\n",
            "Epoch 400, change: 0.00024822\n",
            "Epoch 398, change: 0.00014873\n",
            "Epoch 398, change: 0.00016653\n",
            "Epoch 400, change: 0.00018395\n",
            "Epoch 398, change: 0.00021767\n",
            "Epoch 400, change: 0.00017660\n",
            "Epoch 401, change: 0.00024646\n",
            "Epoch 399, change: 0.00014766\n",
            "Epoch 399, change: 0.00016496\n",
            "Epoch 401, change: 0.00018279\n",
            "Epoch 399, change: 0.00021628\n",
            "Epoch 401, change: 0.00017542\n",
            "Epoch 402, change: 0.00024464\n",
            "Epoch 400, change: 0.00014660\n",
            "Epoch 400, change: 0.00016368\n",
            "Epoch 402, change: 0.00018162\n",
            "Epoch 400, change: 0.00021352\n",
            "Epoch 402, change: 0.00017424\n",
            "Epoch 403, change: 0.00024291\n",
            "Epoch 401, change: 0.00014556\n",
            "Epoch 401, change: 0.00016225\n",
            "Epoch 403, change: 0.00018046\n",
            "Epoch 401, change: 0.00021208\n",
            "Epoch 403, change: 0.00017308\n",
            "Epoch 404, change: 0.00024122\n",
            "Epoch 402, change: 0.00014452\n",
            "Epoch 402, change: 0.00016088\n",
            "Epoch 404, change: 0.00017931\n",
            "Epoch 402, change: 0.00021038\n",
            "Epoch 404, change: 0.00017191\n",
            "Epoch 405, change: 0.00023956\n",
            "Epoch 403, change: 0.00014348\n",
            "Epoch 403, change: 0.00015967\n",
            "Epoch 405, change: 0.00017817\n",
            "Epoch 403, change: 0.00020831\n",
            "Epoch 405, change: 0.00017076\n",
            "Epoch 406, change: 0.00023797\n",
            "Epoch 404, change: 0.00014247\n",
            "Epoch 404, change: 0.00015812\n",
            "Epoch 406, change: 0.00017704\n",
            "Epoch 404, change: 0.00020685\n",
            "Epoch 406, change: 0.00016962\n",
            "Epoch 407, change: 0.00023574\n",
            "Epoch 405, change: 0.00014145\n",
            "Epoch 405, change: 0.00015700\n",
            "Epoch 407, change: 0.00017591\n",
            "Epoch 405, change: 0.00020497\n",
            "Epoch 407, change: 0.00016848\n",
            "Epoch 408, change: 0.00023402\n",
            "Epoch 406, change: 0.00014045\n",
            "Epoch 406, change: 0.00015557\n",
            "Epoch 408, change: 0.00017479\n",
            "Epoch 406, change: 0.00020322\n",
            "Epoch 408, change: 0.00016736\n",
            "Epoch 409, change: 0.00023245\n",
            "Epoch 407, change: 0.00013944\n",
            "Epoch 407, change: 0.00015436\n",
            "Epoch 409, change: 0.00017368\n",
            "Epoch 407, change: 0.00020114\n",
            "Epoch 409, change: 0.00016625\n",
            "Epoch 410, change: 0.00023074\n",
            "Epoch 408, change: 0.00013846\n",
            "Epoch 408, change: 0.00015286\n",
            "Epoch 410, change: 0.00017257\n",
            "Epoch 408, change: 0.00019985\n",
            "Epoch 410, change: 0.00016514\n",
            "Epoch 411, change: 0.00022917\n",
            "Epoch 409, change: 0.00013747\n",
            "Epoch 409, change: 0.00015179\n",
            "Epoch 411, change: 0.00017148\n",
            "Epoch 409, change: 0.00019757\n",
            "Epoch 411, change: 0.00016400\n",
            "Epoch 412, change: 0.00022756\n",
            "Epoch 410, change: 0.00013648\n",
            "Epoch 410, change: 0.00015036\n",
            "Epoch 412, change: 0.00017038\n",
            "Epoch 410, change: 0.00019614\n",
            "Epoch 412, change: 0.00016292\n",
            "Epoch 413, change: 0.00022600\n",
            "Epoch 411, change: 0.00013550\n",
            "Epoch 411, change: 0.00014906\n",
            "Epoch 413, change: 0.00016930\n",
            "Epoch 411, change: 0.00019439\n",
            "Epoch 413, change: 0.00016183\n",
            "Epoch 414, change: 0.00022438\n",
            "Epoch 412, change: 0.00013454\n",
            "Epoch 412, change: 0.00014783\n",
            "Epoch 414, change: 0.00016822\n",
            "Epoch 412, change: 0.00019331\n",
            "Epoch 414, change: 0.00016074\n",
            "Epoch 415, change: 0.00022238\n",
            "Epoch 413, change: 0.00013358\n",
            "Epoch 413, change: 0.00014675\n",
            "Epoch 415, change: 0.00016715\n",
            "Epoch 413, change: 0.00019078\n",
            "Epoch 415, change: 0.00015967\n",
            "Epoch 416, change: 0.00022098\n",
            "Epoch 414, change: 0.00013263\n",
            "Epoch 414, change: 0.00014540\n",
            "Epoch 416, change: 0.00016608\n",
            "Epoch 414, change: 0.00018926\n",
            "Epoch 416, change: 0.00015859\n",
            "Epoch 417, change: 0.00021928\n",
            "Epoch 415, change: 0.00013168\n",
            "Epoch 415, change: 0.00014431\n",
            "Epoch 417, change: 0.00016503\n",
            "Epoch 415, change: 0.00018756\n",
            "Epoch 417, change: 0.00015754\n",
            "Epoch 418, change: 0.00021783\n",
            "Epoch 416, change: 0.00013074\n",
            "Epoch 416, change: 0.00014285\n",
            "Epoch 418, change: 0.00016398\n",
            "Epoch 416, change: 0.00018619\n",
            "Epoch 418, change: 0.00015648\n",
            "Epoch 419, change: 0.00021619\n",
            "Epoch 417, change: 0.00012981\n",
            "Epoch 417, change: 0.00014177\n",
            "Epoch 419, change: 0.00016294\n",
            "Epoch 417, change: 0.00018438\n",
            "Epoch 419, change: 0.00015543\n",
            "Epoch 420, change: 0.00021462\n",
            "Epoch 418, change: 0.00012889\n",
            "Epoch 418, change: 0.00014058\n",
            "Epoch 420, change: 0.00016190\n",
            "Epoch 418, change: 0.00018302\n",
            "Epoch 420, change: 0.00015439\n",
            "Epoch 421, change: 0.00021302\n",
            "Epoch 419, change: 0.00012796\n",
            "Epoch 419, change: 0.00013945\n",
            "Epoch 421, change: 0.00016087\n",
            "Epoch 419, change: 0.00018135\n",
            "Epoch 421, change: 0.00015336\n",
            "Epoch 422, change: 0.00021153\n",
            "Epoch 420, change: 0.00012705\n",
            "Epoch 422, change: 0.00015985\n",
            "Epoch 420, change: 0.00013815\n",
            "Epoch 420, change: 0.00018032\n",
            "Epoch 422, change: 0.00015233\n",
            "Epoch 423, change: 0.00020996\n",
            "Epoch 421, change: 0.00012615\n",
            "Epoch 423, change: 0.00015884\n",
            "Epoch 421, change: 0.00013719\n",
            "Epoch 421, change: 0.00017811\n",
            "Epoch 423, change: 0.00015131\n",
            "Epoch 424, change: 0.00020853\n",
            "Epoch 422, change: 0.00012525\n",
            "Epoch 424, change: 0.00015782\n",
            "Epoch 422, change: 0.00013588\n",
            "Epoch 422, change: 0.00017649\n",
            "Epoch 424, change: 0.00015030\n",
            "Epoch 425, change: 0.00020695\n",
            "Epoch 423, change: 0.00012435\n",
            "Epoch 425, change: 0.00015681\n",
            "Epoch 423, change: 0.00013488\n",
            "Epoch 423, change: 0.00017548\n",
            "Epoch 425, change: 0.00014929\n",
            "Epoch 426, change: 0.00020544\n",
            "Epoch 424, change: 0.00012347\n",
            "Epoch 426, change: 0.00015582\n",
            "Epoch 424, change: 0.00013365\n",
            "Epoch 424, change: 0.00017401\n",
            "Epoch 426, change: 0.00014829\n",
            "Epoch 427, change: 0.00020403\n",
            "Epoch 425, change: 0.00012259\n",
            "Epoch 427, change: 0.00015483\n",
            "Epoch 425, change: 0.00013268\n",
            "Epoch 425, change: 0.00017171\n",
            "Epoch 427, change: 0.00014730\n",
            "Epoch 428, change: 0.00020245\n",
            "Epoch 426, change: 0.00012171\n",
            "Epoch 428, change: 0.00015385\n",
            "Epoch 426, change: 0.00013140\n",
            "Epoch 426, change: 0.00017067\n",
            "Epoch 428, change: 0.00014631\n",
            "Epoch 429, change: 0.00020105\n",
            "Epoch 427, change: 0.00012085\n",
            "Epoch 429, change: 0.00015287\n",
            "Epoch 427, change: 0.00013040\n",
            "Epoch 427, change: 0.00016920\n",
            "Epoch 429, change: 0.00014533\n",
            "Epoch 430, change: 0.00019960\n",
            "Epoch 428, change: 0.00011999\n",
            "Epoch 430, change: 0.00015190\n",
            "Epoch 428, change: 0.00012922\n",
            "Epoch 428, change: 0.00016783\n",
            "Epoch 430, change: 0.00014437\n",
            "Epoch 431, change: 0.00019826\n",
            "Epoch 429, change: 0.00011913\n",
            "Epoch 431, change: 0.00015093\n",
            "Epoch 429, change: 0.00012813\n",
            "Epoch 429, change: 0.00016609\n",
            "Epoch 431, change: 0.00014339\n",
            "Epoch 432, change: 0.00019690\n",
            "Epoch 430, change: 0.00011829\n",
            "Epoch 432, change: 0.00014997\n",
            "Epoch 430, change: 0.00012709\n",
            "Epoch 430, change: 0.00016475\n",
            "Epoch 432, change: 0.00014244\n",
            "Epoch 433, change: 0.00019542\n",
            "Epoch 431, change: 0.00011745\n",
            "Epoch 433, change: 0.00014902\n",
            "Epoch 431, change: 0.00012603\n",
            "Epoch 431, change: 0.00016326\n",
            "Epoch 433, change: 0.00014148\n",
            "Epoch 434, change: 0.00019390\n",
            "Epoch 432, change: 0.00011661\n",
            "Epoch 434, change: 0.00014807\n",
            "Epoch 432, change: 0.00012503\n",
            "Epoch 432, change: 0.00016197\n",
            "Epoch 434, change: 0.00014053\n",
            "Epoch 435, change: 0.00019250\n",
            "Epoch 433, change: 0.00011577\n",
            "Epoch 435, change: 0.00014713\n",
            "Epoch 433, change: 0.00012399\n",
            "Epoch 433, change: 0.00016045\n",
            "Epoch 435, change: 0.00013960\n",
            "Epoch 436, change: 0.00019104\n",
            "Epoch 434, change: 0.00011495\n",
            "Epoch 436, change: 0.00014619\n",
            "Epoch 434, change: 0.00012284\n",
            "Epoch 434, change: 0.00015938\n",
            "Epoch 436, change: 0.00013866\n",
            "Epoch 437, change: 0.00018973\n",
            "Epoch 435, change: 0.00011413\n",
            "Epoch 437, change: 0.00014527\n",
            "Epoch 435, change: 0.00012189\n",
            "Epoch 435, change: 0.00015805\n",
            "Epoch 437, change: 0.00013773\n",
            "Epoch 438, change: 0.00018846\n",
            "Epoch 436, change: 0.00011332\n",
            "Epoch 438, change: 0.00014434\n",
            "Epoch 436, change: 0.00012092\n",
            "Epoch 436, change: 0.00015618\n",
            "Epoch 438, change: 0.00013682\n",
            "Epoch 439, change: 0.00018690\n",
            "Epoch 437, change: 0.00011251\n",
            "Epoch 439, change: 0.00014343\n",
            "Epoch 437, change: 0.00011996\n",
            "Epoch 437, change: 0.00015531\n",
            "Epoch 439, change: 0.00013590\n",
            "Epoch 440, change: 0.00018568\n",
            "Epoch 438, change: 0.00011171\n",
            "Epoch 440, change: 0.00014252\n",
            "Epoch 438, change: 0.00011899\n",
            "Epoch 438, change: 0.00015400\n",
            "Epoch 440, change: 0.00013498\n",
            "Epoch 441, change: 0.00018429\n",
            "Epoch 439, change: 0.00011091\n",
            "Epoch 441, change: 0.00014161\n",
            "Epoch 439, change: 0.00011807\n",
            "Epoch 439, change: 0.00015255\n",
            "Epoch 441, change: 0.00013409\n",
            "Epoch 442, change: 0.00018296\n",
            "Epoch 440, change: 0.00011012\n",
            "Epoch 442, change: 0.00014071\n",
            "Epoch 440, change: 0.00011712\n",
            "Epoch 440, change: 0.00015140\n",
            "Epoch 442, change: 0.00013319\n",
            "Epoch 443, change: 0.00018162\n",
            "Epoch 441, change: 0.00010934\n",
            "Epoch 443, change: 0.00013982\n",
            "Epoch 441, change: 0.00011579\n",
            "Epoch 441, change: 0.00015011\n",
            "Epoch 443, change: 0.00013229\n",
            "Epoch 444, change: 0.00018042\n",
            "Epoch 442, change: 0.00010855\n",
            "Epoch 444, change: 0.00013893\n",
            "Epoch 442, change: 0.00011491\n",
            "Epoch 442, change: 0.00014885\n",
            "Epoch 444, change: 0.00013142\n",
            "Epoch 445, change: 0.00017906\n",
            "Epoch 443, change: 0.00010778\n",
            "Epoch 445, change: 0.00013805\n",
            "Epoch 443, change: 0.00011391\n",
            "Epoch 443, change: 0.00014717\n",
            "Epoch 445, change: 0.00013053\n",
            "Epoch 446, change: 0.00017785\n",
            "Epoch 444, change: 0.00010702\n",
            "Epoch 446, change: 0.00013717\n",
            "Epoch 444, change: 0.00011300\n",
            "Epoch 444, change: 0.00014619\n",
            "Epoch 446, change: 0.00012966\n",
            "Epoch 447, change: 0.00017643\n",
            "Epoch 447, change: 0.00013630\n",
            "Epoch 445, change: 0.00010626\n",
            "Epoch 445, change: 0.00011209\n",
            "Epoch 445, change: 0.00014440\n",
            "Epoch 447, change: 0.00012880\n",
            "Epoch 448, change: 0.00017515\n",
            "Epoch 448, change: 0.00013544\n",
            "Epoch 446, change: 0.00010550\n",
            "Epoch 446, change: 0.00011108\n",
            "Epoch 446, change: 0.00014350\n",
            "Epoch 448, change: 0.00012794\n",
            "Epoch 449, change: 0.00017395\n",
            "Epoch 449, change: 0.00013458\n",
            "Epoch 447, change: 0.00010476\n",
            "Epoch 447, change: 0.00011019\n",
            "Epoch 447, change: 0.00014236\n",
            "Epoch 449, change: 0.00012706\n",
            "Epoch 450, change: 0.00017267\n",
            "Epoch 450, change: 0.00013372\n",
            "Epoch 448, change: 0.00010400\n",
            "Epoch 448, change: 0.00010923\n",
            "Epoch 448, change: 0.00014114\n",
            "Epoch 450, change: 0.00012623\n",
            "Epoch 451, change: 0.00017148\n",
            "Epoch 451, change: 0.00013287\n",
            "Epoch 449, change: 0.00010326\n",
            "Epoch 449, change: 0.00010837\n",
            "Epoch 449, change: 0.00014015\n",
            "Epoch 451, change: 0.00012538\n",
            "Epoch 452, change: 0.00017016\n",
            "Epoch 452, change: 0.00013203\n",
            "Epoch 450, change: 0.00010253\n",
            "Epoch 450, change: 0.00010746\n",
            "Epoch 450, change: 0.00013846\n",
            "Epoch 452, change: 0.00012454\n",
            "Epoch 453, change: 0.00016899\n",
            "Epoch 453, change: 0.00013119\n",
            "Epoch 451, change: 0.00010180\n",
            "Epoch 451, change: 0.00010656\n",
            "Epoch 451, change: 0.00013739\n",
            "Epoch 453, change: 0.00012371\n",
            "Epoch 454, change: 0.00016772\n",
            "Epoch 454, change: 0.00013036\n",
            "Epoch 452, change: 0.00010106\n",
            "Epoch 452, change: 0.00010567\n",
            "Epoch 452, change: 0.00013621\n",
            "Epoch 454, change: 0.00012288\n",
            "Epoch 455, change: 0.00016659\n",
            "Epoch 455, change: 0.00012953\n",
            "Epoch 453, change: 0.00010035\n",
            "Epoch 453, change: 0.00010473\n",
            "Epoch 453, change: 0.00013521\n",
            "Epoch 455, change: 0.00012207\n",
            "Epoch 456, change: 0.00016531\n",
            "Epoch 456, change: 0.00012871\n",
            "convergence after 454 epochs took 455 seconds\n",
            "Epoch 454, change: 0.00010391\n",
            "Epoch 454, change: 0.00013387\n",
            "Epoch 456, change: 0.00012124\n",
            "Epoch 457, change: 0.00016412\n",
            "Epoch 457, change: 0.00012789\n",
            "Epoch 455, change: 0.00010307\n",
            "Epoch 455, change: 0.00013268\n",
            "Epoch 457, change: 0.00012043\n",
            "Epoch 458, change: 0.00016295\n",
            "Epoch 458, change: 0.00012708\n",
            "Epoch 456, change: 0.00010218\n",
            "Epoch 456, change: 0.00013165\n",
            "Epoch 458, change: 0.00011963\n",
            "Epoch 459, change: 0.00016183\n",
            "Epoch 459, change: 0.00012628\n",
            "Epoch 457, change: 0.00010142\n",
            "Epoch 457, change: 0.00013080\n",
            "Epoch 459, change: 0.00011883\n",
            "Epoch 460, change: 0.00016076\n",
            "Epoch 460, change: 0.00012547\n",
            "Epoch 458, change: 0.00010046\n",
            "Epoch 458, change: 0.00012906\n",
            "Epoch 460, change: 0.00011803\n",
            "Epoch 461, change: 0.00015953\n",
            "Epoch 461, change: 0.00012467\n",
            "convergence after 459 epochs took 462 seconds\n",
            "Epoch 459, change: 0.00012821\n",
            "Epoch 461, change: 0.00011725\n",
            "Epoch 462, change: 0.00015822\n",
            "Epoch 462, change: 0.00012388\n",
            "Epoch 460, change: 0.00012709\n",
            "Epoch 462, change: 0.00011646\n",
            "Epoch 463, change: 0.00015729\n",
            "Epoch 463, change: 0.00012310\n",
            "Epoch 461, change: 0.00012618\n",
            "Epoch 463, change: 0.00011568\n",
            "Epoch 464, change: 0.00015594\n",
            "Epoch 464, change: 0.00012231\n",
            "Epoch 462, change: 0.00012499\n",
            "Epoch 464, change: 0.00011491\n",
            "Epoch 465, change: 0.00015491\n",
            "Epoch 465, change: 0.00012154\n",
            "Epoch 463, change: 0.00012386\n",
            "Epoch 465, change: 0.00011414\n",
            "Epoch 466, change: 0.00015386\n",
            "Epoch 466, change: 0.00012077\n",
            "Epoch 464, change: 0.00012302\n",
            "Epoch 466, change: 0.00011338\n",
            "Epoch 467, change: 0.00015277\n",
            "Epoch 467, change: 0.00012000\n",
            "Epoch 465, change: 0.00012195\n",
            "Epoch 467, change: 0.00011261\n",
            "Epoch 468, change: 0.00015173\n",
            "Epoch 468, change: 0.00011924\n",
            "Epoch 466, change: 0.00012100\n",
            "Epoch 468, change: 0.00011186\n",
            "Epoch 469, change: 0.00015068\n",
            "Epoch 469, change: 0.00011848\n",
            "Epoch 467, change: 0.00011971\n",
            "Epoch 469, change: 0.00011112\n",
            "Epoch 470, change: 0.00014942\n",
            "Epoch 470, change: 0.00011773\n",
            "Epoch 468, change: 0.00011873\n",
            "Epoch 470, change: 0.00011038\n",
            "Epoch 471, change: 0.00014832\n",
            "Epoch 471, change: 0.00011699\n",
            "Epoch 469, change: 0.00011775\n",
            "Epoch 471, change: 0.00010963\n",
            "Epoch 472, change: 0.00014730\n",
            "Epoch 472, change: 0.00011625\n",
            "Epoch 470, change: 0.00011682\n",
            "Epoch 472, change: 0.00010890\n",
            "Epoch 473, change: 0.00014626\n",
            "Epoch 473, change: 0.00011551\n",
            "Epoch 471, change: 0.00011607\n",
            "Epoch 473, change: 0.00010817\n",
            "Epoch 474, change: 0.00014517\n",
            "Epoch 474, change: 0.00011478\n",
            "Epoch 472, change: 0.00011504\n",
            "Epoch 474, change: 0.00010745\n",
            "Epoch 475, change: 0.00014422\n",
            "Epoch 475, change: 0.00011405\n",
            "Epoch 473, change: 0.00011339\n",
            "Epoch 475, change: 0.00010674\n",
            "Epoch 476, change: 0.00014313\n",
            "Epoch 476, change: 0.00011332\n",
            "Epoch 474, change: 0.00011288\n",
            "Epoch 476, change: 0.00010602\n",
            "Epoch 477, change: 0.00014202\n",
            "Epoch 477, change: 0.00011260\n",
            "Epoch 475, change: 0.00011197\n",
            "Epoch 477, change: 0.00010531\n",
            "Epoch 478, change: 0.00014100\n",
            "Epoch 478, change: 0.00011189\n",
            "Epoch 476, change: 0.00011108\n",
            "Epoch 478, change: 0.00010461\n",
            "Epoch 479, change: 0.00014003\n",
            "Epoch 479, change: 0.00011118\n",
            "Epoch 477, change: 0.00010967\n",
            "Epoch 479, change: 0.00010391\n",
            "Epoch 480, change: 0.00013901\n",
            "Epoch 480, change: 0.00011048\n",
            "Epoch 478, change: 0.00010892\n",
            "Epoch 480, change: 0.00010321\n",
            "Epoch 481, change: 0.00013802\n",
            "Epoch 481, change: 0.00010978\n",
            "Epoch 479, change: 0.00010823\n",
            "Epoch 481, change: 0.00010253\n",
            "Epoch 482, change: 0.00013705\n",
            "Epoch 482, change: 0.00010908\n",
            "Epoch 480, change: 0.00010726\n",
            "Epoch 482, change: 0.00010184\n",
            "Epoch 483, change: 0.00013602\n",
            "Epoch 483, change: 0.00010839\n",
            "Epoch 481, change: 0.00010607\n",
            "Epoch 483, change: 0.00010116\n",
            "Epoch 484, change: 0.00013506\n",
            "Epoch 484, change: 0.00010770\n",
            "Epoch 482, change: 0.00010533\n",
            "Epoch 484, change: 0.00010048\n",
            "Epoch 485, change: 0.00013414\n",
            "Epoch 485, change: 0.00010702\n",
            "Epoch 483, change: 0.00010435\n",
            "convergence after 485 epochs took 482 seconds\n",
            "Epoch 486, change: 0.00013311\n",
            "Epoch 486, change: 0.00010634\n",
            "Epoch 484, change: 0.00010346\n",
            "Epoch 487, change: 0.00013218\n",
            "Epoch 487, change: 0.00010567\n",
            "Epoch 485, change: 0.00010267\n",
            "Epoch 488, change: 0.00013124\n",
            "Epoch 488, change: 0.00010499\n",
            "Epoch 486, change: 0.00010169\n",
            "Epoch 489, change: 0.00013036\n",
            "Epoch 489, change: 0.00010433\n",
            "Epoch 487, change: 0.00010067\n",
            "Epoch 490, change: 0.00012931\n",
            "Epoch 490, change: 0.00010367\n",
            "convergence after 488 epochs took 484 seconds\n",
            "Epoch 491, change: 0.00012841\n",
            "Epoch 491, change: 0.00010301\n",
            "Epoch 492, change: 0.00012745\n",
            "Epoch 492, change: 0.00010236\n",
            "Epoch 493, change: 0.00012659\n",
            "Epoch 493, change: 0.00010171\n",
            "Epoch 494, change: 0.00012563\n",
            "Epoch 494, change: 0.00010107\n",
            "Epoch 495, change: 0.00012482\n",
            "Epoch 495, change: 0.00010042\n",
            "Epoch 496, change: 0.00012382\n",
            "convergence after 496 epochs took 489 seconds\n",
            "Epoch 497, change: 0.00012300\n",
            "Epoch 498, change: 0.00012211\n",
            "Epoch 499, change: 0.00012127\n",
            "Epoch 500, change: 0.00012038\n",
            "Epoch 501, change: 0.00011958\n",
            "Epoch 502, change: 0.00011858\n",
            "Epoch 503, change: 0.00011779\n",
            "Epoch 504, change: 0.00011693\n",
            "Epoch 505, change: 0.00011615\n",
            "Epoch 506, change: 0.00011523\n",
            "Epoch 507, change: 0.00011446\n",
            "Epoch 508, change: 0.00011360\n",
            "Epoch 509, change: 0.00011283\n",
            "Epoch 510, change: 0.00011195\n",
            "Epoch 511, change: 0.00011117\n",
            "Epoch 512, change: 0.00011037\n",
            "Epoch 513, change: 0.00010959\n",
            "Epoch 514, change: 0.00010885\n",
            "Epoch 515, change: 0.00010813\n",
            "Epoch 516, change: 0.00010732\n",
            "Epoch 517, change: 0.00010646\n",
            "Epoch 518, change: 0.00010573\n",
            "Epoch 519, change: 0.00010490\n",
            "Epoch 520, change: 0.00010422\n",
            "Epoch 521, change: 0.00010352\n",
            "Epoch 522, change: 0.00010264\n",
            "Epoch 523, change: 0.00010194\n",
            "Epoch 524, change: 0.00010127\n",
            "Epoch 525, change: 0.00010055\n",
            "convergence after 526 epochs took 517 seconds\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0640843487394958 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05586882738346957 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024163738524936095 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014203334757401398 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007269835993149527 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031297712732813784 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007903334018712538 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000450670209458163 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002578222437458051 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 9.420290843371138e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.22978964893988219.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                                        FunctionTransformer(func=&lt;function preprocess_data at 0x175540a40&gt;,\n",
              "                                                            kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                                       (&#x27;logisticregression&#x27;,\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;logisticregression__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;sag&#x27;,\n",
              "                                                        &#x27;saga&#x27;, &#x27;lbfgs&#x27;],\n",
              "                         &#x27;preprocessing__kw_args&#x27;: [{&#x27;method&#x27;: &#x27;normalize&#x27;},\n",
              "                                                    {&#x27;method&#x27;: &#x27;binarize&#x27;}]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                                        FunctionTransformer(func=&lt;function preprocess_data at 0x175540a40&gt;,\n",
              "                                                            kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                                       (&#x27;logisticregression&#x27;,\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;logisticregression__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;sag&#x27;,\n",
              "                                                        &#x27;saga&#x27;, &#x27;lbfgs&#x27;],\n",
              "                         &#x27;preprocessing__kw_args&#x27;: [{&#x27;method&#x27;: &#x27;normalize&#x27;},\n",
              "                                                    {&#x27;method&#x27;: &#x27;binarize&#x27;}]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function preprocess_data at 0x175540a40&gt;,\n",
              "                                     kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                (&#x27;logisticregression&#x27;,\n",
              "                 LogisticRegression(max_iter=10000, solver=&#x27;newton-cg&#x27;,\n",
              "                                    verbose=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function preprocess_data at 0x175540a40&gt;,\n",
              "                    kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;newton-cg&#x27;, verbose=1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('preprocessing',\n",
              "                                        FunctionTransformer(func=<function preprocess_data at 0x175540a40>,\n",
              "                                                            kw_args={'method': 'normalize'})),\n",
              "                                       ('logisticregression',\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'logisticregression__solver': ['newton-cg', 'sag',\n",
              "                                                        'saga', 'lbfgs'],\n",
              "                         'preprocessing__kw_args': [{'method': 'normalize'},\n",
              "                                                    {'method': 'binarize'}]},\n",
              "             scoring='f1_weighted', verbose=1)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Grid search with your pipeline\n",
        "## commenting these lines to avoid running fit again as it is time consuming.\n",
        "## uncomment the below lines to fit model again.\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring=\"f1_weighted\", n_jobs=-1, verbose=1)\n",
        "grid_search.fit(train_X, train_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oj0VCOudrpB"
      },
      "source": [
        "##### Finding Best Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpeEqwJFS1jz",
        "outputId": "6326203d-4c91-4b5c-ddbb-e4a2d2e57752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'logisticregression__solver': 'newton-cg', 'preprocessing__kw_args': {'method': 'normalize'}}\n",
            "Best F1 Score: 0.9204433376055948\n"
          ]
        }
      ],
      "source": [
        "# Best params and score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best F1 Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWp1NVE68Gqx"
      },
      "source": [
        "##### Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "MLjOhWEV5GIJ"
      },
      "outputs": [],
      "source": [
        "## dump the model to google drive\n",
        "# filename = joblib.dump(grid_search.best_estimator_, f\"{shared_folder_path}/logistic_regression_best_model.joblib\")\n",
        "save_model(grid_search.best_estimator_, \"logistic_regression_v1.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwqsnB8d9hmr",
        "outputId": "38b1a7c8-c411-4ebf-8af5-b1157838af7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([ 28.50849724,  27.54449733, 306.79800105, 308.38000703,\n",
              "        487.81333653, 477.84813762,  23.51338299,  23.86472789]),\n",
              " 'std_fit_time': array([ 0.60806676,  0.97046056, 19.76600528, 12.23758659, 22.64126077,\n",
              "        14.85395318,  0.4342204 ,  0.38090089]),\n",
              " 'mean_score_time': array([0.27372948, 0.28919959, 0.13347689, 0.22060474, 0.08749445,\n",
              "        0.14384158, 0.23106503, 0.18673372]),\n",
              " 'std_score_time': array([0.07651892, 0.05792351, 0.01989788, 0.02318948, 0.00408268,\n",
              "        0.00802898, 0.06584602, 0.01925479]),\n",
              " 'param_logisticregression__solver': masked_array(data=['newton-cg', 'newton-cg', 'sag', 'sag', 'saga', 'saga',\n",
              "                    'lbfgs', 'lbfgs'],\n",
              "              mask=[False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_preprocessing__kw_args': masked_array(data=[{'method': 'normalize'}, {'method': 'binarize'},\n",
              "                    {'method': 'normalize'}, {'method': 'binarize'},\n",
              "                    {'method': 'normalize'}, {'method': 'binarize'},\n",
              "                    {'method': 'normalize'}, {'method': 'binarize'}],\n",
              "              mask=[False, False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'logisticregression__solver': 'newton-cg',\n",
              "   'preprocessing__kw_args': {'method': 'normalize'}},\n",
              "  {'logisticregression__solver': 'newton-cg',\n",
              "   'preprocessing__kw_args': {'method': 'binarize'}},\n",
              "  {'logisticregression__solver': 'sag',\n",
              "   'preprocessing__kw_args': {'method': 'normalize'}},\n",
              "  {'logisticregression__solver': 'sag',\n",
              "   'preprocessing__kw_args': {'method': 'binarize'}},\n",
              "  {'logisticregression__solver': 'saga',\n",
              "   'preprocessing__kw_args': {'method': 'normalize'}},\n",
              "  {'logisticregression__solver': 'saga',\n",
              "   'preprocessing__kw_args': {'method': 'binarize'}},\n",
              "  {'logisticregression__solver': 'lbfgs',\n",
              "   'preprocessing__kw_args': {'method': 'normalize'}},\n",
              "  {'logisticregression__solver': 'lbfgs',\n",
              "   'preprocessing__kw_args': {'method': 'binarize'}}],\n",
              " 'split0_test_score': array([0.91906499, 0.90864351, 0.91896009, 0.90913417, 0.91890747,\n",
              "        0.90908187, 0.91901975, 0.90850093]),\n",
              " 'split1_test_score': array([0.91970242, 0.9074639 , 0.9194354 , 0.90762015, 0.9194354 ,\n",
              "        0.90762015, 0.9191696 , 0.90751268]),\n",
              " 'split2_test_score': array([0.9225626 , 0.90962854, 0.92142711, 0.90908886, 0.92142711,\n",
              "        0.90908984, 0.92089949, 0.90904651]),\n",
              " 'mean_test_score': array([0.92044334, 0.90857865, 0.91994087, 0.9086144 , 0.91992333,\n",
              "        0.90859729, 0.91969628, 0.90835337]),\n",
              " 'std_test_score': array([0.00152097, 0.0008849 , 0.0010687 , 0.00070328, 0.00108496,\n",
              "        0.00069095, 0.00085299, 0.00063481]),\n",
              " 'rank_test_score': array([1, 7, 2, 5, 3, 6, 4, 8], dtype=int32)}"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "8eWhKAcI8aAl"
      },
      "outputs": [],
      "source": [
        "# Save cross-validation results as JSON\n",
        "## commenting these lines to avoid overwriting the model in google drive.\n",
        "## uncomment them to update the model in google drive.\n",
        "\n",
        "# filename = joblib.dump(grid_search.cv_results_, f\"{shared_folder_path}/logistic_regression_v1_cv_results.joblib\")\n",
        "save_model(grid_search.cv_results_, \"logistic_regression_v1_cv_results.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545aexfaLVeh"
      },
      "source": [
        "##### Performance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99OqaCN4w1KV"
      },
      "source": [
        "* To calculate the performance metrics, we'll first get the best params from grid search and do cross val with the same params."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "hpsk1VMIyikc"
      },
      "outputs": [],
      "source": [
        "best_params = grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "X-ZVEi0fyoIH"
      },
      "outputs": [],
      "source": [
        "## create new pipeline\n",
        "## defaulting to newton-cg solver if not found in best_params, because that was the best solver in iteration 1 of grid search.\n",
        "logistic_regression = LogisticRegression(max_iter=10000, verbose=1, solver=best_params.get(\"logisticregression__solver\", \"newton-cg\"))\n",
        "## create pipeline\n",
        "preprocessing_method = best_params.get(\"preprocessing__kw_args\", {\"method\": \"normalize\"})[\"method\"]\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessing\", FunctionTransformer(preprocess_data, kw_args={\"method\": preprocessing_method})),\n",
        "    (\"training\", logistic_regression)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNEvRLeyzM8X",
        "outputId": "4285b609-d799-4652-82c8-6bd1a257d0b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05595957070928089 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0556326571727961 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596280984522609 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.023023988305067158 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024388942315533235 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025091128394095222 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013596754560941109 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014506205604912571 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.01453673896669188 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005054019827049796 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007593654728518624 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007283441377992933 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023202958093750045 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032522697034441383 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031146963465692153 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000913237919852819 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007994908562239658 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000836455371295198 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005284668717374731 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005088976609375899 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005773570836641845 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002756891144761195 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00032831161461654914 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003457691373532914 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010587022746062941 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00022188555862540438 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010949043378872298 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 9.829169845516656e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2261625773537494.\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.9769157620122838e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.21649195609951896.\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.8331698858140754e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2182472068133294.\n"
          ]
        }
      ],
      "source": [
        "probabilities = cross_val_predict(pipeline, train_X, train_Y, cv=3, method=\"predict_proba\", n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "dvk9G4gW3_DF",
        "outputId": "bc769070-48cf-4390-e685-d80b0e941207"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Method</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1 Score</th>\n",
              "      <th>ROC AUC Score</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>Default Estimator</td>\n",
              "      <td>0.919839</td>\n",
              "      <td>0.919697</td>\n",
              "      <td>0.992891</td>\n",
              "      <td>0.96094</td>\n",
              "      <td>0.964241</td>\n",
              "      <td>0.904483</td>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.926959</td>\n",
              "      <td>0.879824</td>\n",
              "      <td>0.944259</td>\n",
              "      <td>0.929785</td>\n",
              "      <td>0.880834</td>\n",
              "      <td>0.897883</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Algorithm             Method  Accuracy  Weighted F1 Score  \\\n",
              "0  Logistic Regression  Default Estimator  0.919839           0.919697   \n",
              "\n",
              "   ROC AUC Score  Class_0   Class_1   Class_2   Class_3   Class_4   Class_5  \\\n",
              "0       0.992891  0.96094  0.964241  0.904483  0.898339  0.926959  0.879824   \n",
              "\n",
              "    Class_6   Class_7   Class_8   Class_9  \n",
              "0  0.944259  0.929785  0.880834  0.897883  "
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "-igPDimqNoxK"
      },
      "outputs": [],
      "source": [
        "comparison_df = update_model_comparison(probabilities, train_Y, \"Logistic Regression V1\", \"GridSearchCV\", comparison_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "RUc1nO52Yhjf",
        "outputId": "01084b93-1015-460c-dc52-b277a9090150"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Method</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1 Score</th>\n",
              "      <th>ROC AUC Score</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>Default Estimator</td>\n",
              "      <td>0.919839</td>\n",
              "      <td>0.919697</td>\n",
              "      <td>0.992891</td>\n",
              "      <td>0.960940</td>\n",
              "      <td>0.964241</td>\n",
              "      <td>0.904483</td>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.926959</td>\n",
              "      <td>0.879824</td>\n",
              "      <td>0.944259</td>\n",
              "      <td>0.929785</td>\n",
              "      <td>0.880834</td>\n",
              "      <td>0.897883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>GridSearchCV</td>\n",
              "      <td>0.920589</td>\n",
              "      <td>0.920444</td>\n",
              "      <td>0.992934</td>\n",
              "      <td>0.960701</td>\n",
              "      <td>0.964468</td>\n",
              "      <td>0.905045</td>\n",
              "      <td>0.899217</td>\n",
              "      <td>0.927801</td>\n",
              "      <td>0.881860</td>\n",
              "      <td>0.944334</td>\n",
              "      <td>0.930612</td>\n",
              "      <td>0.882478</td>\n",
              "      <td>0.898686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Algorithm             Method  Accuracy  Weighted F1 Score  \\\n",
              "0  Logistic Regression  Default Estimator  0.919839           0.919697   \n",
              "1  Logistic Regression       GridSearchCV  0.920589           0.920444   \n",
              "\n",
              "   ROC AUC Score   Class_0   Class_1   Class_2   Class_3   Class_4   Class_5  \\\n",
              "0       0.992891  0.960940  0.964241  0.904483  0.898339  0.926959  0.879824   \n",
              "1       0.992934  0.960701  0.964468  0.905045  0.899217  0.927801  0.881860   \n",
              "\n",
              "    Class_6   Class_7   Class_8   Class_9  \n",
              "0  0.944259  0.929785  0.880834  0.897883  \n",
              "1  0.944334  0.930612  0.882478  0.898686  "
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6e1OafAOJbb"
      },
      "source": [
        "Observations:\n",
        "* We see slight improvement in hyper tuned model, but nothing significant. Lets try second iteration of GridSearchCV while keeping `solver` and `arguments` as it is and finding best penalty and C value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4CzhGROBZwi"
      },
      "source": [
        "#### Iteration 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "9AfVrdctAuoc"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"logisticregression__penalty\": [\"l2\", \"none\"],\n",
        "    \"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "}\n",
        "\n",
        "## initialize LogisticRegression\n",
        "logistic_regression = LogisticRegression(max_iter=10000, verbose=1, solver=\"newton-cg\")\n",
        "\n",
        "## create pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessing\", FunctionTransformer(preprocess_data, kw_args={\"method\": \"normalize\"})),\n",
        "    (\"logisticregression\", logistic_regression)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "0cQZ1gb2ySdT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055564065752412115 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055562390638798476 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02432906067101161 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025014333511724714 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0555970450825691 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05524060914005245 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05190199271115941 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02301896702628503 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014040146519874818 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014019285137091685 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05165096503827657 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02297238233791094 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02461197375918775 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0519472609388737 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02278163146395315 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013557421162128927 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024059743389368227 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055926431956904214 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013171309205769336 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055923640488595217 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007296904610291197 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007482663900920433 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025083798155239107 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.010484076639706318 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.010097110507840568 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024383172341876317 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.010779454332901544 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005065541125684582 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014488922114073073 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0556326571727961 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00354037435355282 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.008812577434644997 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.003674936919392082 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.01446318016887404 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0069789120499681835 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.023023988305067158 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.008468079166671876 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596280984522609 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05595957070928089 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.009105121824390364 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025091128394095222 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023467551513162944 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024388942315533235 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007594867746964214 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013596754560941109 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0072830810223857454 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0035259918693891596 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014506205604912571 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.01453673896669188 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0012760345490456305 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.002001317946866174 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0012479302758733844 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.003152071846735626 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005054019827049796 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00177694349634275 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032894088761413567 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0019295779746140449 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007283441377992933 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007773652777184898 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0012935603181583645 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007593654728518624 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.001194956471441318 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0012272624991858572 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0011877976903233863 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023202958093750045 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007209542399616343 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0006039273987990154 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032522697034441383 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031146963465692153 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007434279210330187 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007153852880897589 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00019014547133748235 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0006321152470001904 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0004634213649588231 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0006890222878775543 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0006788917850443394 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000913237919852819 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00013833894184318193 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00015856244172271142 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001556761111711034 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000836455371295198 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007994908562239658 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003050509630877706 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000399436840947619 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 7.4990556137787e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.7153146804790197.\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 6.872045625559582e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.7191290423133508.\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001208048815349592 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00016669901705916037 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.8396786325280944e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.7175774431327271.\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 3.1034347203771106e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.39630679219687004.\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.9673681311368662e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.39218200647310375.\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005284668717374731 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00020543133104297627 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005773570836641845 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001416408159326003 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005088976609375899 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596644736547852 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05563621806067901 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 3.989536177090954e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.3905888224697264.\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02509186536159745 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.023024494162193966 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596316345273406 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.94044164517556e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2701159656201794.\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014541529058781628 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002756891144761195 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024389523001331098 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013600695021156416 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055636574146249486 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596352272428737 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 6.354098463447835e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2770602111181727.\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.05596681111481183 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02302454478530166 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0075934943391692 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014510515247939748 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00032831161461654914 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024389581106896895 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025091939097891546 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005052831607139531 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 4.1545474253220635e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2716568327265989.\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013601089138278472 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014510946283114055 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014542008151932568 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007283493446101924 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031109908789157398 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003457691373532914 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023176968174017207 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005052712422229324 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007283498812030823 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007593477957946967 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032485937284625257 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023174374744748833 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032482265443146687 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00311062070162115 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0008239526345900075 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0009121119228269432 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.001308438215077127 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00022188555862540438 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0008732234572114266 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0008262584713304899 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.001247413298571283 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010587022746062941 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000610422403980983 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010949043378872298 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007069440354207921 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00048245313363068766 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007085377607142712 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00055237818153694 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000440818198293241 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00040091585957261454 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0006193429486532404 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0004715864650232148 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 9.829169845516656e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2261625773537494.\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0004705105448131787 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0005267285960200239 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.9769157620122838e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.21649195609951896.\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00022502444831957362 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002115599631456347 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000418622105337116 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 2.8331698858140754e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2182472068133294.\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001908730691454986 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003669091638481095 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0002740002497711003 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00019720227200500242 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00040821285507904606 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00019276923370367598 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00011632661148418438 <= 0.0001 False\n",
            "Newton-CG iter = 10Newton-CG iter = 10\n",
            "\n",
            "  Check Convergence  Check Convergence\n",
            "\n",
            "    max |gradient| <= tol: 0.00019284158008265286 <= 0.0001 False    max |gradient| <= tol: 0.0001783988707843964 <= 0.0001 False\n",
            "\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00016386247130532688 <= 0.0001 False\n",
            "Newton-CG iter = 10\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001839036156015388 <= 0.0001 False\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00012533257529979887 <= 0.0001 False\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00011061155128695 <= 0.0001 False\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00017763344444246955 <= 0.0001 False\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 9.531634888107158e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.1848306550431336.\n",
            "Newton-CG iter = 12\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00010600616162245349 <= 0.0001 False\n",
            "Newton-CG iter = 11\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00016047087651088174 <= 0.0001 False\n",
            "Newton-CG iter = 12\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00013781078806919506 <= 0.0001 False\n",
            "Newton-CG iter = 12\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 6.58751413371422e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.18864427734725123.\n",
            "Newton-CG iter = 13\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 3.4848631122161004e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.18640638494626502.\n",
            "Newton-CG iter = 12\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00013379073104418477 <= 0.0001 False\n",
            "Newton-CG iter = 13\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.966660767480363e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.19476744649341077.\n",
            "Newton-CG iter = 12\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00024137880895179627 <= 0.0001 False\n",
            "Newton-CG iter = 13\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001490092063684326 <= 0.0001 False\n",
            "Newton-CG iter = 13\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 8.237156653134281e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.17495933559441748.\n",
            "Newton-CG iter = 14\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.660727933300787e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.1816967780288528.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "18 fits failed out of a total of 36.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "4 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/Users/gaurangdave/anaconda3/envs/ml/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.88715685        nan 0.91171344        nan 0.92119086        nan\n",
            " 0.92044334        nan 0.91256468        nan 0.910563          nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0640843487394958 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055844834961084146 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024159706273318312 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014174266275980962 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007271341865288091 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0031551853574376997 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007129159485098198 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00041611691202089865 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00019037509431587743 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.83773662971508e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.26863483023546475.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                                        FunctionTransformer(func=&lt;function preprocess_data at 0x175540a40&gt;,\n",
              "                                                            kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                                       (&#x27;logisticregression&#x27;,\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           solver=&#x27;newton-cg&#x27;,\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10,\n",
              "                                                   100],\n",
              "                         &#x27;logisticregression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                                        FunctionTransformer(func=&lt;function preprocess_data at 0x175540a40&gt;,\n",
              "                                                            kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                                       (&#x27;logisticregression&#x27;,\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           solver=&#x27;newton-cg&#x27;,\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10,\n",
              "                                                   100],\n",
              "                         &#x27;logisticregression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;none&#x27;]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function preprocess_data at 0x175540a40&gt;,\n",
              "                                     kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})),\n",
              "                (&#x27;logisticregression&#x27;,\n",
              "                 LogisticRegression(C=0.1, max_iter=10000, solver=&#x27;newton-cg&#x27;,\n",
              "                                    verbose=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function preprocess_data at 0x175540a40&gt;,\n",
              "                    kw_args={&#x27;method&#x27;: &#x27;normalize&#x27;})</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.1, max_iter=10000, solver=&#x27;newton-cg&#x27;, verbose=1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('preprocessing',\n",
              "                                        FunctionTransformer(func=<function preprocess_data at 0x175540a40>,\n",
              "                                                            kw_args={'method': 'normalize'})),\n",
              "                                       ('logisticregression',\n",
              "                                        LogisticRegression(max_iter=10000,\n",
              "                                                           solver='newton-cg',\n",
              "                                                           verbose=1))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'logisticregression__C': [0.001, 0.01, 0.1, 1, 10,\n",
              "                                                   100],\n",
              "                         'logisticregression__penalty': ['l2', 'none']},\n",
              "             scoring='f1_weighted', verbose=1)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring=\"f1_weighted\", n_jobs=-1, verbose=1)\n",
        "grid_search.fit(train_X, train_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Finding Best Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2'}\n",
            "Best F1 Score: 0.9211908550922101\n"
          ]
        }
      ],
      "source": [
        "# Best params and score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best F1 Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "## dump the model to google drive\n",
        "# filename = joblib.dump(grid_search.best_estimator_, f\"{shared_folder_path}/logistic_regression_best_model.joblib\")\n",
        "save_model(grid_search.best_estimator_, \"logistic_regression_v2.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Performance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* To calculate the performance metrics, we'll first get the best params from grid search and do cross val with the same params."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_params = grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "## create new pipeline\n",
        "## defaulting to newton-cg solver if not found in best_params, because that was the best solver in iteration 1 of grid search.\n",
        "\n",
        "logistic_regression = LogisticRegression(max_iter=10000, verbose=1, solver=\"newton-cg\", penalty=best_params.get(\"logisticregression__penalty\", \"l2\"), C=best_params.get(\"logisticregression__C\", 0.1))\n",
        "## create pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessing\", FunctionTransformer(preprocess_data, kw_args={\"method\": \"normalize\"})),\n",
        "    (\"training\", logistic_regression)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0641773902393036 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06405625109635646 <= 0.0001 False\n",
            "Newton-CG iter = 0\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.06401940563544949 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055926431956904214 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0555970450825691 <= 0.0001 False\n",
            "Newton-CG iter = 1\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.055923640488595217 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.025083798155239107 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.02301896702628503 <= 0.0001 False\n",
            "Newton-CG iter = 2\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.024383172341876317 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.013557421162128927 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.014488922114073073 <= 0.0001 False\n",
            "Newton-CG iter = 3\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.01446318016887404 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.005065541125684582 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.007594867746964214 <= 0.0001 False\n",
            "Newton-CG iter = 4\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0072830810223857454 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.003152071846735626 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0023467551513162944 <= 0.0001 False\n",
            "Newton-CG iter = 5\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0032894088761413567 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007773652777184898 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007153852880897589 <= 0.0001 False\n",
            "Newton-CG iter = 6\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0007434279210330187 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.000399436840947619 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0004634213649588231 <= 0.0001 False\n",
            "Newton-CG iter = 7\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0003050509630877706 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00020543133104297627 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.00016669901705916037 <= 0.0001 False\n",
            "Newton-CG iter = 8\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 0.0001416408159326003 <= 0.0001 False\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 6.354098463447835e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2770602111181727.\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 5.94044164517556e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2701159656201794.\n",
            "Newton-CG iter = 9\n",
            "  Check Convergence\n",
            "    max |gradient| <= tol: 4.1545474253220635e-05 <= 0.0001 True\n",
            "  Solver did converge at loss = 0.2716568327265989.\n"
          ]
        }
      ],
      "source": [
        "probabilities = cross_val_predict(pipeline, train_X, train_Y, cv=3, method=\"predict_proba\", n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Method</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1 Score</th>\n",
              "      <th>ROC AUC Score</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>Default Estimator</td>\n",
              "      <td>0.919839</td>\n",
              "      <td>0.919697</td>\n",
              "      <td>0.992891</td>\n",
              "      <td>0.960940</td>\n",
              "      <td>0.964241</td>\n",
              "      <td>0.904483</td>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.926959</td>\n",
              "      <td>0.879824</td>\n",
              "      <td>0.944259</td>\n",
              "      <td>0.929785</td>\n",
              "      <td>0.880834</td>\n",
              "      <td>0.897883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>GridSearchCV</td>\n",
              "      <td>0.920589</td>\n",
              "      <td>0.920444</td>\n",
              "      <td>0.992934</td>\n",
              "      <td>0.960701</td>\n",
              "      <td>0.964468</td>\n",
              "      <td>0.905045</td>\n",
              "      <td>0.899217</td>\n",
              "      <td>0.927801</td>\n",
              "      <td>0.881860</td>\n",
              "      <td>0.944334</td>\n",
              "      <td>0.930612</td>\n",
              "      <td>0.882478</td>\n",
              "      <td>0.898686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Algorithm             Method  Accuracy  Weighted F1 Score  \\\n",
              "0  Logistic Regression  Default Estimator  0.919839           0.919697   \n",
              "1  Logistic Regression       GridSearchCV  0.920589           0.920444   \n",
              "\n",
              "   ROC AUC Score   Class_0   Class_1   Class_2   Class_3   Class_4   Class_5  \\\n",
              "0       0.992891  0.960940  0.964241  0.904483  0.898339  0.926959  0.879824   \n",
              "1       0.992934  0.960701  0.964468  0.905045  0.899217  0.927801  0.881860   \n",
              "\n",
              "    Class_6   Class_7   Class_8   Class_9  \n",
              "0  0.944259  0.929785  0.880834  0.897883  \n",
              "1  0.944334  0.930612  0.882478  0.898686  "
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "comparison_df = update_model_comparison(probabilities, train_Y, \"Logistic Regression V2\", \"GridSearchCV\", comparison_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Method</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Weighted F1 Score</th>\n",
              "      <th>ROC AUC Score</th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>Default Estimator</td>\n",
              "      <td>0.919839</td>\n",
              "      <td>0.919697</td>\n",
              "      <td>0.992891</td>\n",
              "      <td>0.960940</td>\n",
              "      <td>0.964241</td>\n",
              "      <td>0.904483</td>\n",
              "      <td>0.898339</td>\n",
              "      <td>0.926959</td>\n",
              "      <td>0.879824</td>\n",
              "      <td>0.944259</td>\n",
              "      <td>0.929785</td>\n",
              "      <td>0.880834</td>\n",
              "      <td>0.897883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>GridSearchCV</td>\n",
              "      <td>0.920589</td>\n",
              "      <td>0.920444</td>\n",
              "      <td>0.992934</td>\n",
              "      <td>0.960701</td>\n",
              "      <td>0.964468</td>\n",
              "      <td>0.905045</td>\n",
              "      <td>0.899217</td>\n",
              "      <td>0.927801</td>\n",
              "      <td>0.881860</td>\n",
              "      <td>0.944334</td>\n",
              "      <td>0.930612</td>\n",
              "      <td>0.882478</td>\n",
              "      <td>0.898686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic Regression V2</td>\n",
              "      <td>GridSearchCV</td>\n",
              "      <td>0.921375</td>\n",
              "      <td>0.921193</td>\n",
              "      <td>0.993371</td>\n",
              "      <td>0.961961</td>\n",
              "      <td>0.960945</td>\n",
              "      <td>0.908795</td>\n",
              "      <td>0.900696</td>\n",
              "      <td>0.927737</td>\n",
              "      <td>0.880727</td>\n",
              "      <td>0.948119</td>\n",
              "      <td>0.931754</td>\n",
              "      <td>0.884302</td>\n",
              "      <td>0.898043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Algorithm             Method  Accuracy  Weighted F1 Score  \\\n",
              "0     Logistic Regression  Default Estimator  0.919839           0.919697   \n",
              "1     Logistic Regression       GridSearchCV  0.920589           0.920444   \n",
              "2  Logistic Regression V2       GridSearchCV  0.921375           0.921193   \n",
              "\n",
              "   ROC AUC Score   Class_0   Class_1   Class_2   Class_3   Class_4   Class_5  \\\n",
              "0       0.992891  0.960940  0.964241  0.904483  0.898339  0.926959  0.879824   \n",
              "1       0.992934  0.960701  0.964468  0.905045  0.899217  0.927801  0.881860   \n",
              "2       0.993371  0.961961  0.960945  0.908795  0.900696  0.927737  0.880727   \n",
              "\n",
              "    Class_6   Class_7   Class_8   Class_9  \n",
              "0  0.944259  0.929785  0.880834  0.897883  \n",
              "1  0.944334  0.930612  0.882478  0.898686  \n",
              "2  0.948119  0.931754  0.884302  0.898043  "
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observations:\n",
        "* So there is slight improvement in Accuracy and F1 Scores from previous version, and its definately better than default version. \n",
        "* We also see some improvements in per class f1 scores, specially class 3 which has f1 score of 0.9 as compared to .89 in baseline version. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "## saving the dataframe to csv file\n",
        "save_comparison_df(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Params\n",
        "* So for `Logistic Regresssion` following are the final params that gives us best estimator,\n",
        "    * Preprocessing: `normalize`\n",
        "    * Solver : `newton-cg`\n",
        "    * C : `0.1`\n",
        "    * Penalty : `l2`\n",
        "* These params will give us an classifier with F1 score of `0.92`, Accuracy of `0.92` and ROC AUC Score of `.99`\n",
        "* We still need to test this on test data, but we'll do that after exploring other algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Support Vector Classifier (SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Default Estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter Tuning"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
